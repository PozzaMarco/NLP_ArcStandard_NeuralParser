{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c041f954-42d3-44e6-b2c2-281d579e61e6",
   "metadata": {
    "id": "c041f954-42d3-44e6-b2c2-281d579e61e6"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install transformers\n",
    "#!pip install datasets\n",
    "#!pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f",
   "metadata": {
    "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer, BertModel, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d704ceb0",
   "metadata": {
    "id": "d704ceb0"
   },
   "source": [
    "# Bert model and other hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad5b81d",
   "metadata": {
    "id": "cad5b81d"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BERT_MODEL = 'dbmdz/bert-base-italian-xxl-cased'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "DROPOUT_RATE = 0.3\n",
    "MLP_SIZE_1 = 500\n",
    "MLP_SIZE_2 = 150\n",
    "INPUT_SIZE = 3*768\n",
    "\n",
    "\n",
    "EPOCHS = 5\n",
    "SAVE_PATH = \"saved_checkpoint.pt\"\n",
    "TOKENIZER_MAX_LEN = 75\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
   "metadata": {
    "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5"
   },
   "source": [
    "# Arc-standard\n",
    "\n",
    "Recall that a **configuration** of the arc-standard parser is a triple of the form $( \\sigma, \\beta, A)$\n",
    "where:\n",
    "\n",
    "* $\\sigma$ is the stack;\n",
    "* $\\beta$ is the input buffer;\n",
    "* $A$ is a set of arcs constructed so far.\n",
    "\n",
    "We write $\\sigma_i$, $i \\geq 1$, for the $i$-th token in the stack; we also write $\\beta_i$, $i \\geq 1$, for the $i$-th token in the buffer. \n",
    "\n",
    "The parser can perform three types of **actions** (transitions):\n",
    "\n",
    "* **shift**, which removes $\\beta_1$ from the buffer and pushes it into the stack;\n",
    "* **left-arc**, which creates the arc $(\\sigma_1 \\rightarrow \\sigma_2)$, and removes $\\sigma_2$ from the stack;\n",
    "* **right-arc**, which creates the arc $(\\sigma_2 \\rightarrow \\sigma_1)$, and removes $\\sigma_1$ from the stack.\n",
    "\n",
    "Let $w = w_0 w_1 \\cdots w_{n}$ be the input sentence, with $w_0$ the special symbol `<ROOT>`.\n",
    "Stack and buffer are implemented as lists of integers, where `j` represents word $w_j$.  Top-most stack token is at the right-end of the list; first buffer token is at the left-end of the list. \n",
    "Set $A$ is implemented as an array `arcs` of size $n+1$ such that if arc $(w_i \\rightarrow w_j)$ is in $A$ then `arcs[j]=i`, and if $w_j$ is still missing its head node in the tree under construction, then `arcs[j]=-1`. We always have `arcs[0]=-1`.  We use this representation also for complete dependency trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf",
   "metadata": {
    "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf"
   },
   "outputs": [],
   "source": [
    "import orig #file orig.py in the same foldr contains original class and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7",
   "metadata": {
    "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7"
   },
   "outputs": [],
   "source": [
    "class ArcStandard (orig.ArcStandard):\n",
    "    def __init__(self, sentence, label_set):\n",
    "        self.sentence = sentence\n",
    "        self.buffer = [i for i in range(len(self.sentence))]\n",
    "        self.stack = []\n",
    "        self.arcs = [(-1, -1) for _ in range(len(self.sentence))]# head - relation converted to int\n",
    "\n",
    "        self.label_set = {y:x for x,y in label_set.items()} #for future reference (printing)\n",
    "        # three shift moves to initialize the stack\n",
    "        self.shift()\n",
    "        self.shift()\n",
    "        if len(self.sentence) > 2:\n",
    "            self.shift()\n",
    "\n",
    "    def left_arc(self, deprel):\n",
    "        o1 = self.stack.pop()\n",
    "        o2 = self.stack.pop()\n",
    "        self.arcs[o2] = (o1, deprel) #added deprel\n",
    "        self.stack.append(o1)\n",
    "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
    "            self.shift()\n",
    "\n",
    "    def right_arc(self, deprel):\n",
    "        o1 = self.stack.pop()\n",
    "        o2 = self.stack.pop()\n",
    "        self.arcs[o1] = (o2, deprel) #added deprel\n",
    "        self.stack.append(o2)\n",
    "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
    "            self.shift()\n",
    "\n",
    "    def print_configuration(self):\n",
    "        s = [self.sentence[i] for i in self.stack]\n",
    "        b = [self.sentence[i] for i in self.buffer]\n",
    "        print(\"STACK: \", s, \"BUFFER: \", b) #added indication of stack and buffer\n",
    "        print([(x[0], self.label_set[x[1]]) for x in self.arcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d836502-bba0-4f49-9c39-39a916ed270c",
   "metadata": {
    "id": "1d836502-bba0-4f49-9c39-39a916ed270c"
   },
   "outputs": [],
   "source": [
    "class Oracle (orig.Oracle):\n",
    "    def __init__(self, parser, gold_tree, gold_labels):\n",
    "        self.parser = parser\n",
    "        self.gold = gold_tree\n",
    "        self.labels = gold_labels #must be integers; see below\n",
    "\n",
    "    def get_gold_label(self):\n",
    "        if(self.is_left_arc_gold()):\n",
    "            o2 = self.parser.stack[len(self.parser.stack)-2]\n",
    "            return self.labels[o2]\n",
    "        elif(self.is_right_arc_gold()):\n",
    "            o1 = self.parser.stack[len(self.parser.stack)-1]\n",
    "            return self.labels[o1]\n",
    "        else:\n",
    "            raise Exception(\"Action SHIFT does not produce a labeled dependency\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2",
   "metadata": {
    "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2"
   },
   "source": [
    "## Functions to simplify the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374",
   "metadata": {
    "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dataset should be a Dataset object from HuggingFace\n",
    "Return a dictionary where arc labels are associate to integer values.\n",
    "Label '_' is removed (used for composite tokens)\n",
    "Labels are sorted in alphabetical order because MSE in the neural network will penalize less classes that are \"close\".\n",
    "<ROOT> label is given value -1 (label of the <ROOT> node).\n",
    "\"\"\"\n",
    "def create_deprel_dict(dataset):\n",
    "    labels = set()\n",
    "    for x in dataset['deprel']:\n",
    "        for elem in x:\n",
    "            if(elem != '_'):\n",
    "                labels.add(elem)\n",
    "    labels = sorted(list(labels))\n",
    "    ret = {labels[i]:i for i in range(len(labels))}\n",
    "    ret.update({\"None\":-1})\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "Return (sanitized_tokens, gold tree, gold labels) for a sentence in the dataset, assuming gold tree is in a column labeled 'head' and labels in a column labeled 'deprel'.\n",
    "Both token indices and labels are converted to integer (in the latter case, according to deprel_dict).\n",
    "Sanitized tokens is a tokenlist with removal of composite tokens.\n",
    "\"\"\"\n",
    "def create_gold(sentence, deprel_dict):\n",
    "    sanitized = ['<ROOT>']\n",
    "    gold_tree = [-1]\n",
    "    gold_labels = [-1]\n",
    "    for i in range(len(sentence['tokens'])):\n",
    "        if(sentence['head'][i] != 'None') and sentence['deprel'][i] in deprel_dict: #second condition is to avoid unseen or wrong labels\n",
    "            sanitized.append(sentence['tokens'][i])\n",
    "            gold_tree.append(int(sentence['head'][i]))\n",
    "            gold_labels.append(deprel_dict[sentence['deprel'][i]])\n",
    "    \n",
    "    return sanitized, gold_tree, gold_labels\n",
    "\n",
    "# Convert the list of words into a list of sentences to be preprocessed by BERT Tokenizer\n",
    "def to_list_sentences(sentences):\n",
    "  list_sentences = []\n",
    "\n",
    "  for lst in sentences:\n",
    "    s = \"\"\n",
    "    for word in lst:\n",
    "      s+= (word + \" \")\n",
    "    list_sentences.append(s)\n",
    "  return list_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd",
   "metadata": {
    "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd"
   },
   "source": [
    "## Testing parser and oracle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bcbd5e-b121-4cef-992f-f22df16e4315",
   "metadata": {
    "id": "21bcbd5e-b121-4cef-992f-f22df16e4315"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9269d170-abea-4671-b795-a9026fc3e46a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9269d170-abea-4671-b795-a9026fc3e46a",
    "outputId": "6eca8ecb-bcd9-4597-8f7f-23225dac6b20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<ROOT>', 'Inconsueto', 'allarme', 'a', 'la', 'Tate', 'Gallery', ':']\n",
      "[-1, 2, 0, 5, 5, 2, 5, 2]\n",
      "[-1, 4, 41, 8, 17, 31, 28, 40]\n"
     ]
    }
   ],
   "source": [
    "deprels = create_deprel_dict(train_dataset)\n",
    "sentence = train_dataset[3]\n",
    "\n",
    "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
    "\n",
    "print(tokens)\n",
    "print(gold_tree)\n",
    "print(gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
    "outputId": "130b1a7a-aab9-44ed-bab3-271d30a4d91a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK:  ['<ROOT>', 'Inconsueto', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n"
     ]
    }
   ],
   "source": [
    "parser = ArcStandard(tokens, deprels)\n",
    "oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "parser.print_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
    "outputId": "1618b31f-212b-4f67-9081-510419a02f38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a'] BUFFER:  ['la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'la'] BUFFER:  ['Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'la', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate', 'Gallery'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', ':'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n",
      "STACK:  ['<ROOT>'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (0, 'root'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n"
     ]
    }
   ],
   "source": [
    "while not parser.is_tree_final():  # transition precedence implemented here\n",
    "    if oracle.is_shift_gold():  \n",
    "        parser.shift()\n",
    "    elif oracle.is_left_arc_gold():\n",
    "        parser.left_arc(oracle.get_gold_label())\n",
    "    elif oracle.is_right_arc_gold():\n",
    "        parser.right_arc(oracle.get_gold_label())\n",
    "    \n",
    "    parser.print_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05840970-630c-4152-bdc6-2c25e81fefff",
   "metadata": {
    "id": "05840970-630c-4152-bdc6-2c25e81fefff"
   },
   "source": [
    "## Testing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68",
    "outputId": "c76432ea-e47d-4a8d-8963-08e0d596f6d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember to call orig.is_projective() to check for projectivity!!\n",
    "sentence = train_dataset[10]\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
    "orig.is_projective(gold_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6464ec95-43b7-457a-b764-8ce310c34207",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6464ec95-43b7-457a-b764-8ce310c34207",
    "outputId": "c692c839-da83-4380-96b5-7e289a9f0c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non projective:  167\n",
      "correct:  282533\n",
      "wrong:  0\n"
     ]
    }
   ],
   "source": [
    "### NOTE: THIS CELL WAS COPIED WITH FEW MODIFICATIONS FROM THE ORIGINAL FILE\n",
    "\n",
    "# oracle test: run the parser guided by the oracle on the entire training set \n",
    "\n",
    "non_projective = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "for sample in train_dataset:\n",
    "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
    "\n",
    "    if not orig.is_projective(gold_tree):\n",
    "        non_projective += 1\n",
    "        continue\n",
    "\n",
    "    parser = ArcStandard(tokens, deprels)\n",
    "    oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "    while not parser.is_tree_final():\n",
    "        if oracle.is_left_arc_gold(): \n",
    "            parser.left_arc(oracle.get_gold_label())\n",
    "        elif oracle.is_right_arc_gold():\n",
    "            parser.right_arc(oracle.get_gold_label())\n",
    "        elif oracle.is_shift_gold(): \n",
    "            parser.shift()\n",
    "\n",
    "    for j in range(len(gold_tree)):  # comparing heads from parser and gold for actual sample\n",
    "        if gold_tree[j] == parser.arcs[j][0] and gold_labels[j] == parser.arcs[j][1]: \n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "print(\"non projective: \", non_projective)\n",
    "print(\"correct: \", correct)\n",
    "print(\"wrong: \", wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
   "metadata": {
    "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
    "outputId": "f87fd0da-15df-4d67-829e-21be6b0ee436"
   },
   "source": [
    "## Creating samples for the neural oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453c9ca5-9c30-4813-bf82-2555efaeac12",
   "metadata": {
    "id": "453c9ca5-9c30-4813-bf82-2555efaeac12"
   },
   "outputs": [],
   "source": [
    "# Modified from the original\n",
    "\"\"\"\n",
    "This function processes a single sample, which is one sentence provided as an element of a Dataset object and returns \n",
    "    enc_sentence : a list of integers encoding the phrase #???? is this even correct for BERT???\n",
    "    gold_path : a list of configurations\n",
    "    gold_moves : a list of (move, label)\n",
    "\"\"\"\n",
    "def process_sample(sample, deprels, get_gold_path = False): #emb_dictionary and deprels are dictionaries of words and of dependency relations\n",
    "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
    "    #print(\"DEBUG:\", tokens)\n",
    "    #enc_sentence = [word if word in emb_dictionary else \"<unk>\" for word in tokens] #NOT NEEDED! BERT takes care of unknown words\n",
    "    #print(\"DEBUG:\", enc_sentence)\n",
    "    \n",
    "    # gold_path and gold_moves are parallel arrays whose elements refer to parsing steps\n",
    "    gold_path = []   # record two topmost stack token and first buffer token for current step\n",
    "    gold_moves = []  # oracle (canonical) move for current step: 100 is left, 0 right, -100 shift #motivations provided above TODO\n",
    "\n",
    "    if get_gold_path:  # only for training\n",
    "        parser = ArcStandard(tokens, deprels)\n",
    "        oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "        while not parser.is_tree_final():\n",
    "            configuration = [parser.stack[len(parser.stack)-2], parser.stack[len(parser.stack)-1]]\n",
    "            if len(parser.buffer) == 0:\n",
    "                configuration.append(-1)\n",
    "            else:\n",
    "                configuration.append(parser.buffer[0])\n",
    "\n",
    "            gold_path.append(configuration)\n",
    "            \n",
    "            if oracle.is_left_arc_gold():\n",
    "                label_code = oracle.get_gold_label() #deprels[oracle.get_gold_label()]\n",
    "                parser.left_arc(label_code) #labels 1-45 mean leftarc\n",
    "                gold_moves.append(1+label_code) #note: I switched the instructions here for symmetry. There was no comment or good reason not to.\n",
    "            elif oracle.is_right_arc_gold():\n",
    "                label_code = oracle.get_gold_label() #deprels[oracle.get_gold_label()]\n",
    "                parser.right_arc(1 + len(deprels) + label_code) #labels 46-90 mean rightarc\n",
    "                gold_moves.append(1 + len(deprels) + label_code)\n",
    "            elif oracle.is_shift_gold():\n",
    "                parser.shift()\n",
    "                gold_moves.append(0)\n",
    "            else:\n",
    "                print(\"**** AN ERROR OCCURRED ****\")\n",
    "                #print(tokens)\n",
    "                #print(enc_sentence)\n",
    "                #print(gold_tree)\n",
    "                parser.print_configuration()\n",
    "                raise Exception(\"No action identified as gold!! Please make sure your dataset doesn't contain nonprojective trees.\")\n",
    "                \n",
    "            #print(\"DEBUG: \", parser.stack)\n",
    "    \n",
    "    #print(\"DEBUG: length of path: \", len(gold_path), \"length of moves: \", len(gold_moves))\n",
    "    return tokens, gold_path, gold_moves, gold_tree, gold_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d214f7df-0622-40df-9ce6-ace620105cc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "d214f7df-0622-40df-9ce6-ace620105cc2",
    "outputId": "e5b9aed6-06da-4d05-95ce-f54c2d65d72e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_sentence = train_dataset[88]\\nemb_dictionary = create_dict(train_dataset)\\ndeprels = create_deprel_dict(train_dataset)\\n\\nprocess_sample(test_sentence, emb_dictionary, deprels, get_gold_path = True)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code to test process_sample\n",
    "\"\"\"\n",
    "test_sentence = train_dataset[88]\n",
    "emb_dictionary = create_dict(train_dataset)\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "process_sample(test_sentence, emb_dictionary, deprels, get_gold_path = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1",
   "metadata": {
    "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that prepares the data for the model.\n",
    "@return sentences : list of sentences in the dataset encoded according to emb_dictionary\n",
    "@return paths : list of lists of configurations visited during the oracle-guided parsing (on training data) | empty list if get_gold_path is False\n",
    "@return moves : list of lists of moves as a number performed during the oracle-guided parsing (on training data) | empty if get_gold_path is False\n",
    "                                N.B. 0 = shift\n",
    "                                        1-45 = leftarc + label\n",
    "                                        46-90 = rightarc + label\n",
    "@return trees : ground truth tree\n",
    "@return labels : ground truth lables\n",
    "\"\"\"\n",
    "#modified form orig\n",
    "def prepare_batch(batch_data, deprels, get_gold_path=False):\n",
    "    data = [process_sample(s, deprels, get_gold_path=get_gold_path) for s in batch_data]\n",
    "    # sentences, paths, moves, trees are parallel arrays, each element refers to a sentence\n",
    "    sentences = [s[0] for s in data]\n",
    "    paths = [s[1] for s in data]\n",
    "    moves = [s[2] for s in data]\n",
    "    trees = [s[3] for s in data]\n",
    "    labels = [s[4] for s in data]\n",
    "    return sentences, paths, moves, trees, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f3002b0-00f7-4f95-82f7-215b97ada014",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "0f3002b0-00f7-4f95-82f7-215b97ada014",
    "outputId": "854b1429-501f-4fc2-d1b9-67b556f502c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nemb_dictionary = create_dict(train_dataset)\\ndeprels = create_deprel_dict(train_dataset)\\n\\n_ = prepare_batch(iter(train_dataset), emb_dictionary, deprels, True)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### code to test prepare_batch\n",
    "\"\"\"\n",
    "emb_dictionary = create_dict(train_dataset)\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "_ = prepare_batch(iter(train_dataset), emb_dictionary, deprels, True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7e3cfb5-dad2-48a3-bc92-cf2196d8748f",
   "metadata": {
    "id": "c7e3cfb5-dad2-48a3-bc92-cf2196d8748f"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copied from original.\n",
    "Modified casing of pad and unk.\n",
    "\"\"\"\n",
    "def create_dict(dataset, threshold=3):\n",
    "  dic = {}  # dictionary of word counts\n",
    "  for sample in dataset:\n",
    "    for word in sample['tokens']:\n",
    "      if word in dic:\n",
    "        dic[word] += 1\n",
    "      else:\n",
    "        dic[word] = 1 \n",
    "\n",
    "  map = {}  # dictionary of word/index pairs\n",
    "  map[\"[PAD]\"] = 0\n",
    "  map[\"<ROOT>\"] = 1\n",
    "  map[\"<unk>\"] = 2\n",
    "\n",
    "  next_indx = 3\n",
    "  for word in dic.keys():\n",
    "    if dic[word] >= threshold:\n",
    "      map[word] = next_indx\n",
    "      next_indx += 1\n",
    "\n",
    "  return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dc8dfb6-91e4-425d-8406-bd427b31d053",
   "metadata": {
    "id": "0dc8dfb6-91e4-425d-8406-bd427b31d053"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return the indices of the element to mantain in the dataset. This procedure was\n",
    "created because some sentences present some dependecies never seen in the training\n",
    "and will not processed correctly.\n",
    "In our case the worng sentences have the following idx element: 10_new-83\n",
    "\"\"\"\n",
    "def remove_sentences(dataset, idx):\n",
    "    ret = []\n",
    "    for i in range(len(dataset)):\n",
    "        x = dataset[i]\n",
    "        if x[\"idx\"] != idx:\n",
    "            ret.append(i)\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "Return indices of projective sentences in the dataset. Must be used with select() to filter out nonprojective trees.\n",
    "\"\"\"\n",
    "def find_projective_idx(dataset):\n",
    "    ret = []\n",
    "    for i in range(len(dataset)):\n",
    "        x = dataset[i]\n",
    "        if orig.is_projective([-1] + [int(head) for head in x[\"head\"] if head!='None']):\n",
    "            ret.append(i)\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "Return indices of sentences shorter than TOKENIZER_MAX_LEN/2 (to account for subtokens)\n",
    "\"\"\"\n",
    "def find_long_idx(dataset):\n",
    "    ret = []\n",
    "    for i in range(len(dataset)):\n",
    "        x = dataset[i]\n",
    "        if len(x[\"tokens\"]) < int(TOKENIZER_MAX_LEN*0.66): \n",
    "            ret.append(i)\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "Remove trailing apostrophes in tokens from the dataset\n",
    "This function will be applied by map() on each row of the dataset separately\n",
    "\"\"\"\n",
    "def remove_apostrophe(example):\n",
    "    example['tokens'] = [ example['tokens'][i][:-1] if (example['tokens'][i][-1]==\"'\" and example['tokens'][i][0]!=\"'\") else  example['tokens'][i] for i in range(len(example['tokens']))]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f28698",
   "metadata": {
    "id": "c8f28698"
   },
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "referenced_widgets": [
      "e8906ef310e545009d9eda77e7f84950",
      "24cf7f369c0444efa4daa98863fe952f",
      "4e3c0567edec4b78b62bc8cde063ee9e",
      "5b5405d078c84e2ea21f1ca8e719b698",
      "7bb4712d68034260be29924cf24969c0",
      "5d38df55c6b744e28f265ca1644c78ac",
      "4f54fc2cce884678a636d24948127381",
      "a56d09474e0247c2b68ed18345ecd8e4",
      "5268d9d9519544c6803d8d0fd97e1088",
      "e8a9e6fff8a34cd2ba8420901c1344f7",
      "eb17c1f76c394a5cac764a415cedddb5",
      "2b8d762966f64f25bd41c40bf7b1e0b2",
      "dfdbd6c2f7724bb2a1c0b3fd95fcdadf",
      "26d33e5772a64f8fa3aca53d7c111d29",
      "88fbd16c7ff2487e9ec01594838ab426",
      "5359e14052f54381a58d8f846629f6cf",
      "b52fcf0461d946eb902793a7c513c467",
      "c00f960bc6ca47ab9efa330dc76e415e",
      "c6bed0ac748c4da6a3b2a6aca87d255a",
      "75c20f16616e417bbf21055b36cb3f67",
      "e3bbd11ad7a94f6183b5e06d002e76e3",
      "5a2adf50ddbc41b68c6573957971e4f4",
      "ee91fa8b40bf4c018eb4e3a01be00589",
      "2b80b5aaa02040928f7411a2e77d57ae",
      "e444112e2aea49f3b41aa19e3a78b687",
      "11864f5edce54fe4aca12957bcfb2744",
      "8c12944a4db94cb4ac3c8e3276c7de70",
      "787707d041474b6aad5901020ec386de",
      "99de82f14ce1412f9737f3d12bea7a42",
      "163f4e024ca04d0691d4ad7d1f06c11d",
      "a6a4c55a4908462faa12c529b8c5f5fa",
      "6f7e490b42644809ab354ece8f39039d",
      "162a7f46b3754069b8c7449ab0e14ce5",
      "ba63d8a18d7742fda3f78419238a0841",
      "7d851215506e4bbd889e6d81579a72e1",
      "6ba992b8f6f8482e8e9f5801354d1522",
      "c7c9a05b9bb640a591c5b6e55c51b5fd",
      "e7a9623f60454f9e9f01d861c8dc65d4",
      "e8742c42cf034968a2657a069600bd49",
      "c18e286a91a44e4989f14cd0c5cdf6d4",
      "671b43f0fb974bf3ad3c6317223b1fa7",
      "abaace07c6f24ce3b360b6b3bf13dd7b",
      "7d7f0bb756b2433baa7eb67b2c50798f",
      "46ff0f37a8184ff7a3e21d9163b42d5e"
     ]
    },
    "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
    "outputId": "df907f4a-369b-4d8f-c020-bc29caf4ebc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
      "Loading cached processed dataset at /home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d/cache-1548aef782f705ca.arrow\n",
      "Loading cached processed dataset at /home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d/cache-7685e31ce8d76f0a.arrow\n",
      "Loading cached processed dataset at /home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d/cache-aa7f40d419b056c7.arrow\n",
      "Loading cached processed dataset at /home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d/cache-8d333d70cc816d4c.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")\n",
    "train_lite_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train[:10%]\")\n",
    "dev_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"validation\")\n",
    "test_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"test\")\n",
    "\n",
    "train_dataset = train_dataset.select(find_projective_idx(train_dataset)) #to remove nonprojective trees\n",
    "train_dataset = train_dataset.select(find_long_idx(train_dataset)) #to remove sentences too long\n",
    "train_dataset = train_dataset.map(remove_apostrophe)\n",
    "\n",
    "train_lite_dataset = train_lite_dataset.select(find_projective_idx(train_lite_dataset)) #to remove nonprojective trees\n",
    "train_lite_dataset = train_lite_dataset.select(find_long_idx(train_lite_dataset)) #to remove sentences too long\n",
    "train_lite_dataset = train_lite_dataset.map(remove_apostrophe)\n",
    "\n",
    "dev_dataset = dev_dataset.select(find_projective_idx(dev_dataset)) #to remove nonprojective trees\n",
    "dev_dataset = dev_dataset.select(find_long_idx(dev_dataset)) #to remove sentences too long\n",
    "dev_dataset = dev_dataset.map(remove_apostrophe)\n",
    "\n",
    "test_dataset = test_dataset.select(remove_sentences(test_dataset, \"10_new-83\")) #this specific sentence has a label that never appears in the training set\n",
    "test_dataset = test_dataset.select(find_projective_idx(test_dataset)) #to remove nonprojective trees\n",
    "test_dataset = test_dataset.select(find_long_idx(test_dataset)) #to remove sentences too long\n",
    "test_dataset = test_dataset.map(remove_apostrophe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bcb2cbf-eebb-4099-bba8-a05925919abf",
   "metadata": {
    "id": "8bcb2cbf-eebb-4099-bba8-a05925919abf"
   },
   "outputs": [],
   "source": [
    "#emb_dictionary = create_dict(train_dataset)\n",
    "deprels = create_deprel_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d176de-aa6a-4258-ab75-e46c772beb81",
   "metadata": {
    "id": "51d176de-aa6a-4258-ab75-e46c772beb81"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(prepare_batch, deprels = deprels, get_gold_path=True))\n",
    "train_lite_dataloader = torch.utils.data.DataLoader(train_lite_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(prepare_batch, deprels = deprels, get_gold_path=True))\n",
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch, deprels = deprels, get_gold_path=True))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch, deprels = deprels, get_gold_path=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b",
   "metadata": {
    "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b"
   },
   "source": [
    "## Ideas for the future\n",
    "* Use mean square error to predict pairs (MOVE, LABEL) in the training set\n",
    "* We need to rescale the data in an acceptable range. Probably should make the MOVE have greater variation, e.g LeftArc=100 RightArc=0 Shift=-100\n",
    "* BERT layer must process each sentence separately to produce word embeddings, but it should also be finetuned alongside the fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xNoPh6s17yyx",
   "metadata": {
    "id": "xNoPh6s17yyx"
   },
   "source": [
    "# Neural Oracle\n",
    "\n",
    "Neural oracle implemented using BERT fine-tunned with a simple classifiers.\n",
    "The references are: [Towards Data Science](https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f) and [Text Classification | Sentiment Analysis with BERT using huggingface, PyTorch and Python Tutorial](https://www.youtube.com/watch?v=8N-nM3QW7O0).\n",
    "\n",
    "The hyperparameters and the training tweaks are taken from the original BERT paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ZfqzDHLLA08V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "b007865b76de4b4187fa9adfe8bb50de",
      "cdc57b438f1c441f9e44ad73e9020a8a",
      "177d6115f64946949f194af9369dc6c4",
      "c8ab0d73e9824a24ada934e611af163b",
      "2edde41cfe23483baae27aeda2c22ec7",
      "e25d49a1e840452e8bd21025709d81dd",
      "c09a422c3bde4dfda823a95b41f28d00",
      "044dba1986d843f1abed44d8489462b4",
      "4aec3392e3664f26a39f38a4c5181de9",
      "83f5c41a0d8f4f51b6c3c415765db15f",
      "9e661ec955b44e14ace7bc60478ffe16",
      "2c31a4d2e87a4e90a4532e4965549e8a",
      "fb1f53e8d5c448699865afdef2e6468e",
      "464381f9c4104593b73252f5251bc0b3",
      "021171af678f45b4b5438492cd2dcf0a",
      "f3a58e57364c4a0d879579995c0f2a1f",
      "46cfb0de504344fabbe3a47b799d5cab",
      "04fd7433bcee4d6fafc43bbf648b7e74",
      "0d6ce7c063a74780913dd0e00b7ff668",
      "e50de337c5c64dc1ae64f90c7f899016",
      "b60725bbf7014763a6d8c3c0d9be9a20",
      "42ae41c6fe3b4b02add2a3e0204cff5e",
      "d87aa740108a48e6a7fba60860aa966a",
      "c1b6f79804194108a6436f19c61f447c",
      "032ad69c29f84f57ab22ed99e0aec44d",
      "200e2ca9e3094422b0798395f908bf72",
      "8882eeaa91df40408c0f5c9eec56490a",
      "9a3abd55570d45dead562ff14cd0b7c1",
      "789338215eac4ac0bb9c56fd3c6111ce",
      "4290084e2c564e94bc7604d8c2803f39",
      "a29c036922204cf1948efebc71ff742e",
      "73528e1820e847a6898d3ff20a32323f",
      "0dc7e3c838394c1c9a36cab9e68915c2"
     ]
    },
    "id": "ZfqzDHLLA08V",
    "outputId": "d90a2141-5b7b-4d85-feab-546987e265f5"
   },
   "outputs": [],
   "source": [
    "# load the BERT tokenizer with pretrained weights for the Italian language\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845TJICw2Q9x",
   "metadata": {
    "id": "845TJICw2Q9x"
   },
   "source": [
    "In this section we have loaded the BERT tokenizer and try it to see how a sentence is processed and which kind of objects the tokenizer returns to be used in BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "QtZZfEGK9IG5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtZZfEGK9IG5",
    "outputId": "51c911b0-63c8-43ca-ab4d-1e7a58744c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  102,   401,   162,  1909,   532, 27948,  2369,   139,  5101,  1783,\n",
      "           223,  1731,   146, 16711,   103]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "[CLS] Con il termine interfluvio in geologia si indica la porzione [SEP]\n"
     ]
    }
   ],
   "source": [
    "example_text = '''Con il termine interfluvio in geologia si indica la porzione di superﬁcie più elevata\n",
    "                  che separa due valli ﬂuviali adiacenti, che può essere una cresta oppure un' area ampia,\n",
    "                  comunque non coinvolta dal movimento delle acque'''\n",
    "\n",
    "\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length = 15, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(bert_input['input_ids'])      # words to integer\n",
    "print(bert_input['token_type_ids']) # binary mask that identifies whether a token is in the first sentence (before [SEP]) or the second (after [SEP])\n",
    "print(bert_input['attention_mask']) # binary mask that identifies whether a token is a real word or just padding\n",
    "\n",
    "decoded_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mxtuOhzE6rTi",
   "metadata": {
    "id": "mxtuOhzE6rTi"
   },
   "source": [
    "  ## Oracle model using BERT\n",
    "For the oracle we decided to use and fine-tune bert in a regression task.\n",
    "The main idea is:\n",
    "\n",
    "*   given a sentence get the **'Bert input tokens**' and the **'attention mask**' from the BERT tokenizer above;\n",
    "*   pass the 'input tokens' and the 'attention mask' to the BERTOracle that returns a tensor that contains a list of configurations, one for each sentence.\n",
    "\n",
    "In this setting a configuration is a pair of numbers. For this reason we use MSE loss to create a **multi-ouptut regressor** task.\n",
    "\n",
    "One configuration is in the form (**ACTION, LABELS**) where for ACTION we have:\n",
    "\n",
    "* 100 for **LeftArc** action;\n",
    "* 0 for **RightArc** action;\n",
    "* -100 for **Shift** action.\n",
    "\n",
    "For the LABELS we have decided to order them in alphabetical order and convert them into consecutive numbers.\n",
    "The main idea is: \n",
    "\n",
    "the labels represent the relation between words.<br>\n",
    "In the used treebank there are many such relation that are very similar like *obj* and *iobj* so by ordering them and giving consecutive numbers we have that *obj* will be encoded, for instance, as 12 and *iobj* with 13. This means that, even if the oracle infere 13 instead of 12 we have that the prediction is not as wrong as if it will have predicte 50.<br>\n",
    "The main assumption is that closer numbers represent more similar relation.\n",
    "\n",
    "To perfrom the actual multi-output regression we used a simple linear layer that outputs this two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "KkXDGmBW-vFo",
   "metadata": {
    "id": "KkXDGmBW-vFo"
   },
   "outputs": [],
   "source": [
    "class BERTOracle(nn.Module):\n",
    "    def __init__(self, input_size, deprels, DROPOUT_RATE, MLP_SIZE_1, MLP_SIZE_2):\n",
    "      super(BERTOracle, self).__init__()\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "      self.bert = BertModel.from_pretrained(BERT_MODEL, output_hidden_states=True)\n",
    "      self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "      self.w1 = nn.Linear(input_size, MLP_SIZE_1) \n",
    "      self.activation = torch.nn.Tanh()\n",
    "      self.w2 = nn.Linear(MLP_SIZE_1, MLP_SIZE_2)\n",
    "      self.w3 = nn.Linear(MLP_SIZE_2, 2*len(deprels)+1) #for classification: we need 2*sizeof(label_set)+1\n",
    "      self.softmax = torch.nn.Softmax(dim=-1) #32xN_classes\n",
    "    \n",
    "    \"\"\"\n",
    "    We select an average of the 4 last hidden states in BERT as an embedding representation for each subtoken\n",
    "    \"\"\"\n",
    "    def get_embeddings(self, output):\n",
    "      layers = [-4, -3, -2, -1]\n",
    "      # Get all hidden states\n",
    "      states = output.hidden_states\n",
    "      # Stack and sum all requested layers\n",
    "      output = torch.stack([states[i] for i in layers])\n",
    "      return output.mean(dim=0)\n",
    "\n",
    "    \"\"\"\n",
    "    Substitute the word indices in the paths with the embeddings\n",
    "    Since the BERT tokenizer performs subword tokenization but we have to build configurations with the embedding of WORDS\n",
    "    \"\"\"\n",
    "    def substitute_embeddings(self, avg_of_last_states, tok_output, paths):\n",
    "      ffn_input = []\n",
    "      zero_tensor = torch.zeros(768, requires_grad=False).to(DEVICE)\n",
    "      for sentence_index in range(len(paths)): # one path for each sentence so len(paths) = number of sentences\n",
    "        for configuration in paths[sentence_index]: # take the sentence in number 'sentence_index' \n",
    "            new_tensor = torch.cat(\n",
    "              [\n",
    "                zero_tensor if configuration[0]==-1 else self.get_embedding_for_word_j(sentence_index, configuration[0], avg_of_last_states, tok_output), \n",
    "                zero_tensor if configuration[1]==-1 else self.get_embedding_for_word_j(sentence_index, configuration[1], avg_of_last_states, tok_output), \n",
    "                zero_tensor if configuration[2]==-1 else self.get_embedding_for_word_j(sentence_index, configuration[2], avg_of_last_states, tok_output)\n",
    "              ]\n",
    "            )\n",
    "            ffn_input.append(new_tensor)\n",
    "      ffn_input = torch.stack(ffn_input).to(DEVICE)\n",
    "      #print(\"DEBUG substitute_embeddings: ffn_input.size()\", ffn_input.size())\n",
    "      return ffn_input\n",
    "\n",
    "    \"\"\"\n",
    "    We choose as embedding for a full word the AVERAGE of the embedding of each of its subtokens\n",
    "    \"\"\"\n",
    "    def get_embedding_for_word_j(self, i, j, hidd_states, tok_output):\n",
    "        indices = np.where(np.array(tok_output.word_ids(i)) == j)[0] #retrieve indices of subtokens belonging to word j\n",
    "        #print(indices)\n",
    "        if len(indices) == 0:\n",
    "            print(\"DEBUG: tok_output.word_ids(i)) :\", tok_output.word_ids(i))\n",
    "            print(\"DEBUG: hidd_states[i].size() :\", hidd_states[i].size())\n",
    "            raise Exception(\"The requested word index (\"+str(j)+\") in sentence \"+str(i)+\" is not present\")\n",
    "        #print(torch.stack([hidd_states[i][k] for k in indices]).size()) #OK!!\n",
    "        return torch.stack([hidd_states[i][k] for k in indices]).mean(dim=0)\n",
    "    \n",
    "\n",
    "    def ffn_pass(self, configuration):\n",
    "      out = self.dropout(configuration)\n",
    "      out = self.w1(out)\n",
    "      out = self.activation(out)\n",
    "      out = self.dropout(out)\n",
    "      out = self.w2(out)\n",
    "      out = self.activation(out)\n",
    "      return self.w3(out)\n",
    "      #return self.softmax(out)\n",
    "\n",
    "    def forward(self, sentences, paths):\n",
    "      #Compute the BERT embeddings and retrieve them from the last hidden layer\n",
    "      enc = self.tokenizer(sentences, padding='max_length', max_length = TOKENIZER_MAX_LEN, \n",
    "                        truncation=True, return_tensors=\"pt\", is_split_into_words=True) \n",
    "      out = self.bert(enc['input_ids'].to(DEVICE), enc['attention_mask'].to(DEVICE))\n",
    "\n",
    "      avg_of_last_states = self.get_embeddings(out)\n",
    "      configurations = self.substitute_embeddings(avg_of_last_states, enc, paths)\n",
    "\n",
    "      #Pass through FFN\n",
    "      return self.ffn_pass(configurations)\n",
    "    ##################################################################################################################\n",
    "\n",
    "    def infere(self, sentences):\n",
    "        #print(\"DEBUG infere: sentences==\", sentences)\n",
    "        parsers = [ArcStandard(i, deprels) for i in sentences]\n",
    "    \n",
    "        enc = self.tokenizer(sentences, padding='max_length', max_length = TOKENIZER_MAX_LEN, \n",
    "                        truncation=True, return_tensors=\"pt\", is_split_into_words=True) \n",
    "        out = self.bert(enc['input_ids'].to(DEVICE), enc['attention_mask'].to(DEVICE))\n",
    "\n",
    "        h = self.get_embeddings(out)\n",
    "        #print(\"DEBUG infere: h.size()\", h.size()) #32x50x768 batch_size;TOKENIZER_MAX_LEN;len(bert_embedding)\n",
    "\n",
    "        while not self.parsed_all(parsers):\n",
    "            configurations = self.get_configurations(parsers)\n",
    "            #print(\"DEBUG infere: configurations\", configurations)\n",
    "            mlp_input = self.substitute_embeddings(h, enc, configurations) #32x(768*3)\n",
    "            mlp_out = self.ffn_pass(mlp_input)\n",
    "            self.parse_step(parsers, mlp_out, deprels)\n",
    "        \n",
    "        #print(\"DEBUG: parsers[13].arcs==\", parsers[13].arcs)\n",
    "        #print(\"DEBUG: parsers[13]==\", parsers[13])\n",
    "        #print(\"DEBUG infere: parsers[10].arcs ==\", parsers[10].arcs)\n",
    "        return [parser.arcs for parser in parsers] \n",
    "    \n",
    "    \"\"\"\n",
    "    This function was copied from the original file\n",
    "    \"\"\"\n",
    "    def get_configurations(self, parsers):\n",
    "        configurations = []\n",
    "\n",
    "        for parser in parsers:\n",
    "          if parser.is_tree_final():\n",
    "            conf = [-1, -1, -1]\n",
    "          else:\n",
    "            conf = [parser.stack[len(parser.stack)-2], parser.stack[len(parser.stack)-1]]\n",
    "            if len(parser.buffer) == 0:\n",
    "              conf.append(-1)\n",
    "            else:\n",
    "              conf.append(parser.buffer[0])  \n",
    "          configurations.append([conf])\n",
    "\n",
    "        return configurations\n",
    "\n",
    "    \"\"\"\n",
    "    This function was copied from the original file\n",
    "    \"\"\"\n",
    "    def parsed_all(self, parsers):\n",
    "        for parser in parsers:\n",
    "            if not parser.is_tree_final():\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    \"\"\"\n",
    "    Remember we use the convention\n",
    "    0 = shift\n",
    "    [1, len(deprels)] = left-arc\n",
    "    [len(deprels)+1, 2*len(deprels)+1] = right-arc\n",
    "    \n",
    "    This function was adapted from the original to remove padding from the buffer avoiding all edge cases\n",
    "    that complicated the original code.\n",
    "    \"\"\"\n",
    "    def parse_step(self, parsers, moves, labels):\n",
    "      moves_argm = moves.argmax(-1) #vector of argmaxes\n",
    "      #print(\"DEBUG parse_step: moves_argm.size()==\", moves_argm.size()) #size is 32, which is correct (one for each parser in the batch)\n",
    "      moves_second_argm = moves[:, 1:].argmax(-1) + 1 #needed when buffer is empty but argmax is 0 (shift). Contains the argmax for each sentence excluding index 0. \n",
    "                                                      #1 is added to account for slicing\n",
    "      \n",
    "      for i in range(len(parsers)):\n",
    "          kind_of_move = 0 if moves_argm[i] == 0 else (1 + int(moves_argm[i] / len(labels))) #0 if shift, 1 if leftarc, 2 is rightarc\n",
    "          label = (moves_argm[i] % len(labels)).item() #label of the arc, ignored if shift\n",
    "          #print(\"DEBUG parse_step: type(label)\")\n",
    "          #print(\"DEBUG: parse_step: label.size()\", label.size())\n",
    "\n",
    "          if parsers[i].is_tree_final():\n",
    "              continue\n",
    "          #print(\"DEBUG parse_step: configuration of the parser\", parsers[i].print_configuration())\n",
    "          if kind_of_move == 1: #predicted: leftarc\n",
    "            if parsers[i].stack[-2] != 0: #If the second element in the stack is not ROOT\n",
    "              parsers[i].left_arc(label)\n",
    "            else:\n",
    "              if len(parsers[i].buffer) > 0: #if buffer is not empty\n",
    "                parsers[i].shift()\n",
    "              else:\n",
    "                parsers[i].right_arc(label) #if buffer is empty: do rightarc\n",
    "\n",
    "          elif kind_of_move == 2: #predicted: rightarc\n",
    "            if parsers[i].stack[-2] == 0 and len(parsers[i].buffer)>0: #if there is ROOT in the 2nd position in the stack and buffer is not empty\n",
    "              parsers[i].shift\n",
    "            else:\n",
    "              parsers[i].right_arc(label)\n",
    "\n",
    "          elif moves_argm[i] == 0: #predicted: shift\n",
    "              if parsers[i].buffer: #if the buffer is not empty \n",
    "                  parsers[i].shift()\n",
    "              else: #in case buffer is empty\n",
    "                #note integer division\n",
    "                  if (moves_second_argm[i]//len(labels)) == 0:\n",
    "                      parsers[i].left_arc((moves_second_argm[i] % len(labels)).item())\n",
    "                  elif (moves_second_argm[i]//len(labels)) == 1:\n",
    "                      parsers[i].right_arc((moves_second_argm[i] % len(labels)).item())\n",
    "                  else:\n",
    "                      raise Exception(\"moves_second_argm not in range [1, 2*len(labels)]\")\n",
    "                      \n",
    "          else:\n",
    "              raise Exception(\"argmax not in range [0, 2*len(labels)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oUpbfnjJBTvv",
   "metadata": {
    "id": "oUpbfnjJBTvv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "QRk1Qh53F5EG",
   "metadata": {
    "id": "QRk1Qh53F5EG"
   },
   "source": [
    "## Training and evaluation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p3ePzCq4gJWx",
   "metadata": {
    "id": "p3ePzCq4gJWx"
   },
   "source": [
    "## Grid search for BERTOracle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4h-Y7lj8INBz",
   "metadata": {
    "id": "4h-Y7lj8INBz"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer):\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "  for batch in data_loader:\n",
    "    sentences, paths, moves, trees, labels = batch\n",
    "\n",
    "    outputs = model(sentences, paths)\n",
    "\n",
    "    # Compute the loss for each configurations for each sentence in parallel\n",
    "    tensor_moves = torch.tensor(sum(moves, [])).to(DEVICE)\n",
    "    loss = loss_fn(outputs, tensor_moves)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    #backpropagation routine\n",
    "    optimizer.zero_grad()                                             # initialize gradient to zeros\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  mean_loss = np.mean(losses)\n",
    "\n",
    "  return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "idw5no5rK0Ea",
   "metadata": {
    "id": "idw5no5rK0Ea"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, optimzier):\n",
    "  model = model.eval()                                                # dropout and batch_norm are not enabled\n",
    "\n",
    "  losses = []\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "      sentences, paths, moves, trees, labels = batch\n",
    "\n",
    "      outputs = model(sentences, paths)\n",
    "\n",
    "      # Compute the loss for each configurations for each sentence in parallel\n",
    "      tensor_moves = torch.tensor(sum(moves, [])).to(DEVICE)\n",
    "      loss = loss_fn(outputs, tensor_moves)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "      optimizer.zero_grad()                                             # initialize gradient to zeros\n",
    "\n",
    "  mean_loss = np.mean(losses)\n",
    "\n",
    "  return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4qhZPXfxLo67",
   "metadata": {
    "id": "4qhZPXfxLo67"
   },
   "source": [
    "## Grid search\n",
    "Training loop that for the given number of epoch preform the training step and the evaluation step for each sentence in the train_dataloader and val_dataloader.\n",
    "All the results are krept inside a dictionary of history.\n",
    "\n",
    "Grid search commented out to avoid disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "AaJXSRebF7EE",
   "metadata": {
    "id": "AaJXSRebF7EE"
   },
   "outputs": [],
   "source": [
    "lr = [5e-04]\n",
    "dr = [0.3]\n",
    "mlp_size = [150]\n",
    "\n",
    "import itertools\n",
    "hyperparams = itertools.product(lr, dr, mlp_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80a6892a-eeda-46a9-a77e-7eb2fa8384a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ngRlytTZLqnK",
   "metadata": {
    "id": "ngRlytTZLqnK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngrid_search_results = []\\nn = 13 #keep track of the number of grid search\\n\\nfor hp in hyperparams:\\n    n += 1\\n    LEARNING_RATE = hp[0]\\n    DROPOUT_RATE = hp[1]\\n    MLP_SIZE_2 = hp[2]\\n    SAVE_PATH = \"saved_checkpoint_grid_\"+str(n)+\".pt\"\\n    #Initialize the BERTOracle model\\n    model = BERTOracle(INPUT_SIZE, deprels, DROPOUT_RATE, MLP_SIZE_1, MLP_SIZE_2)\\n    model.to(DEVICE)\\n\\n    # Adam optimizer\\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\\n\\n    #Define the loss as cross entropy\\n    loss_fn = nn.CrossEntropyLoss().to(DEVICE)\\n\\n    import gc\\n    gc.collect()\\n\\n    import time\\n\\n    history = defaultdict(list) # store training and validation losses in a dictionary \\n    epoch_to_save = 5           # save model every 5 epochs\\n\\n    for epoch in range(EPOCHS):\\n      print(f\\'Grid search number {n}: LR={LEARNING_RATE}, DROPOUT={DROPOUT_RATE}, MLP_SIZE_2={MLP_SIZE_2}\\')\\n      print(f\\'Epoch {epoch + 1} / {EPOCHS}\\')\\n\\n      #Training step\\n      start_time = time.time()\\n      train_loss = train_epoch(model, train_lite_dataloader, loss_fn, optimizer)\\n      end_time = time.time()\\n      print(f\"Train loss {train_loss}\")\\n      print(f\"Time elapsed : {end_time-start_time} seconds\")\\n      #Evaluation step\\n      val_loss = eval_model(model, dev_dataloader, loss_fn, optimizer)\\n\\n      print(f\"Val loss {val_loss}\")\\n      print(\\'-\\'*10)\\n\\n      history[\\'train_loss\\'].append(train_loss)\\n\\n      history[\\'val_loss\\'].append(val_loss)\\n\\n      if epoch % epoch_to_save == 0:\\n        torch.save(model, SAVE_PATH)\\n        print(\"|MODEL SAVED|\")\\n        \\n      if epoch == EPOCHS-1:\\n        grid_search_results.append({\\'train_loss\\':train_loss, \\'val_loss\\':val_loss})\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "grid_search_results = []\n",
    "n = 13 #keep track of the number of grid search\n",
    "\n",
    "for hp in hyperparams:\n",
    "    n += 1\n",
    "    LEARNING_RATE = hp[0]\n",
    "    DROPOUT_RATE = hp[1]\n",
    "    MLP_SIZE_2 = hp[2]\n",
    "    SAVE_PATH = \"saved_checkpoint_grid_\"+str(n)+\".pt\"\n",
    "    #Initialize the BERTOracle model\n",
    "    model = BERTOracle(INPUT_SIZE, deprels, DROPOUT_RATE, MLP_SIZE_1, MLP_SIZE_2)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    #Define the loss as cross entropy\n",
    "    loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "    import time\n",
    "\n",
    "    history = defaultdict(list) # store training and validation losses in a dictionary \n",
    "    epoch_to_save = 5           # save model every 5 epochs\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "      print(f'Grid search number {n}: LR={LEARNING_RATE}, DROPOUT={DROPOUT_RATE}, MLP_SIZE_2={MLP_SIZE_2}')\n",
    "      print(f'Epoch {epoch + 1} / {EPOCHS}')\n",
    "\n",
    "      #Training step\n",
    "      start_time = time.time()\n",
    "      train_loss = train_epoch(model, train_lite_dataloader, loss_fn, optimizer)\n",
    "      end_time = time.time()\n",
    "      print(f\"Train loss {train_loss}\")\n",
    "      print(f\"Time elapsed : {end_time-start_time} seconds\")\n",
    "      #Evaluation step\n",
    "      val_loss = eval_model(model, dev_dataloader, loss_fn, optimizer)\n",
    "\n",
    "      print(f\"Val loss {val_loss}\")\n",
    "      print('-'*10)\n",
    "\n",
    "      history['train_loss'].append(train_loss)\n",
    "\n",
    "      history['val_loss'].append(val_loss)\n",
    "\n",
    "      if epoch % epoch_to_save == 0:\n",
    "        torch.save(model, SAVE_PATH)\n",
    "        print(\"|MODEL SAVED|\")\n",
    "        \n",
    "      if epoch == EPOCHS-1:\n",
    "        grid_search_results.append({'train_loss':train_loss, 'val_loss':val_loss})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "LkQh-VVvZcKb",
   "metadata": {
    "id": "LkQh-VVvZcKb",
    "outputId": "d7c950f4-99ba-4ff4-c216-30bc0c4bf281"
   },
   "outputs": [],
   "source": [
    "#grid_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ed53f-58d5-4f1b-9bc8-b0edcbf34189",
   "metadata": {},
   "source": [
    "## Training on optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "891941dc-214f-4131-b1bd-d479ad0013e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR=0.0001, DROPOUT=0.1, MLP_SIZE_2=300\n",
      "Epoch 1 / 5\n",
      "Train loss 1.5189408444343728\n",
      "Time elapsed : 843.9847373962402 seconds\n",
      "Val loss 0.5122224357393053\n",
      "----------\n",
      "|MODEL SAVED|\n",
      "LR=0.0001, DROPOUT=0.1, MLP_SIZE_2=300\n",
      "Epoch 2 / 5\n",
      "Train loss 0.3418819362971377\n",
      "Time elapsed : 843.7815444469452 seconds\n",
      "Val loss 0.2207983268631829\n",
      "----------\n",
      "|MODEL SAVED|\n",
      "LR=0.0001, DROPOUT=0.1, MLP_SIZE_2=300\n",
      "Epoch 3 / 5\n",
      "Train loss 0.1678984811569148\n",
      "Time elapsed : 844.8818018436432 seconds\n",
      "Val loss 0.17463983429802787\n",
      "----------\n",
      "|MODEL SAVED|\n",
      "LR=0.0001, DROPOUT=0.1, MLP_SIZE_2=300\n",
      "Epoch 4 / 5\n",
      "Train loss 0.10714307435332461\n",
      "Time elapsed : 847.8088767528534 seconds\n",
      "Val loss 0.148846252510945\n",
      "----------\n",
      "|MODEL SAVED|\n",
      "LR=0.0001, DROPOUT=0.1, MLP_SIZE_2=300\n",
      "Epoch 5 / 5\n",
      "Train loss 0.07510739346926516\n",
      "Time elapsed : 846.1845502853394 seconds\n",
      "Val loss 0.15122611737913555\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-04\n",
    "MLP_SIZE_2 = 300\n",
    "DROPOUT_RATE = 0.1\n",
    "SAVE_PATH = \"final_model_checkpoint.pt\"\n",
    "\n",
    "model = BERTOracle(INPUT_SIZE, deprels, DROPOUT_RATE, MLP_SIZE_1, MLP_SIZE_2)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Define the loss as cross entropy\n",
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import time\n",
    "\n",
    "history = defaultdict(list) # store training and validation losses in a dictionary \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  print(f'LR={LEARNING_RATE}, DROPOUT={DROPOUT_RATE}, MLP_SIZE_2={MLP_SIZE_2}')\n",
    "  print(f'Epoch {epoch + 1} / {EPOCHS}')\n",
    "\n",
    "  #Training step\n",
    "  start_time = time.time()\n",
    "  train_loss = train_epoch(model, train_dataloader, loss_fn, optimizer)\n",
    "  end_time = time.time()\n",
    "  print(f\"Train loss {train_loss}\")\n",
    "  print(f\"Time elapsed : {end_time-start_time} seconds\")\n",
    "  #Evaluation step\n",
    "  val_loss = eval_model(model, dev_dataloader, loss_fn, optimizer)\n",
    "\n",
    "  print(f\"Val loss {val_loss}\")\n",
    "  print('-'*10)\n",
    "\n",
    "  history['train_loss'].append(train_loss)\n",
    "\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if len(history['val_loss'])==1 or history['val_loss'][-1] < min(history['val_loss'][:-1]): #implement some kind of early stopping\n",
    "    torch.save(model, SAVE_PATH)\n",
    "    print(\"|MODEL SAVED|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23173fb7-fc03-4e5d-9f36-c6b11b2b66fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.148846252510945\n"
     ]
    }
   ],
   "source": [
    "print(min(history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Om8sss6qfK-L",
   "metadata": {
    "id": "Om8sss6qfK-L"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cb5cbce",
   "metadata": {
    "id": "2cb5cbce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTOracle(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32102, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (w1): Linear(in_features=2304, out_features=500, bias=True)\n",
       "  (activation): Tanh()\n",
       "  (w2): Linear(in_features=500, out_features=300, bias=True)\n",
       "  (w3): Linear(in_features=300, out_features=91, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the saved model's weights\n",
    "old_path = \"../gridsearch_new/final/final_model_epoch_1.pt\"\n",
    "model = torch.load(SAVE_PATH)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0a01376-3579-469e-b907-40e686da5051",
   "metadata": {
    "id": "a0a01376-3579-469e-b907-40e686da5051"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions were adapted from the ones in the original notebook\n",
    "preds is a list of *couples*\n",
    "\n",
    "evaluate() returns a couple of values (UAS, LAS)\n",
    "\"\"\"\n",
    "def evaluate(gold, preds): \n",
    "  total = 0\n",
    "  correct = 0\n",
    "\n",
    "  for g, p in zip(gold, preds):\n",
    "    for i in range(1,len(g)):\n",
    "      total += 1\n",
    "      if g[i] == p[i]:\n",
    "        correct += 1\n",
    "  return correct/total\n",
    "\n",
    "def validation(model, dataloader):\n",
    "  model.eval()\n",
    "  tree_preds = []\n",
    "  label_preds = []\n",
    "  tree_gold = []\n",
    "  label_gold = []\n",
    "\n",
    "  for batch in dataloader:\n",
    "    sentences, paths, moves, trees, labels = batch\n",
    "    #trees is a list of lists\n",
    "    with torch.no_grad():\n",
    "        pred = model.infere(sentences) #now pred is a list of lists of (move, label) pairs (1 lists for each sentence) \n",
    "        for lst in pred:\n",
    "            tree_preds.append([x[0] for x in lst])\n",
    "            label_preds.append([x[1] for x in lst])\n",
    "        tree_gold += trees\n",
    "        label_gold += labels\n",
    "    \n",
    "  return (evaluate(tree_gold, tree_preds), evaluate(label_gold, label_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "JIWowQo7wcjb",
   "metadata": {
    "id": "JIWowQo7wcjb",
    "outputId": "d0deae16-0d08-4ef8-f7df-d9501dda378d"
   },
   "outputs": [],
   "source": [
    "uas, las = validation(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "AhGFcm1IXUIp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhGFcm1IXUIp",
    "outputId": "c491f3d0-6beb-466d-a988-419aeb718b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9526222447428426\n",
      "0.003040283759817583\n"
     ]
    }
   ],
   "source": [
    "print(uas)\n",
    "print(las)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "C_88w3bsXgqK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_88w3bsXgqK",
    "outputId": "1e8e40e1-038a-43d8-f006-c4a8e327c432"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027489232328350648"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I892o0ixXhyJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I892o0ixXhyJ",
    "outputId": "075a3143-51f7-4d53-91e1-ea341d3406f4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SmmdXqS2YUFW",
   "metadata": {
    "id": "SmmdXqS2YUFW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
    "747b671a-fd4b-4cbd-a602-a9a25da5e4b2",
    "5a1b7b56-5928-4ca4-9427-0a5edd150ecd",
    "05840970-630c-4152-bdc6-2c25e81fefff",
    "mxtuOhzE6rTi",
    "p3ePzCq4gJWx"
   ],
   "name": "our_dep_parser.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "021171af678f45b4b5438492cd2dcf0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b60725bbf7014763a6d8c3c0d9be9a20",
      "placeholder": "​",
      "style": "IPY_MODEL_42ae41c6fe3b4b02add2a3e0204cff5e",
      "value": " 59.0/59.0 [00:00&lt;00:00, 1.44kB/s]"
     }
    },
    "032ad69c29f84f57ab22ed99e0aec44d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4290084e2c564e94bc7604d8c2803f39",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a29c036922204cf1948efebc71ff742e",
      "value": 433
     }
    },
    "044dba1986d843f1abed44d8489462b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04fd7433bcee4d6fafc43bbf648b7e74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d6ce7c063a74780913dd0e00b7ff668": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dc7e3c838394c1c9a36cab9e68915c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11864f5edce54fe4aca12957bcfb2744": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f7e490b42644809ab354ece8f39039d",
      "placeholder": "​",
      "style": "IPY_MODEL_162a7f46b3754069b8c7449ab0e14ce5",
      "value": " 516/516 [00:00&lt;00:00, 2142.82ex/s]"
     }
    },
    "162a7f46b3754069b8c7449ab0e14ce5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "163f4e024ca04d0691d4ad7d1f06c11d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "177d6115f64946949f194af9369dc6c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_044dba1986d843f1abed44d8489462b4",
      "max": 235127,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4aec3392e3664f26a39f38a4c5181de9",
      "value": 235127
     }
    },
    "200e2ca9e3094422b0798395f908bf72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73528e1820e847a6898d3ff20a32323f",
      "placeholder": "​",
      "style": "IPY_MODEL_0dc7e3c838394c1c9a36cab9e68915c2",
      "value": " 433/433 [00:00&lt;00:00, 11.7kB/s]"
     }
    },
    "24cf7f369c0444efa4daa98863fe952f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d38df55c6b744e28f265ca1644c78ac",
      "placeholder": "​",
      "style": "IPY_MODEL_4f54fc2cce884678a636d24948127381",
      "value": "100%"
     }
    },
    "26d33e5772a64f8fa3aca53d7c111d29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6bed0ac748c4da6a3b2a6aca87d255a",
      "max": 1224,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75c20f16616e417bbf21055b36cb3f67",
      "value": 1224
     }
    },
    "2b80b5aaa02040928f7411a2e77d57ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_787707d041474b6aad5901020ec386de",
      "placeholder": "​",
      "style": "IPY_MODEL_99de82f14ce1412f9737f3d12bea7a42",
      "value": "100%"
     }
    },
    "2b8d762966f64f25bd41c40bf7b1e0b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dfdbd6c2f7724bb2a1c0b3fd95fcdadf",
       "IPY_MODEL_26d33e5772a64f8fa3aca53d7c111d29",
       "IPY_MODEL_88fbd16c7ff2487e9ec01594838ab426"
      ],
      "layout": "IPY_MODEL_5359e14052f54381a58d8f846629f6cf"
     }
    },
    "2c31a4d2e87a4e90a4532e4965549e8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb1f53e8d5c448699865afdef2e6468e",
       "IPY_MODEL_464381f9c4104593b73252f5251bc0b3",
       "IPY_MODEL_021171af678f45b4b5438492cd2dcf0a"
      ],
      "layout": "IPY_MODEL_f3a58e57364c4a0d879579995c0f2a1f"
     }
    },
    "2edde41cfe23483baae27aeda2c22ec7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4290084e2c564e94bc7604d8c2803f39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42ae41c6fe3b4b02add2a3e0204cff5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "464381f9c4104593b73252f5251bc0b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d6ce7c063a74780913dd0e00b7ff668",
      "max": 59,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e50de337c5c64dc1ae64f90c7f899016",
      "value": 59
     }
    },
    "46cfb0de504344fabbe3a47b799d5cab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46ff0f37a8184ff7a3e21d9163b42d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4aec3392e3664f26a39f38a4c5181de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e3c0567edec4b78b62bc8cde063ee9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a56d09474e0247c2b68ed18345ecd8e4",
      "max": 12090,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5268d9d9519544c6803d8d0fd97e1088",
      "value": 12090
     }
    },
    "4f54fc2cce884678a636d24948127381": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5268d9d9519544c6803d8d0fd97e1088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5359e14052f54381a58d8f846629f6cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2adf50ddbc41b68c6573957971e4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b5405d078c84e2ea21f1ca8e719b698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8a9e6fff8a34cd2ba8420901c1344f7",
      "placeholder": "​",
      "style": "IPY_MODEL_eb17c1f76c394a5cac764a415cedddb5",
      "value": " 12090/12090 [00:06&lt;00:00, 1116.40ex/s]"
     }
    },
    "5d38df55c6b744e28f265ca1644c78ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "671b43f0fb974bf3ad3c6317223b1fa7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ba992b8f6f8482e8e9f5801354d1522": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_671b43f0fb974bf3ad3c6317223b1fa7",
      "max": 439,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_abaace07c6f24ce3b360b6b3bf13dd7b",
      "value": 439
     }
    },
    "6f7e490b42644809ab354ece8f39039d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73528e1820e847a6898d3ff20a32323f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c20f16616e417bbf21055b36cb3f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "787707d041474b6aad5901020ec386de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "789338215eac4ac0bb9c56fd3c6111ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bb4712d68034260be29924cf24969c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d7f0bb756b2433baa7eb67b2c50798f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d851215506e4bbd889e6d81579a72e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8742c42cf034968a2657a069600bd49",
      "placeholder": "​",
      "style": "IPY_MODEL_c18e286a91a44e4989f14cd0c5cdf6d4",
      "value": "100%"
     }
    },
    "83f5c41a0d8f4f51b6c3c415765db15f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8882eeaa91df40408c0f5c9eec56490a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88fbd16c7ff2487e9ec01594838ab426": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3bbd11ad7a94f6183b5e06d002e76e3",
      "placeholder": "​",
      "style": "IPY_MODEL_5a2adf50ddbc41b68c6573957971e4f4",
      "value": " 1224/1224 [00:00&lt;00:00, 2687.85ex/s]"
     }
    },
    "8c12944a4db94cb4ac3c8e3276c7de70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99de82f14ce1412f9737f3d12bea7a42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a3abd55570d45dead562ff14cd0b7c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e661ec955b44e14ace7bc60478ffe16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a29c036922204cf1948efebc71ff742e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a56d09474e0247c2b68ed18345ecd8e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6a4c55a4908462faa12c529b8c5f5fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abaace07c6f24ce3b360b6b3bf13dd7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b007865b76de4b4187fa9adfe8bb50de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cdc57b438f1c441f9e44ad73e9020a8a",
       "IPY_MODEL_177d6115f64946949f194af9369dc6c4",
       "IPY_MODEL_c8ab0d73e9824a24ada934e611af163b"
      ],
      "layout": "IPY_MODEL_2edde41cfe23483baae27aeda2c22ec7"
     }
    },
    "b52fcf0461d946eb902793a7c513c467": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b60725bbf7014763a6d8c3c0d9be9a20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba63d8a18d7742fda3f78419238a0841": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d851215506e4bbd889e6d81579a72e1",
       "IPY_MODEL_6ba992b8f6f8482e8e9f5801354d1522",
       "IPY_MODEL_c7c9a05b9bb640a591c5b6e55c51b5fd"
      ],
      "layout": "IPY_MODEL_e7a9623f60454f9e9f01d861c8dc65d4"
     }
    },
    "c00f960bc6ca47ab9efa330dc76e415e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c09a422c3bde4dfda823a95b41f28d00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c18e286a91a44e4989f14cd0c5cdf6d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1b6f79804194108a6436f19c61f447c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a3abd55570d45dead562ff14cd0b7c1",
      "placeholder": "​",
      "style": "IPY_MODEL_789338215eac4ac0bb9c56fd3c6111ce",
      "value": "Downloading: 100%"
     }
    },
    "c6bed0ac748c4da6a3b2a6aca87d255a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7c9a05b9bb640a591c5b6e55c51b5fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d7f0bb756b2433baa7eb67b2c50798f",
      "placeholder": "​",
      "style": "IPY_MODEL_46ff0f37a8184ff7a3e21d9163b42d5e",
      "value": " 439/439 [00:00&lt;00:00, 1415.43ex/s]"
     }
    },
    "c8ab0d73e9824a24ada934e611af163b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83f5c41a0d8f4f51b6c3c415765db15f",
      "placeholder": "​",
      "style": "IPY_MODEL_9e661ec955b44e14ace7bc60478ffe16",
      "value": " 230k/230k [00:00&lt;00:00, 4.44MB/s]"
     }
    },
    "cdc57b438f1c441f9e44ad73e9020a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e25d49a1e840452e8bd21025709d81dd",
      "placeholder": "​",
      "style": "IPY_MODEL_c09a422c3bde4dfda823a95b41f28d00",
      "value": "Downloading: 100%"
     }
    },
    "d87aa740108a48e6a7fba60860aa966a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c1b6f79804194108a6436f19c61f447c",
       "IPY_MODEL_032ad69c29f84f57ab22ed99e0aec44d",
       "IPY_MODEL_200e2ca9e3094422b0798395f908bf72"
      ],
      "layout": "IPY_MODEL_8882eeaa91df40408c0f5c9eec56490a"
     }
    },
    "dfdbd6c2f7724bb2a1c0b3fd95fcdadf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b52fcf0461d946eb902793a7c513c467",
      "placeholder": "​",
      "style": "IPY_MODEL_c00f960bc6ca47ab9efa330dc76e415e",
      "value": "100%"
     }
    },
    "e25d49a1e840452e8bd21025709d81dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3bbd11ad7a94f6183b5e06d002e76e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e444112e2aea49f3b41aa19e3a78b687": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_163f4e024ca04d0691d4ad7d1f06c11d",
      "max": 516,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6a4c55a4908462faa12c529b8c5f5fa",
      "value": 516
     }
    },
    "e50de337c5c64dc1ae64f90c7f899016": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7a9623f60454f9e9f01d861c8dc65d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8742c42cf034968a2657a069600bd49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8906ef310e545009d9eda77e7f84950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_24cf7f369c0444efa4daa98863fe952f",
       "IPY_MODEL_4e3c0567edec4b78b62bc8cde063ee9e",
       "IPY_MODEL_5b5405d078c84e2ea21f1ca8e719b698"
      ],
      "layout": "IPY_MODEL_7bb4712d68034260be29924cf24969c0"
     }
    },
    "e8a9e6fff8a34cd2ba8420901c1344f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb17c1f76c394a5cac764a415cedddb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee91fa8b40bf4c018eb4e3a01be00589": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b80b5aaa02040928f7411a2e77d57ae",
       "IPY_MODEL_e444112e2aea49f3b41aa19e3a78b687",
       "IPY_MODEL_11864f5edce54fe4aca12957bcfb2744"
      ],
      "layout": "IPY_MODEL_8c12944a4db94cb4ac3c8e3276c7de70"
     }
    },
    "f3a58e57364c4a0d879579995c0f2a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb1f53e8d5c448699865afdef2e6468e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46cfb0de504344fabbe3a47b799d5cab",
      "placeholder": "​",
      "style": "IPY_MODEL_04fd7433bcee4d6fafc43bbf648b7e74",
      "value": "Downloading: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
