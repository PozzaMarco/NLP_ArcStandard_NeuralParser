{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c041f954-42d3-44e6-b2c2-281d579e61e6",
      "metadata": {
        "id": "c041f954-42d3-44e6-b2c2-281d579e61e6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f",
      "metadata": {
        "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d704ceb0",
      "metadata": {
        "id": "d704ceb0"
      },
      "source": [
        "# Bert model and other hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cad5b81d",
      "metadata": {
        "id": "cad5b81d"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BERT_MODEL = 'dbmdz/bert-base-italian-xxl-cased'\n",
        "DROPOUT_RATE = 0.2\n",
        "MLP_SIZE = 300\n",
        "INPUT_SIZE = 3*768\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 30\n",
        "SAVE_PATH = \"saved_checkpoint.pt\"\n",
        "TOKENIZER_MAX_LEN = 150\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
      "metadata": {
        "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5"
      },
      "source": [
        "# Arc-standard\n",
        "\n",
        "Recall that a **configuration** of the arc-standard parser is a triple of the form $( \\sigma, \\beta, A)$\n",
        "where:\n",
        "\n",
        "* $\\sigma$ is the stack;\n",
        "* $\\beta$ is the input buffer;\n",
        "* $A$ is a set of arcs constructed so far.\n",
        "\n",
        "We write $\\sigma_i$, $i \\geq 1$, for the $i$-th token in the stack; we also write $\\beta_i$, $i \\geq 1$, for the $i$-th token in the buffer. \n",
        "\n",
        "The parser can perform three types of **actions** (transitions):\n",
        "\n",
        "* **shift**, which removes $\\beta_1$ from the buffer and pushes it into the stack;\n",
        "* **left-arc**, which creates the arc $(\\sigma_1 \\rightarrow \\sigma_2)$, and removes $\\sigma_2$ from the stack;\n",
        "* **right-arc**, which creates the arc $(\\sigma_2 \\rightarrow \\sigma_1)$, and removes $\\sigma_1$ from the stack.\n",
        "\n",
        "Let $w = w_0 w_1 \\cdots w_{n}$ be the input sentence, with $w_0$ the special symbol `<ROOT>`.\n",
        "Stack and buffer are implemented as lists of integers, where `j` represents word $w_j$.  Top-most stack token is at the right-end of the list; first buffer token is at the left-end of the list. \n",
        "Set $A$ is implemented as an array `arcs` of size $n+1$ such that if arc $(w_i \\rightarrow w_j)$ is in $A$ then `arcs[j]=i`, and if $w_j$ is still missing its head node in the tree under construction, then `arcs[j]=-1`. We always have `arcs[0]=-1`.  We use this representation also for complete dependency trees.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf",
      "metadata": {
        "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf"
      },
      "outputs": [],
      "source": [
        "import orig #file orig.py in the same foldr contains original class and function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7",
      "metadata": {
        "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7"
      },
      "outputs": [],
      "source": [
        "class ArcStandard (orig.ArcStandard):\n",
        "    def __init__(self, sentence, label_set):\n",
        "        self.sentence = sentence\n",
        "        self.buffer = [i for i in range(len(self.sentence))]\n",
        "        self.stack = []\n",
        "        self.arcs = [(-1, -1) for _ in range(len(self.sentence))]# head - relation converted to int\n",
        "\n",
        "        self.label_set = {y:x for x,y in label_set.items()} #for future reference (printing)\n",
        "        # three shift moves to initialize the stack\n",
        "        self.shift()\n",
        "        self.shift()\n",
        "        if len(self.sentence) > 2:\n",
        "            self.shift()\n",
        "\n",
        "    def left_arc(self, deprel):\n",
        "        o1 = self.stack.pop()\n",
        "        o2 = self.stack.pop()\n",
        "        self.arcs[o2] = (o1, deprel) #added deprel\n",
        "        self.stack.append(o1)\n",
        "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
        "            self.shift()\n",
        "\n",
        "    def right_arc(self, deprel):\n",
        "        o1 = self.stack.pop()\n",
        "        o2 = self.stack.pop()\n",
        "        self.arcs[o1] = (o2, deprel) #added deprel\n",
        "        self.stack.append(o2)\n",
        "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
        "            self.shift()\n",
        "\n",
        "    def print_configuration(self):\n",
        "        s = [self.sentence[i] for i in self.stack]\n",
        "        b = [self.sentence[i] for i in self.buffer]\n",
        "        print(\"STACK: \", s, \"BUFFER: \", b) #added indication of stack and buffer\n",
        "        print([(x[0], self.label_set[x[1]]) for x in self.arcs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1d836502-bba0-4f49-9c39-39a916ed270c",
      "metadata": {
        "id": "1d836502-bba0-4f49-9c39-39a916ed270c"
      },
      "outputs": [],
      "source": [
        "class Oracle (orig.Oracle):\n",
        "    def __init__(self, parser, gold_tree, gold_labels):\n",
        "        self.parser = parser\n",
        "        self.gold = gold_tree\n",
        "        self.labels = gold_labels #must be integers; see below\n",
        "\n",
        "    def get_gold_label(self):\n",
        "        if(self.is_left_arc_gold()):\n",
        "            o2 = self.parser.stack[len(self.parser.stack)-2]\n",
        "            return self.labels[o2]\n",
        "        elif(self.is_right_arc_gold()):\n",
        "            o1 = self.parser.stack[len(self.parser.stack)-1]\n",
        "            return self.labels[o1]\n",
        "        else:\n",
        "            raise Exception(\"Action SHIFT does not produce a labeled dependency\")\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2",
      "metadata": {
        "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2"
      },
      "source": [
        "## Functions to simplify the processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374",
      "metadata": {
        "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "dataset should be a Dataset object from HuggingFace\n",
        "Return a dictionary where arc labels are associate to integer values.\n",
        "Label '_' is removed (used for composite tokens)\n",
        "Labels are sorted in alphabetical order because MSE in the neural network will penalize less classes that are \"close\".\n",
        "<ROOT> label is given value -1 (label of the <ROOT> node).\n",
        "\"\"\"\n",
        "def create_deprel_dict(dataset):\n",
        "    labels = set()\n",
        "    for x in dataset['deprel']:\n",
        "        for elem in x:\n",
        "            if(elem != '_'):\n",
        "                labels.add(elem)\n",
        "    labels = sorted(list(labels))\n",
        "    ret = {labels[i]:i for i in range(len(labels))}\n",
        "    ret.update({\"None\":-1})\n",
        "    return ret\n",
        "\n",
        "\"\"\"\n",
        "Return (sanitized_tokens, gold tree, gold labels) for a sentence in the dataset, assuming gold tree is in a column labeled 'head' and labels in a column labeled 'deprel'.\n",
        "Both token indices and labels are converted to integer (in the latter case, according to deprel_dict).\n",
        "Sanitized tokens is a tokenlist with removal of composite tokens.\n",
        "\"\"\"\n",
        "def create_gold(sentence, deprel_dict):\n",
        "    sanitized = ['<ROOT>']\n",
        "    gold_tree = [-1]\n",
        "    gold_labels = [-1]\n",
        "    for i in range(len(sentence['tokens'])):\n",
        "        if(sentence['head'][i] != 'None') and sentence['deprel'][i] in deprel_dict: #second condition is to avoid unseen or wrong labels\n",
        "            sanitized.append(sentence['tokens'][i])\n",
        "            gold_tree.append(int(sentence['head'][i]))\n",
        "            gold_labels.append(deprel_dict[sentence['deprel'][i]])\n",
        "    \n",
        "    return sanitized, gold_tree, gold_labels "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd",
      "metadata": {
        "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd"
      },
      "source": [
        "## Testing parser and oracle..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "21bcbd5e-b121-4cef-992f-f22df16e4315",
      "metadata": {
        "id": "21bcbd5e-b121-4cef-992f-f22df16e4315"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9269d170-abea-4671-b795-a9026fc3e46a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9269d170-abea-4671-b795-a9026fc3e46a",
        "outputId": "6d810adb-c256-4fd2-d594-d2e4a0309859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<ROOT>', 'Inconsueto', 'allarme', 'a', 'la', 'Tate', 'Gallery', ':']\n",
            "[-1, 2, 0, 5, 5, 2, 5, 2]\n",
            "[-1, 4, 41, 8, 17, 31, 28, 40]\n"
          ]
        }
      ],
      "source": [
        "deprels = create_deprel_dict(train_dataset)\n",
        "sentence = train_dataset[3]\n",
        "\n",
        "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
        "\n",
        "print(tokens)\n",
        "print(gold_tree)\n",
        "print(gold_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
        "outputId": "2167bab1-da56-455b-84cb-06b8c5fb4251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STACK:  ['<ROOT>', 'Inconsueto', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
            "[(-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n"
          ]
        }
      ],
      "source": [
        "parser = ArcStandard(tokens, deprels)\n",
        "oracle = Oracle(parser, gold_tree, gold_labels)\n",
        "\n",
        "parser.print_configuration()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
        "outputId": "5774c4c3-ad06-494a-de39-82d5daca3036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STACK:  ['<ROOT>', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'a'] BUFFER:  ['la', 'Tate', 'Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'a', 'la'] BUFFER:  ['Tate', 'Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'a', 'la', 'Tate'] BUFFER:  ['Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'a', 'Tate'] BUFFER:  ['Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  ['Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'Tate', 'Gallery'] BUFFER:  [':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  [':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (5, 'flat:name'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme'] BUFFER:  [':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', ':'] BUFFER:  []\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme'] BUFFER:  []\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n",
            "STACK:  ['<ROOT>'] BUFFER:  []\n",
            "[(-1, 'None'), (2, 'amod'), (0, 'root'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n"
          ]
        }
      ],
      "source": [
        "while not parser.is_tree_final():  # transition precedence implemented here\n",
        "    if oracle.is_shift_gold():  \n",
        "        parser.shift()\n",
        "    elif oracle.is_left_arc_gold():\n",
        "        parser.left_arc(oracle.get_gold_label())\n",
        "    elif oracle.is_right_arc_gold():\n",
        "        parser.right_arc(oracle.get_gold_label())\n",
        "    \n",
        "    parser.print_configuration()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05840970-630c-4152-bdc6-2c25e81fefff",
      "metadata": {
        "id": "05840970-630c-4152-bdc6-2c25e81fefff"
      },
      "source": [
        "## Testing the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68",
        "outputId": "3fb4eab0-6076-449f-8587-ae6bd311b3fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remember to call orig.is_projective() to check for projectivity!!\n",
        "sentence = train_dataset[10]\n",
        "deprels = create_deprel_dict(train_dataset)\n",
        "\n",
        "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
        "orig.is_projective(gold_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6464ec95-43b7-457a-b764-8ce310c34207",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6464ec95-43b7-457a-b764-8ce310c34207",
        "outputId": "58e9c8aa-f917-46a6-b1ca-653d745eec44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "non projective:  167\n",
            "correct:  282533\n",
            "wrong:  0\n"
          ]
        }
      ],
      "source": [
        "### NOTE: THIS CELL WAS COPIED WITH FEW MODIFICATIONS FROM THE ORIGINAL FILE\n",
        "\n",
        "# oracle test: run the parser guided by the oracle on the entire training set \n",
        "\n",
        "non_projective = 0\n",
        "correct = 0\n",
        "wrong = 0\n",
        "\n",
        "deprels = create_deprel_dict(train_dataset)\n",
        "\n",
        "for sample in train_dataset:\n",
        "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
        "\n",
        "    if not orig.is_projective(gold_tree):\n",
        "        non_projective += 1\n",
        "        continue\n",
        "\n",
        "    parser = ArcStandard(tokens, deprels)\n",
        "    oracle = Oracle(parser, gold_tree, gold_labels)\n",
        "\n",
        "    while not parser.is_tree_final():\n",
        "        if oracle.is_left_arc_gold(): \n",
        "            parser.left_arc(oracle.get_gold_label())\n",
        "        elif oracle.is_right_arc_gold():\n",
        "            parser.right_arc(oracle.get_gold_label())\n",
        "        elif oracle.is_shift_gold(): \n",
        "            parser.shift()\n",
        "\n",
        "    for j in range(len(gold_tree)):  # comparing heads from parser and gold for actual sample\n",
        "        if gold_tree[j] == parser.arcs[j][0] and gold_labels[j] == parser.arcs[j][1]: \n",
        "            correct += 1\n",
        "        else:\n",
        "            wrong += 1\n",
        "\n",
        "print(\"non projective: \", non_projective)\n",
        "print(\"correct: \", correct)\n",
        "print(\"wrong: \", wrong)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
      "metadata": {
        "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
        "outputId": "f87fd0da-15df-4d67-829e-21be6b0ee436"
      },
      "source": [
        "## Creating samples for the neural oracle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "453c9ca5-9c30-4813-bf82-2555efaeac12",
      "metadata": {
        "id": "453c9ca5-9c30-4813-bf82-2555efaeac12"
      },
      "outputs": [],
      "source": [
        "# Modified from the original\n",
        "\"\"\"\n",
        "This function processes a single sample, which is one sentence provided as an element of a Dataset object and returns \n",
        "    enc_sentence : a list of integers encoding the phrase #???? is this even correct for BERT???\n",
        "    gold_path : a list of configurations\n",
        "    gold_moves : a list of (move, label)\n",
        "\"\"\"\n",
        "def process_sample(sample, emb_dictionary, deprels, get_gold_path = False): #emb_dictionary and deprels are dictionaries of words and of dependency relations\n",
        "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
        "    #print(\"DEBUG:\", tokens)\n",
        "    enc_sentence = [emb_dictionary[word] if word in emb_dictionary else emb_dictionary[\"<unk>\"] for word in tokens]\n",
        "    #print(\"DEBUG:\", enc_sentence)\n",
        "    \n",
        "    # gold_path and gold_moves are parallel arrays whose elements refer to parsing steps\n",
        "    gold_path = []   # record two topmost stack token and first buffer token for current step\n",
        "    gold_moves = []  # oracle (canonical) move for current step: 100 is left, 0 right, -100 shift #motivations provided above TODO\n",
        "\n",
        "    if get_gold_path:  # only for training\n",
        "        parser = ArcStandard(enc_sentence, deprels)\n",
        "        oracle = Oracle(parser, gold_tree, gold_labels)\n",
        "\n",
        "        while not parser.is_tree_final():\n",
        "            configuration = [parser.stack[len(parser.stack)-2], parser.stack[len(parser.stack)-1]]\n",
        "            if len(parser.buffer) == 0:\n",
        "                configuration.append(-1)\n",
        "            else:\n",
        "                configuration.append(parser.buffer[0])\n",
        "\n",
        "            gold_path.append(configuration)\n",
        "            \n",
        "            if oracle.is_left_arc_gold():\n",
        "                label_code = oracle.get_gold_label() #deprels[oracle.get_gold_label()]\n",
        "                parser.left_arc(label_code) #labels 1-45 mean leftarc\n",
        "                gold_moves.append(1+label_code) #note: I switched the instructions here for symmetry. There was no comment or good reason not to.\n",
        "            elif oracle.is_right_arc_gold():\n",
        "                label_code = oracle.get_gold_label() #deprels[oracle.get_gold_label()]\n",
        "                parser.right_arc(1 + len(deprels) + label_code) #labels 46-90 mean rightarc\n",
        "                gold_moves.append(1 + len(deprels) + label_code)\n",
        "            elif oracle.is_shift_gold():\n",
        "                parser.shift()\n",
        "                gold_moves.append(0)\n",
        "            else:\n",
        "                print(\"**** AN ERROR OCCURRED ****\")\n",
        "                #print(tokens)\n",
        "                #print(enc_sentence)\n",
        "                #print(gold_tree)\n",
        "                parser.print_configuration()\n",
        "                raise Exception(\"No action identified as gold!! Please make sure your dataset doesn't contain nonprojective trees.\")\n",
        "                \n",
        "            #print(\"DEBUG: \", parser.stack)\n",
        "    \n",
        "    #print(\"DEBUG: length of path: \", len(gold_path), \"length of moves: \", len(gold_moves))\n",
        "    return enc_sentence, gold_path, gold_moves, gold_tree, gold_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d214f7df-0622-40df-9ce6-ace620105cc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d214f7df-0622-40df-9ce6-ace620105cc2",
        "outputId": "9974aa03-ba8d-41c4-d46d-2762fc5d4139"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntest_sentence = train_dataset[88]\\nemb_dictionary = create_dict(train_dataset)\\ndeprels = create_deprel_dict(train_dataset)\\n\\nprocess_sample(test_sentence, emb_dictionary, deprels, get_gold_path = True)\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Code to test process_sample\n",
        "\"\"\"\n",
        "test_sentence = train_dataset[88]\n",
        "emb_dictionary = create_dict(train_dataset)\n",
        "deprels = create_deprel_dict(train_dataset)\n",
        "\n",
        "process_sample(test_sentence, emb_dictionary, deprels, get_gold_path = True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1",
      "metadata": {
        "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Function that prepares the data for the model.\n",
        "@return sentences : list of sentences in the dataset encoded according to emb_dictionary\n",
        "@return paths : list of lists of configurations visited during the oracle-guided parsing (on training data) | empty list if get_gold_path is False\n",
        "@return moves : list of lists of moves as a number performed during the oracle-guided parsing (on training data) | empty if get_gold_path is False\n",
        "                                N.B. 0 = shift\n",
        "                                        1-45 = leftarc + label\n",
        "                                        46-90 = rightarc + label\n",
        "@return trees : ground truth tree\n",
        "@return labels : ground truth lables\n",
        "\"\"\"\n",
        "#modified form orig\n",
        "def prepare_batch(batch_data, emb_dictionary, deprels, get_gold_path=False):\n",
        "    data = [process_sample(s, emb_dictionary, deprels, get_gold_path=get_gold_path) for s in batch_data]\n",
        "    # sentences, paths, moves, trees are parallel arrays, each element refers to a sentence\n",
        "    sentences = [s[0] for s in data]\n",
        "    paths = [s[1] for s in data]\n",
        "    moves = [s[2] for s in data]\n",
        "    trees = [s[3] for s in data]\n",
        "    labels = [s[4] for s in data]\n",
        "    return sentences, paths, moves, trees, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0f3002b0-00f7-4f95-82f7-215b97ada014",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0f3002b0-00f7-4f95-82f7-215b97ada014",
        "outputId": "b808077c-9574-4ae5-a963-ca7a301b30ab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nemb_dictionary = create_dict(train_dataset)\\ndeprels = create_deprel_dict(train_dataset)\\n\\n_ = prepare_batch(iter(train_dataset), emb_dictionary, deprels, True)\\n'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### code to test prepare_batch\n",
        "\"\"\"\n",
        "emb_dictionary = create_dict(train_dataset)\n",
        "deprels = create_deprel_dict(train_dataset)\n",
        "\n",
        "_ = prepare_batch(iter(train_dataset), emb_dictionary, deprels, True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c7e3cfb5-dad2-48a3-bc92-cf2196d8748f",
      "metadata": {
        "id": "c7e3cfb5-dad2-48a3-bc92-cf2196d8748f"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Copied from original.\n",
        "Modified casing of pad and unk.\n",
        "\"\"\"\n",
        "def create_dict(dataset, threshold=3):\n",
        "  dic = {}  # dictionary of word counts\n",
        "  for sample in dataset:\n",
        "    for word in sample['tokens']:\n",
        "      if word in dic:\n",
        "        dic[word] += 1\n",
        "      else:\n",
        "        dic[word] = 1 \n",
        "\n",
        "  map = {}  # dictionary of word/index pairs\n",
        "  map[\"[PAD]\"] = 0\n",
        "  map[\"<ROOT>\"] = 1\n",
        "  map[\"<unk>\"] = 2\n",
        "\n",
        "  next_indx = 3\n",
        "  for word in dic.keys():\n",
        "    if dic[word] >= threshold:\n",
        "      map[word] = next_indx\n",
        "      next_indx += 1\n",
        "\n",
        "  return map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0dc8dfb6-91e4-425d-8406-bd427b31d053",
      "metadata": {
        "id": "0dc8dfb6-91e4-425d-8406-bd427b31d053"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Return the indices of the element to mantain in the dataset. This procedure was\n",
        "created because some sentences present some dependecies never seen in the training\n",
        "and will not processed correctly.\n",
        "In our case the worng sentences have the following idx element: 10_new-83\n",
        "\"\"\"\n",
        "def remove_sentences(dataset, idx):\n",
        "    ret = []\n",
        "    for i in range(len(dataset)):\n",
        "        x = dataset[i]\n",
        "        if x[\"idx\"] != idx:\n",
        "            ret.append(i)\n",
        "    return ret\n",
        "\n",
        "\"\"\"\n",
        "Return indices of projective sentences in the dataset. Must be used with select() to filter out nonprojective trees.\n",
        "\"\"\"\n",
        "def find_projective_idx(dataset):\n",
        "    ret = []\n",
        "    for i in range(len(dataset)):\n",
        "        x = dataset[i]\n",
        "        if orig.is_projective([-1] + [int(head) for head in x[\"head\"] if head!='None']):\n",
        "            ret.append(i)\n",
        "    return ret\n",
        "\n",
        "\"\"\"\n",
        "Return indices of sentences shorter than TOKENIZER_MAX_LEN\n",
        "\"\"\"\n",
        "def find_long_idx(dataset):\n",
        "    ret = []\n",
        "    for i in range(len(dataset)):\n",
        "        x = dataset[i]\n",
        "        if len(x[\"tokens\"]) <= TOKENIZER_MAX_LEN: \n",
        "            ret.append(i)\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
        "outputId": "5fce39dc-8677-42cd-f02e-4f4ae51b06c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset universal_dependencies (/root/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
            "Reusing dataset universal_dependencies (/root/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
            "Reusing dataset universal_dependencies (/root/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")\n",
        "dev_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"validation\")\n",
        "test_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"test\")\n",
        "\n",
        "train_dataset = train_dataset.select(find_projective_idx(train_dataset)) #to remove nonprojective trees\n",
        "train_dataset = train_dataset.select(find_long_idx(train_dataset)) #to remove sentences too long\n",
        "\n",
        "dev_dataset = dev_dataset.select(find_projective_idx(dev_dataset)) #to remove nonprojective trees\n",
        "dev_dataset = dev_dataset.select(find_long_idx(dev_dataset)) #to remove sentences too long\n",
        "\n",
        "test_dataset = test_dataset.select(remove_sentences(test_dataset, \"10_new-83\")) #to remove sentences that have labels that do not appear in the training set\n",
        "test_dataset = test_dataset.select(find_projective_idx(test_dataset)) #to remove nonprojective trees\n",
        "test_dataset = test_dataset.select(find_long_idx(test_dataset)) #to remove sentences too long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8bcb2cbf-eebb-4099-bba8-a05925919abf",
      "metadata": {
        "id": "8bcb2cbf-eebb-4099-bba8-a05925919abf"
      },
      "outputs": [],
      "source": [
        "emb_dictionary = create_dict(train_dataset)\n",
        "deprels = create_deprel_dict(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "51d176de-aa6a-4258-ab75-e46c772beb81",
      "metadata": {
        "id": "51d176de-aa6a-4258-ab75-e46c772beb81"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels, get_gold_path=True))\n",
        "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels, get_gold_path=True))\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels, get_gold_path=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b",
      "metadata": {
        "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b"
      },
      "source": [
        "## Ideas for the future\n",
        "* Use mean square error to predict pairs (MOVE, LABEL) in the training set\n",
        "* We need to rescale the data in an acceptable range. Probably should make the MOVE have greater variation, e.g LeftArc=100 RightArc=0 Shift=-100\n",
        "* BERT layer must process each sentence separately to produce word embeddings, but it should also be finetuned alongside the fully connected layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xNoPh6s17yyx",
      "metadata": {
        "id": "xNoPh6s17yyx"
      },
      "source": [
        "# Neural Oracle\n",
        "\n",
        "Neural oracle implemented using BERT fine-tunned with a simple classifiers.\n",
        "The references are: [Towards Data Science](https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f) and [Text Classification | Sentiment Analysis with BERT using huggingface, PyTorch and Python Tutorial](https://www.youtube.com/watch?v=8N-nM3QW7O0).\n",
        "\n",
        "The hyperparameters and the training tweaks are taken from the original BERT paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ZfqzDHLLA08V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "e98529d69f69464794dac32705d75cb3",
            "1a04da26fbdd4da1a0644c54b85caa01",
            "ee3f74b907884addadf1a15e598705c2",
            "ad87ba88b90643cb9b3fca5bf0199a42",
            "a0d85fa7a1324c5ebd1fee1444ef4461",
            "abee7b07642d4bf4a010dcbaf8082753",
            "6daad2bf38464174abef943bb55f450e",
            "d7f9d710669d4797a881fd5fe05dc96e",
            "a539e1776a8d4b6c8ecf3908ca8c376c",
            "eea30cfd9cc34be686787e334d4c897c",
            "bb38eb597dc24142b9923d1622361257",
            "a82c73f372464f9c9c3dc6ff677837f8",
            "a0d3d1866b794985a48ef77f6cae4263",
            "b9dc50c5dccc40b7af8d809fff978404",
            "25b255dbf9094148a8e48da7de3b88fd",
            "a847609d83ff4c399615c32a5b7eef49",
            "5de9b3a45e92460191d4111862307643",
            "269b0f1896a744898cd7022763ec350b",
            "81b56f90440b4540bdbf984cd133db18",
            "ea4228a2c855461f872a69fdc253e75e",
            "7fdeef2da5b641b08a7d787be4ca8edf",
            "18ac45d58e6e4ba7abf270cd526e99d1",
            "9b122973d9364979bb2726dce51e457a",
            "23d76f1f7a574876a960c8de617f37a0",
            "a4b5509a4c2142a486d812d147a5550a",
            "a14e33f413d84ed8b51000f4cfb49dd8",
            "b7a21d421bcb4d6cbca08db64f4af4b8",
            "e072d8023cc1495bbd4aa27eadc28ccb",
            "6f2e9ea9dfda4699b1afd31866470076",
            "1ee8b47bfe1b47d4a6951dbc78d2ad90",
            "7121c34ea5b845efa0e8b8e09abcf6e1",
            "6b86420c4dc54223a74efdc5420df347",
            "0b07c706cb284aaa996b5cb07b6f6d9f"
          ]
        },
        "id": "ZfqzDHLLA08V",
        "outputId": "94fed78a-4f40-4daa-f96b-eb1bad94e5bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e98529d69f69464794dac32705d75cb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/230k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a82c73f372464f9c9c3dc6ff677837f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b122973d9364979bb2726dce51e457a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load the BERT tokenizer with pretrained weights for the Italian language\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845TJICw2Q9x",
      "metadata": {
        "id": "845TJICw2Q9x"
      },
      "source": [
        "In this section we have loaded the BERT tokenizer and try it to see how a sentence is processed and which kind of objects the tokenizer returns to be used in BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QtZZfEGK9IG5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtZZfEGK9IG5",
        "outputId": "f364f4b5-fb7a-4240-d185-3e171b418d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  102,   401,   162,  1909,   532, 27948,  2369,   139,  5101,  1783,\n",
            "           223,  1731,   146, 16711,   103]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "[CLS] Con il termine interfluvio in geologia si indica la porzione [SEP]\n"
          ]
        }
      ],
      "source": [
        "example_text = '''Con il termine interfluvio in geologia si indica la porzione di superﬁcie più elevata\n",
        "                  che separa due valli ﬂuviali adiacenti, che può essere una cresta oppure un' area ampia,\n",
        "                  comunque non coinvolta dal movimento delle acque'''\n",
        "\n",
        "\n",
        "bert_input = tokenizer(example_text, padding='max_length', max_length = 15, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "print(bert_input['input_ids'])      # words to integer\n",
        "print(bert_input['token_type_ids']) # binary mask that identifies whether a token is in the first sentence (before [SEP]) or the second (after [SEP])\n",
        "print(bert_input['attention_mask']) # binary mask that identifies whether a token is a real word or just padding\n",
        "\n",
        "decoded_text = tokenizer.decode(bert_input.input_ids[0])\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mxtuOhzE6rTi",
      "metadata": {
        "id": "mxtuOhzE6rTi"
      },
      "source": [
        "  ## Oracle model using BERT\n",
        "For the oracle we decided to use and fine-tune bert in a regression task.\n",
        "The main idea is:\n",
        "\n",
        "*   given a sentence get the **'Bert input tokens**' and the **'attention mask**' from the BERT tokenizer above;\n",
        "*   pass the 'input tokens' and the 'attention mask' to the BERTOracle that returns a tensor that contains a list of configurations, one for each sentence.\n",
        "\n",
        "In this setting a configuration is a pair of numbers. For this reason we use MSE loss to create a **multi-ouptut regressor** task.\n",
        "\n",
        "One configuration is in the form (**ACTION, LABELS**) where for ACTION we have:\n",
        "\n",
        "* 100 for **LeftArc** action;\n",
        "* 0 for **RightArc** action;\n",
        "* -100 for **Shift** action.\n",
        "\n",
        "For the LABELS we have decided to order them in alphabetical order and convert them into consecutive numbers.\n",
        "The main idea is: \n",
        "\n",
        "the labels represent the relation between words.<br>\n",
        "In the used treebank there are many such relation that are very similar like *obj* and *iobj* so by ordering them and giving consecutive numbers we have that *obj* will be encoded, for instance, as 12 and *iobj* with 13. This means that, even if the oracle infere 13 instead of 12 we have that the prediction is not as wrong as if it will have predicte 50.<br>\n",
        "The main assumption is that closer numbers represent more similar relation.\n",
        "\n",
        "To perfrom the actual multi-output regression we used a simple linear layer that outputs this two values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "KkXDGmBW-vFo",
      "metadata": {
        "id": "KkXDGmBW-vFo"
      },
      "outputs": [],
      "source": [
        "class BERTOracle(nn.Module):\n",
        "    def __init__(self, input_size, deprels):\n",
        "      super(BERTOracle, self).__init__()\n",
        "      self.bert = BertModel.from_pretrained(BERT_MODEL)\n",
        "      self.dropout = nn.Dropout(DROPOUT_RATE)\n",
        "      self.w1 = nn.Linear(input_size, MLP_SIZE) #for classification: we need 2*sizeof(label_set)+1\n",
        "      self.activation = torch.nn.Tanh()\n",
        "      self.w2 = nn.Linear(MLP_SIZE, 2*len(deprels)+1)\n",
        "      self.softmax = torch.nn.Softmax(dim=-1)\n",
        "\n",
        "    #Substitute the \"tokenized words\" in the paths with the embeddings\n",
        "    def substitute_embeddings(self, word_embeddings, paths):\n",
        "      ffn_input = []\n",
        "      zero_tensor = torch.zeros(768, requires_grad=False).to(DEVICE)\n",
        "      for sentence_index in range(len(paths)): # one path for each sentence so len(paths) = number of sentences\n",
        "        for configuration in paths[sentence_index]: # take the sentence in number 'sentence_index'\n",
        "          new_tensor = torch.cat(\n",
        "              [\n",
        "                zero_tensor if configuration[0]==-1 else word_embeddings[sentence_index][configuration[0]], \n",
        "                zero_tensor if configuration[1]==-1 else word_embeddings[sentence_index][configuration[1]], \n",
        "                zero_tensor if configuration[2]==-1 else word_embeddings[sentence_index][configuration[2]]\n",
        "              ]\n",
        "            )\n",
        "          ffn_input.append(new_tensor)\n",
        "      ffn_input = torch.stack(ffn_input).to(DEVICE)\n",
        "      return ffn_input\n",
        "\n",
        "    #Since each sentence have a different number of configuration I pad the paths to have all the same number of configurations\n",
        "    #Maybe its not required\n",
        "    def pad_paths(arr):\n",
        "      pad_token = [-1,-1,-1]\n",
        "      padded = zip(*itertools.zip_longest(*arr, fillvalue=pad_token))\n",
        "      return list(padded)\n",
        "\n",
        "    def ffn_pass(self, configuration):\n",
        "      out = self.dropout(configuration)\n",
        "      out = self.w1(out)\n",
        "      out = self.activation(out)\n",
        "      out = self.dropout(out)\n",
        "      out = self.w2(out)\n",
        "      return self.softmax(out)\n",
        "\n",
        "    def forward(self, input_tokens, attention_mask, paths):\n",
        "      #Compute the BERT embeddings and retrieve them from the last hidden layer\n",
        "      out = self.bert(input_tokens, attention_mask)    \n",
        "      word_embeddings = out.last_hidden_state # [sentence_index, tokens, embedding_of_token]\n",
        "\n",
        "      #Substitute each word in a configuration with the corrisponding embedding.\n",
        "      #Be aware of: we need padding to have the configurations all the same size, maybe we need to reshape them to match (batch_size x config_per_sentence x 768*3)\n",
        "      configurations = self.substitute_embeddings(word_embeddings, paths)\n",
        "\n",
        "      #Pass through FFN\n",
        "      return self.ffn_pass(configurations)\n",
        "    ##################################################################################################################\n",
        "    \n",
        "    def infere(self, sentences):\n",
        "        parsers = [ArcStandard(i, deprels) for i in sentences]\n",
        "        #copied from below...\n",
        "        list_sentences = [str(x) for x in sentences] \n",
        "        preprocessed_text = tokenizer(list_sentences, padding='max_length', max_length = TOKENIZER_MAX_LEN, truncation=True, return_tensors=\"pt\")\n",
        "        input_tokens = preprocessed_text[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = preprocessed_text[\"attention_mask\"].to(DEVICE)\n",
        "        \n",
        "        h = self.bert(input_tokens, attention_mask).last_hidden_state\n",
        "\n",
        "        while not self.parsed_all(parsers):\n",
        "            configurations = self.get_configurations(parsers)\n",
        "            mlp_input = self.substitute_embeddings(h, configurations) \n",
        "            mlp_out = self.ffn_pass(mlp_input)\n",
        "            self.parse_step(parsers, mlp_out, deprels)\n",
        "\n",
        "        return [parser.arcs for parser in parsers]\n",
        "    \n",
        "    \"\"\"\n",
        "    This function was copied from the original file\n",
        "    \"\"\"\n",
        "    def get_configurations(self, parsers):\n",
        "        configurations = []\n",
        "\n",
        "        for parser in parsers:\n",
        "          if parser.is_tree_final():\n",
        "            conf = [-1, -1, -1]\n",
        "          else:\n",
        "            conf = [parser.stack[len(parser.stack)-2], parser.stack[len(parser.stack)-1]]\n",
        "            if len(parser.buffer) == 0:\n",
        "              conf.append(-1)\n",
        "            else:\n",
        "              conf.append(parser.buffer[0])  \n",
        "          configurations.append([conf])\n",
        "\n",
        "        return configurations\n",
        "\n",
        "    \"\"\"\n",
        "    This function was copied from the original file\n",
        "    \"\"\"\n",
        "    def parsed_all(self, parsers):\n",
        "        for parser in parsers:\n",
        "            if not parser.is_tree_final():\n",
        "                return False\n",
        "        return True\n",
        "    \n",
        "    \"\"\"\n",
        "    Remember we use the convention\n",
        "    0 = shift\n",
        "    [1, len(deprels)] = left-arc\n",
        "    [len(deprels)+1, 2*len(deprels)+1] = right-arc\n",
        "    \n",
        "    This function was adapted from the original to remove padding from the buffer avoiding all edge cases\n",
        "    that complicated the original code.\n",
        "    \"\"\"\n",
        "    def parse_step(self, parsers, moves, labels):\n",
        "      moves_argm = moves.argmax(-1) #vector of argmaxes\n",
        "      moves_second_argm = moves[:, 1:].argmax(-1) + 1 #needed when buffer is empty but argmax is 0 (shift). Contains the argmax for each sentence excluding index 0. \n",
        "                                                      #1 is added to account for slicing\n",
        "      \n",
        "      for i in range(len(parsers)):\n",
        "          kind_of_move = 0 if moves_argm[i] == 0 else (1 + int(moves_argm[i] / len(labels))) #0 if shift, 1 if leftarc, 2 is rightarc\n",
        "          label = moves_argm[i] % len(labels) #label of the arc, ignored if shift\n",
        "          \n",
        "          while parsers[i].buffer and parsers[i].buffer[-1] == 0: #while buffer not empty and we have padding in the buffer: remove it.\n",
        "              parsers[i].buffer.pop()\n",
        "              continue #a new prediction is needed\n",
        "\n",
        "          if parsers[i].is_tree_final():\n",
        "              continue\n",
        "\n",
        "          if kind_of_move == 1: #predicted: leftarc\n",
        "              parsers[i].left_arc(label)\n",
        "\n",
        "          elif kind_of_move == 2: #predicted: rightarc\n",
        "              parsers[i].right_arc(label)\n",
        "\n",
        "          elif moves_argm[i] == 0: #predicted: shift\n",
        "              if parsers[i].buffer: \n",
        "                  parsers[i].shift()\n",
        "              else: #in case buffer is empty\n",
        "                  if moves_second_argm[i]/len(labels) == 0:\n",
        "                      parsers[i].left_arc(moves_second_argm % len(labels))\n",
        "                  elif moves_second_argm[i]/len(labels) == 1:\n",
        "                      parsers[i].right_arc(moves_second_argm % len(labels))\n",
        "                  else:\n",
        "                      raise Exception(\"moves_second_argm not in range [1, 2*len(labels)]\")\n",
        "                      \n",
        "          else:\n",
        "              raise Exception(\"argmax not in range [0, 2*len(labels)]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "oUpbfnjJBTvv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4a875c7d0c3c497580fcc81597c8e483",
            "f13eac44e9794365815aa5f06da1e907",
            "217fdd341e4347a0886d82ac2be672e9",
            "7315116c34034afdb05d732b855b41b6",
            "108f862ce9504191ad131e630fecbdec",
            "7576dc4fbfd24c3288eb9071f11a7f20",
            "b462bec18ab24c2baa370423bdd2c06e",
            "f3025deb18ad4ccc8ea7198fc6e8cbd0",
            "18b181d25e7441389a81450b26400763",
            "1763e0ec394144e49a781d61534147a6",
            "eb87f04d70cf4212b27f8d3430ae8629"
          ]
        },
        "id": "oUpbfnjJBTvv",
        "outputId": "9b527321-4a51-4836-8ea0-c5166eb00d96"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a875c7d0c3c497580fcc81597c8e483",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/425M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BERTOracle(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32102, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (w1): Linear(in_features=2304, out_features=300, bias=True)\n",
              "  (activation): Tanh()\n",
              "  (w2): Linear(in_features=300, out_features=91, bias=True)\n",
              "  (softmax): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Initialize the BERTOracle model\n",
        "model = BERTOracle(INPUT_SIZE, deprels)\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QRk1Qh53F5EG",
      "metadata": {
        "id": "QRk1Qh53F5EG"
      },
      "source": [
        "## Training and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "AaJXSRebF7EE",
      "metadata": {
        "id": "AaJXSRebF7EE"
      },
      "outputs": [],
      "source": [
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "#Define the loss as cross entropy\n",
        "loss_fn = nn.CrossEntropyLoss().to(DEVICE) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p3ePzCq4gJWx",
      "metadata": {
        "id": "p3ePzCq4gJWx"
      },
      "source": [
        "## Train and evaluation function for BERTOracle model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4h-Y7lj8INBz",
      "metadata": {
        "id": "4h-Y7lj8INBz"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  for batch in data_loader:\n",
        "    sentences, paths, moves, trees, labels = batch\n",
        "    optimizer.zero_grad()                                             # initialize gradient to zeros\n",
        "    list_sentences = [str(x) for x in sentences]                      # list of sentences in string format\n",
        "\n",
        "    preprocessed_text = tokenizer(list_sentences, padding='max_length', max_length = TOKENIZER_MAX_LEN, \n",
        "                       truncation=True, return_tensors=\"pt\")          # tokenize input using BERT tokenizer\n",
        "\n",
        "    input_tokens = preprocessed_text[\"input_ids\"].to(DEVICE)\n",
        "    attention_mask = preprocessed_text[\"attention_mask\"].to(DEVICE)\n",
        "  \n",
        "    outputs = model(input_tokens, attention_mask, paths)\n",
        "\n",
        "    # Compute the loss for each configurations for each sentence in parallel\n",
        "    tensor_moves = torch.tensor(sum(moves, [])).to(DEVICE)\n",
        "    loss = loss_fn(outputs, tensor_moves)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    #backpropagation routine\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  mean_loss = np.mean(losses)\n",
        "\n",
        "  return mean_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "idw5no5rK0Ea",
      "metadata": {
        "id": "idw5no5rK0Ea"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, optimzier):\n",
        "  model = model.eval()                                                # dropout and batch_norm are not enabled\n",
        "\n",
        "  losses = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "      sentences, paths, moves, trees, labels = batch\n",
        "      optimizer.zero_grad()                                             # initialize gradient to zeros\n",
        "      list_sentences = [str(x) for x in sentences]                      # list of sentences in string format\n",
        "\n",
        "      preprocessed_text = tokenizer(list_sentences, padding='max_length', max_length = TOKENIZER_MAX_LEN, \n",
        "                        truncation=True, return_tensors=\"pt\")           # tokenize input using BERT tokenizer\n",
        "\n",
        "      input_tokens = preprocessed_text[\"input_ids\"].to(DEVICE)\n",
        "      attention_mask = preprocessed_text[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "      outputs = model(input_tokens, attention_mask, paths)\n",
        "\n",
        "      # Compute the loss for each configurations for each sentence in parallel\n",
        "      tensor_moves = torch.tensor(sum(moves, [])).to(DEVICE)\n",
        "      loss = loss_fn(outputs, tensor_moves)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  mean_loss = np.mean(losses)\n",
        "\n",
        "  return mean_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4qhZPXfxLo67",
      "metadata": {
        "id": "4qhZPXfxLo67"
      },
      "source": [
        "## Training loop\n",
        "Training loop that for the given number of epoch preform the training step and the evaluation step for each sentence in the train_dataloader and val_dataloader.\n",
        "All the results are krept inside a dictionary of history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ngRlytTZLqnK",
      "metadata": {
        "id": "ngRlytTZLqnK"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "history = defaultdict(list) # store training and validation losses in a dictionary \n",
        "epoch_to_save = 5           # save model every 5 epochs\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f'Epoch {epoch + 1} / {EPOCHS}')\n",
        "\n",
        "  #Training step\n",
        "  train_loss = train_epoch(model, test_dataloader, loss_fn, optimizer)\n",
        "\n",
        "  print(f\"Train loss {train_loss}\")\n",
        "\n",
        "  #Evaluation step\n",
        "  val_loss = eval_model(model, dev_dataloader, loss_fn, optimizer)\n",
        "\n",
        "  print(f\"Val loss {val_loss}\")\n",
        "  print('-'*10)\n",
        "\n",
        "  history['train_loss'].append(train_loss)\n",
        "\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if epoch % epoch_to_save == 0:\n",
        "    torch.save(model, SAVE_PATH)\n",
        "    print(\"|MODEL SAVED|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Om8sss6qfK-L",
      "metadata": {
        "id": "Om8sss6qfK-L"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cb5cbce",
      "metadata": {
        "id": "2cb5cbce"
      },
      "outputs": [],
      "source": [
        "#Load the saved model's weights\n",
        "model = torch.load(SAVE_PATH)\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a01376-3579-469e-b907-40e686da5051",
      "metadata": {
        "id": "a0a01376-3579-469e-b907-40e686da5051"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Functions were adapted from the ones in the original notebook\n",
        "preds is a list of *couples*\n",
        "\n",
        "evaluate() returns a couple of values (UAS, LAS)\n",
        "\"\"\"\n",
        "def evaluate(gold, preds): \n",
        "  total = 0\n",
        "  correct_unlabeled = 0\n",
        "  correct_labeled = 0\n",
        "\n",
        "  for g, p in zip(gold, preds):\n",
        "    for i in range(1,len(g)):\n",
        "      total += 1\n",
        "      if g[i][0] == p[i][0]:\n",
        "        correct_unlabeled += 1\n",
        "        if g[i][1] == p[i][1]:\n",
        "          correct_labeled += 1\n",
        "  return correct_unlabeled/total, correct_labeled/total\n",
        "\n",
        "def validation(model, dataloader):\n",
        "  model.eval()\n",
        "  gold = []\n",
        "  preds = []\n",
        "\n",
        "  for batch in dataloader:\n",
        "    sentences, paths, moves, trees, labels = batch\n",
        "    with torch.no_grad():\n",
        "      pred = model.infere(sentences) #now pred is made of (move, label) pairs\n",
        "      \n",
        "      gold += trees\n",
        "      preds += pred\n",
        "          \n",
        "  return evaluate(gold, preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JIWowQo7wcjb",
      "metadata": {
        "id": "JIWowQo7wcjb"
      },
      "outputs": [],
      "source": [
        "uas, las = validation(model, test_dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "d704ceb0",
        "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
        "05840970-630c-4152-bdc6-2c25e81fefff",
        "44355fbe-cb0c-4ae5-8967-016ec09033fc"
      ],
      "name": "our_dep_parser.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b07c706cb284aaa996b5cb07b6f6d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "108f862ce9504191ad131e630fecbdec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1763e0ec394144e49a781d61534147a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ac45d58e6e4ba7abf270cd526e99d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18b181d25e7441389a81450b26400763": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a04da26fbdd4da1a0644c54b85caa01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abee7b07642d4bf4a010dcbaf8082753",
            "placeholder": "​",
            "style": "IPY_MODEL_6daad2bf38464174abef943bb55f450e",
            "value": "Downloading: 100%"
          }
        },
        "1ee8b47bfe1b47d4a6951dbc78d2ad90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217fdd341e4347a0886d82ac2be672e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3025deb18ad4ccc8ea7198fc6e8cbd0",
            "max": 445332122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18b181d25e7441389a81450b26400763",
            "value": 445332122
          }
        },
        "23d76f1f7a574876a960c8de617f37a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e072d8023cc1495bbd4aa27eadc28ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_6f2e9ea9dfda4699b1afd31866470076",
            "value": "Downloading: 100%"
          }
        },
        "25b255dbf9094148a8e48da7de3b88fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fdeef2da5b641b08a7d787be4ca8edf",
            "placeholder": "​",
            "style": "IPY_MODEL_18ac45d58e6e4ba7abf270cd526e99d1",
            "value": " 59.0/59.0 [00:00&lt;00:00, 1.64kB/s]"
          }
        },
        "269b0f1896a744898cd7022763ec350b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a875c7d0c3c497580fcc81597c8e483": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f13eac44e9794365815aa5f06da1e907",
              "IPY_MODEL_217fdd341e4347a0886d82ac2be672e9",
              "IPY_MODEL_7315116c34034afdb05d732b855b41b6"
            ],
            "layout": "IPY_MODEL_108f862ce9504191ad131e630fecbdec"
          }
        },
        "5de9b3a45e92460191d4111862307643": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b86420c4dc54223a74efdc5420df347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6daad2bf38464174abef943bb55f450e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f2e9ea9dfda4699b1afd31866470076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7121c34ea5b845efa0e8b8e09abcf6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7315116c34034afdb05d732b855b41b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1763e0ec394144e49a781d61534147a6",
            "placeholder": "​",
            "style": "IPY_MODEL_eb87f04d70cf4212b27f8d3430ae8629",
            "value": " 425M/425M [00:12&lt;00:00, 38.8MB/s]"
          }
        },
        "7576dc4fbfd24c3288eb9071f11a7f20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fdeef2da5b641b08a7d787be4ca8edf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b56f90440b4540bdbf984cd133db18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b122973d9364979bb2726dce51e457a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23d76f1f7a574876a960c8de617f37a0",
              "IPY_MODEL_a4b5509a4c2142a486d812d147a5550a",
              "IPY_MODEL_a14e33f413d84ed8b51000f4cfb49dd8"
            ],
            "layout": "IPY_MODEL_b7a21d421bcb4d6cbca08db64f4af4b8"
          }
        },
        "a0d3d1866b794985a48ef77f6cae4263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de9b3a45e92460191d4111862307643",
            "placeholder": "​",
            "style": "IPY_MODEL_269b0f1896a744898cd7022763ec350b",
            "value": "Downloading: 100%"
          }
        },
        "a0d85fa7a1324c5ebd1fee1444ef4461": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14e33f413d84ed8b51000f4cfb49dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b86420c4dc54223a74efdc5420df347",
            "placeholder": "​",
            "style": "IPY_MODEL_0b07c706cb284aaa996b5cb07b6f6d9f",
            "value": " 433/433 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "a4b5509a4c2142a486d812d147a5550a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee8b47bfe1b47d4a6951dbc78d2ad90",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7121c34ea5b845efa0e8b8e09abcf6e1",
            "value": 433
          }
        },
        "a539e1776a8d4b6c8ecf3908ca8c376c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a82c73f372464f9c9c3dc6ff677837f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0d3d1866b794985a48ef77f6cae4263",
              "IPY_MODEL_b9dc50c5dccc40b7af8d809fff978404",
              "IPY_MODEL_25b255dbf9094148a8e48da7de3b88fd"
            ],
            "layout": "IPY_MODEL_a847609d83ff4c399615c32a5b7eef49"
          }
        },
        "a847609d83ff4c399615c32a5b7eef49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abee7b07642d4bf4a010dcbaf8082753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad87ba88b90643cb9b3fca5bf0199a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eea30cfd9cc34be686787e334d4c897c",
            "placeholder": "​",
            "style": "IPY_MODEL_bb38eb597dc24142b9923d1622361257",
            "value": " 230k/230k [00:00&lt;00:00, 4.49MB/s]"
          }
        },
        "b462bec18ab24c2baa370423bdd2c06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7a21d421bcb4d6cbca08db64f4af4b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9dc50c5dccc40b7af8d809fff978404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b56f90440b4540bdbf984cd133db18",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea4228a2c855461f872a69fdc253e75e",
            "value": 59
          }
        },
        "bb38eb597dc24142b9923d1622361257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f9d710669d4797a881fd5fe05dc96e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e072d8023cc1495bbd4aa27eadc28ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98529d69f69464794dac32705d75cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a04da26fbdd4da1a0644c54b85caa01",
              "IPY_MODEL_ee3f74b907884addadf1a15e598705c2",
              "IPY_MODEL_ad87ba88b90643cb9b3fca5bf0199a42"
            ],
            "layout": "IPY_MODEL_a0d85fa7a1324c5ebd1fee1444ef4461"
          }
        },
        "ea4228a2c855461f872a69fdc253e75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb87f04d70cf4212b27f8d3430ae8629": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee3f74b907884addadf1a15e598705c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f9d710669d4797a881fd5fe05dc96e",
            "max": 235127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a539e1776a8d4b6c8ecf3908ca8c376c",
            "value": 235127
          }
        },
        "eea30cfd9cc34be686787e334d4c897c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13eac44e9794365815aa5f06da1e907": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7576dc4fbfd24c3288eb9071f11a7f20",
            "placeholder": "​",
            "style": "IPY_MODEL_b462bec18ab24c2baa370423bdd2c06e",
            "value": "Downloading: 100%"
          }
        },
        "f3025deb18ad4ccc8ea7198fc6e8cbd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
