{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c041f954-42d3-44e6-b2c2-281d579e61e6",
   "metadata": {
    "id": "c041f954-42d3-44e6-b2c2-281d579e61e6"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install transformers\n",
    "#!pip install datasets\n",
    "#!pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f",
   "metadata": {
    "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
   "metadata": {
    "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5"
   },
   "source": [
    "## Arc-standard\n",
    "\n",
    "Recall that a **configuration** of the arc-standard parser is a triple of the form $( \\sigma, \\beta, A)$\n",
    "where:\n",
    "\n",
    "* $\\sigma$ is the stack;\n",
    "* $\\beta$ is the input buffer;\n",
    "* $A$ is a set of arcs constructed so far.\n",
    "\n",
    "We write $\\sigma_i$, $i \\geq 1$, for the $i$-th token in the stack; we also write $\\beta_i$, $i \\geq 1$, for the $i$-th token in the buffer. \n",
    "\n",
    "The parser can perform three types of **actions** (transitions):\n",
    "\n",
    "* **shift**, which removes $\\beta_1$ from the buffer and pushes it into the stack;\n",
    "* **left-arc**, which creates the arc $(\\sigma_1 \\rightarrow \\sigma_2)$, and removes $\\sigma_2$ from the stack;\n",
    "* **right-arc**, which creates the arc $(\\sigma_2 \\rightarrow \\sigma_1)$, and removes $\\sigma_1$ from the stack.\n",
    "\n",
    "Let $w = w_0 w_1 \\cdots w_{n}$ be the input sentence, with $w_0$ the special symbol `<ROOT>`.\n",
    "Stack and buffer are implemented as lists of integers, where `j` represents word $w_j$.  Top-most stack token is at the right-end of the list; first buffer token is at the left-end of the list. \n",
    "Set $A$ is implemented as an array `arcs` of size $n+1$ such that if arc $(w_i \\rightarrow w_j)$ is in $A$ then `arcs[j]=i`, and if $w_j$ is still missing its head node in the tree under construction, then `arcs[j]=-1`. We always have `arcs[0]=-1`.  We use this representation also for complete dependency trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf",
   "metadata": {
    "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf"
   },
   "outputs": [],
   "source": [
    "import orig #file orig.py in the same foldr contains original class and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7",
   "metadata": {
    "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7"
   },
   "outputs": [],
   "source": [
    "class ArcStandard (orig.ArcStandard):\n",
    "    def __init__(self, sentence, label_set):\n",
    "        self.sentence = sentence\n",
    "        self.buffer = [i for i in range(len(self.sentence))]\n",
    "        self.stack = []\n",
    "        self.arcs = [(-1, -1) for _ in range(len(self.sentence))]# head - relation converted to int\n",
    "\n",
    "        self.label_set = {y:x for x,y in label_set.items()} #for future reference (printing)\n",
    "        # three shift moves to initialize the stack\n",
    "        self.shift()\n",
    "        self.shift()\n",
    "        if len(self.sentence) > 2:\n",
    "            self.shift()\n",
    "\n",
    "    def left_arc(self, deprel):\n",
    "        o1 = self.stack.pop()\n",
    "        o2 = self.stack.pop()\n",
    "        self.arcs[o2] = (o1, deprel) #added deprel\n",
    "        self.stack.append(o1)\n",
    "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
    "            self.shift()\n",
    "\n",
    "    def right_arc(self, deprel):\n",
    "        o1 = self.stack.pop()\n",
    "        o2 = self.stack.pop()\n",
    "        self.arcs[o1] = (o2, deprel) #added deprel\n",
    "        self.stack.append(o2)\n",
    "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
    "            self.shift()\n",
    "\n",
    "    def print_configuration(self):\n",
    "        s = [self.sentence[i] for i in self.stack]\n",
    "        b = [self.sentence[i] for i in self.buffer]\n",
    "        print(\"STACK: \", s, \"BUFFER: \", b) #added indication of stack and buffer\n",
    "        print([(x[0], self.label_set[x[1]]) for x in self.arcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d836502-bba0-4f49-9c39-39a916ed270c",
   "metadata": {
    "id": "1d836502-bba0-4f49-9c39-39a916ed270c"
   },
   "outputs": [],
   "source": [
    "class Oracle (orig.Oracle):\n",
    "    def __init__(self, parser, gold_tree, gold_labels):\n",
    "        self.parser = parser\n",
    "        self.gold = gold_tree\n",
    "        self.labels = gold_labels #must be integers; see below\n",
    "\n",
    "    def get_gold_label(self):\n",
    "        if(self.is_left_arc_gold()):\n",
    "            o2 = self.parser.stack[len(self.parser.stack)-2]\n",
    "            return self.labels[o2]\n",
    "        elif(self.is_right_arc_gold()):\n",
    "            o1 = self.parser.stack[len(self.parser.stack)-1]\n",
    "            return self.labels[o1]\n",
    "        else:\n",
    "            raise Exception(\"Action SHIFT does not produce a labeled dependency\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2",
   "metadata": {
    "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2"
   },
   "source": [
    "## Functions to simplify the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374",
   "metadata": {
    "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dataset should be a Dataset object from HuggingFace\n",
    "Return a dictionary where arc labels are associate to integer values.\n",
    "Label '_' is removed (used for composite tokens)\n",
    "Labels are sorted in alphabetical order because MSE in the neural network will penalize less classes that are \"close\".\n",
    "<ROOT> label is given value -1 (label of the <ROOT> node).\n",
    "\"\"\"\n",
    "def create_deprel_dict(dataset):\n",
    "    labels = set()\n",
    "    for x in dataset['deprel']:\n",
    "        for elem in x:\n",
    "            if(elem != '_'):\n",
    "                labels.add(elem)\n",
    "    labels = sorted(list(labels))\n",
    "    ret = {labels[i]:i for i in range(len(labels))}\n",
    "    ret.update({\"None\":-1})\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "Return (sanitized_tokens, gold tree, gold labels) for a sentence in the dataset, assuming gold tree is in a column labeled 'head' and labels in a column labeled 'deprel'.\n",
    "Both token indices and labels are converted to integer (in the latter case, according to deprel_dict).\n",
    "Sanitized tokens is a tokenlist with removal of composite tokens.\n",
    "\"\"\"\n",
    "def create_gold(sentence, deprel_dict):\n",
    "    sanitized = ['<ROOT>']\n",
    "    gold_tree = [-1]\n",
    "    gold_labels = [-1]\n",
    "    for i in range(len(sentence['tokens'])):\n",
    "        if(sentence['head'][i] != 'None'):\n",
    "            sanitized.append(sentence['tokens'][i])\n",
    "            gold_tree.append(int(sentence['head'][i]))\n",
    "            gold_labels.append(deprel_dict[sentence['deprel'][i]])\n",
    "    \n",
    "    return sanitized, gold_tree, gold_labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd",
   "metadata": {
    "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd"
   },
   "source": [
    "## Testing parser and oracle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bcbd5e-b121-4cef-992f-f22df16e4315",
   "metadata": {
    "id": "21bcbd5e-b121-4cef-992f-f22df16e4315"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9269d170-abea-4671-b795-a9026fc3e46a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9269d170-abea-4671-b795-a9026fc3e46a",
    "outputId": "38d7033b-c71d-4388-fe65-3e14e7bc8a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<ROOT>', 'Inconsueto', 'allarme', 'a', 'la', 'Tate', 'Gallery', ':']\n",
      "[-1, 2, 0, 5, 5, 2, 5, 2]\n",
      "[-1, 4, 41, 8, 17, 31, 28, 40]\n"
     ]
    }
   ],
   "source": [
    "deprels = create_deprel_dict(train_dataset)\n",
    "sentence = train_dataset[3]\n",
    "\n",
    "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
    "\n",
    "print(tokens)\n",
    "print(gold_tree)\n",
    "print(gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
    "outputId": "7c08fcd8-fc6c-4f78-b0f3-3c0395a58833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK:  ['<ROOT>', 'Inconsueto', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n"
     ]
    }
   ],
   "source": [
    "parser = ArcStandard(tokens, deprels)\n",
    "oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "parser.print_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
    "outputId": "27c17541-3c00-45ac-f726-4f9e16931434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a'] BUFFER:  ['la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'la'] BUFFER:  ['Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'la', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate', 'Gallery'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', ':'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n",
      "STACK:  ['<ROOT>'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (0, 'root'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n"
     ]
    }
   ],
   "source": [
    "while not parser.is_tree_final():  # transition precedence implemented here\n",
    "    if oracle.is_shift_gold():  \n",
    "        parser.shift()\n",
    "    elif oracle.is_left_arc_gold():\n",
    "        parser.left_arc(oracle.get_gold_label())\n",
    "    elif oracle.is_right_arc_gold():\n",
    "        parser.right_arc(oracle.get_gold_label())\n",
    "    \n",
    "    parser.print_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05840970-630c-4152-bdc6-2c25e81fefff",
   "metadata": {
    "id": "05840970-630c-4152-bdc6-2c25e81fefff"
   },
   "source": [
    "## Testing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68",
   "metadata": {
    "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember to call orig.is_projective() to check for projectivity!!\n",
    "sentence = train_dataset[10]\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
    "orig.is_projective(gold_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6464ec95-43b7-457a-b764-8ce310c34207",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6464ec95-43b7-457a-b764-8ce310c34207",
    "outputId": "df7821b4-3b23-47cc-c702-c4904803458d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non projective:  167\n",
      "correct:  282533\n",
      "wrong:  0\n"
     ]
    }
   ],
   "source": [
    "### NOTE: THIS CELL WAS COPIED WITH FEW MODIFICATIONS FROM THE ORIGINAL FILE\n",
    "\n",
    "# oracle test: run the parser guided by the oracle on the entire training set \n",
    "\n",
    "non_projective = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "for sample in train_dataset:\n",
    "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
    "\n",
    "    if not orig.is_projective(gold_tree):\n",
    "        non_projective += 1\n",
    "        continue\n",
    "\n",
    "    parser = ArcStandard(tokens, deprels)\n",
    "    oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "    while not parser.is_tree_final():\n",
    "        if oracle.is_left_arc_gold(): \n",
    "            parser.left_arc(oracle.get_gold_label())\n",
    "        elif oracle.is_right_arc_gold():\n",
    "            parser.right_arc(oracle.get_gold_label())\n",
    "        elif oracle.is_shift_gold(): \n",
    "            parser.shift()\n",
    "\n",
    "    for j in range(len(gold_tree)):  # comparing heads from parser and gold for actual sample\n",
    "        if gold_tree[j] == parser.arcs[j][0] and gold_labels[j] == parser.arcs[j][1]: \n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "print(\"non projective: \", non_projective)\n",
    "print(\"correct: \", correct)\n",
    "print(\"wrong: \", wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
   "metadata": {
    "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
    "outputId": "f87fd0da-15df-4d67-829e-21be6b0ee436"
   },
   "source": [
    "## Creating samples for the neural oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "453c9ca5-9c30-4813-bf82-2555efaeac12",
   "metadata": {
    "id": "453c9ca5-9c30-4813-bf82-2555efaeac12"
   },
   "outputs": [],
   "source": [
    "# Modified from the original\n",
    "\"\"\"\n",
    "This function processes a single sample, which is one sentence provided as an element of a Dataset object and returns \n",
    "    enc_sentence : a list of integers encoding the phrase #???? is this even correct for BERT???\n",
    "    gold_path : a list of configurations\n",
    "    gold_moves : a list of (move, label)\n",
    "\"\"\"\n",
    "def process_sample(sample, emb_dictionary, deprels, get_gold_path = False): #emb_dictionary and deprels are dictionaries of words and of dependency relations\n",
    "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
    "    #print(\"DEBUG:\", tokens)\n",
    "    enc_sentence = [emb_dictionary[word] if word in emb_dictionary else emb_dictionary[\"<unk>\"] for word in tokens]\n",
    "    #print(\"DEBUG:\", enc_sentence)\n",
    "    \n",
    "    # gold_path and gold_moves are parallel arrays whose elements refer to parsing steps\n",
    "    gold_path = []   # record two topmost stack token and first buffer token for current step\n",
    "    gold_moves = []  # oracle (canonical) move for current step: 100 is left, 0 right, -100 shift #motivations provided above TODO\n",
    "\n",
    "    if get_gold_path:  # only for training\n",
    "        parser = ArcStandard(enc_sentence, deprels)\n",
    "        oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "        while not parser.is_tree_final():\n",
    "            configuration = [parser.stack[len(parser.stack)-2], parser.stack[len(parser.stack)-1]]\n",
    "            if len(parser.buffer) == 0:\n",
    "                configuration.append(-1)\n",
    "            else:\n",
    "                configuration.append(parser.buffer[0])\n",
    "\n",
    "            gold_path.append(configuration)\n",
    "            \n",
    "            if oracle.is_left_arc_gold():\n",
    "                label_code = oracle.get_gold_label() #deprels[oracle.get_gold_label()]\n",
    "                parser.left_arc(label_code)\n",
    "                gold_moves.append((100, label_code)) #note: I switched the instructions here for symmetry. There was no comment or good reason not to.\n",
    "            elif oracle.is_right_arc_gold():\n",
    "                label_code = oracle.get_gold_label() #deprels[oracle.get_gold_label()]\n",
    "                parser.right_arc(label_code)\n",
    "                gold_moves.append((0, label_code))\n",
    "            elif oracle.is_shift_gold():\n",
    "                parser.shift()\n",
    "                gold_moves.append((-100, -100))\n",
    "            else:\n",
    "                print(\"**** AN ERROR OCCURRED ****\")\n",
    "                #print(tokens)\n",
    "                #print(enc_sentence)\n",
    "                #print(gold_tree)\n",
    "                parser.print_configuration()\n",
    "                raise Exception(\"No action identified as gold!! Please make sure your dataset doesn't contain nonprojective trees.\")\n",
    "                \n",
    "            #print(\"DEBUG: \", parser.stack)\n",
    "    \n",
    "    #print(\"DEBUG: length of path: \", len(gold_path), \"length of moves: \", len(gold_moves))\n",
    "    return enc_sentence, gold_path, gold_moves, gold_tree, gold_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d214f7df-0622-40df-9ce6-ace620105cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_sentence = train_dataset[88]\\nemb_dictionary = orig.create_dict(train_dataset)\\ndeprels = create_deprel_dict(train_dataset)\\n\\nprocess_sample(test_sentence, emb_dictionary, deprels, get_gold_path = True)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Code to test process_sample\n",
    "\"\"\"\n",
    "test_sentence = train_dataset[88]\n",
    "emb_dictionary = orig.create_dict(train_dataset)\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "process_sample(test_sentence, emb_dictionary, deprels, get_gold_path = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1",
   "metadata": {
    "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that prepares the data for the model.\n",
    "@return sentences : list of sentences in the dataset encoded according to emb_dictionary\n",
    "@return paths : list of lists of configurations visited during the oracle-guided parsing (on training data) | empty list if get_gold_path is False\n",
    "@return moves : list of lists of (MOVE, LABEL) performed during the oracle-guided parsing (on training data) | empty if get_gold_path is False\n",
    "@return trees : ground truth tree\n",
    "@return labels : ground truth lables\n",
    "\n",
    "Note: the last two returned values may eventually be zipped together for faster loss calculation.\n",
    "\"\"\"\n",
    "#modified form orig\n",
    "def prepare_batch(batch_data, emb_dictionary, deprels, get_gold_path=False):\n",
    "    data = [process_sample(s, emb_dictionary, deprels, get_gold_path=get_gold_path) for s in batch_data]\n",
    "    # sentences, paths, moves, trees are parallel arrays, each element refers to a sentence\n",
    "    sentences = [s[0] for s in data]\n",
    "    paths = [s[1] for s in data]\n",
    "    moves = [s[2] for s in data]\n",
    "    trees = [s[3] for s in data]\n",
    "    labels = [s[4] for s in data]\n",
    "    return sentences, paths, moves, trees, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f3002b0-00f7-4f95-82f7-215b97ada014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nemb_dictionary = orig.create_dict(train_dataset)\\ndeprels = create_deprel_dict(train_dataset)\\n\\n_ = prepare_batch(iter(train_dataset), emb_dictionary, deprels, True)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### code to test prepare_batch\n",
    "\"\"\"\n",
    "emb_dictionary = orig.create_dict(train_dataset)\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "_ = prepare_batch(iter(train_dataset), emb_dictionary, deprels, True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dc8dfb6-91e4-425d-8406-bd427b31d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return indices of projective sentences in the dataset. Must be used with select() to filter out nonprojective trees.\n",
    "\"\"\"\n",
    "def find_projective_idx(dataset):\n",
    "    ret = []\n",
    "    for i in range(len(dataset)):\n",
    "        x = dataset[i]\n",
    "        if orig.is_projective([-1] + [int(head) for head in x[\"head\"] if head!='None']):\n",
    "            ret.append(i)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "011f24bd730644c98fcd2874810912de",
      "c2808465ed9a4b33beb16b87b51ff0a3",
      "790dbcfa114e418b8b0c5531dc08919e",
      "f8896a0ad23f4827880c4618a4c3d48b",
      "8f5364f179584d1aa53afc0567738d20",
      "cf36f6cfcd78495382a0ac29c57c1234",
      "800087fe826b4a899ddc232a5ab19e1d",
      "ed6f4348a55146dcaa66fd2fe666ba25",
      "48b10389415c42f2babb2a4cc887ac28",
      "72344d1e08924bbd9ec67d22d9f0175f",
      "e75b59f896ae47e5bd0a0cbc6dd705a1"
     ]
    },
    "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
    "outputId": "5124e913-0809-440f-810f-a380f4797bc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n"
     ]
    }
   ],
   "source": [
    "tmp_train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")\n",
    "dev_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"validation\")\n",
    "test_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"test\")\n",
    "\n",
    "train_dataset = tmp_train_dataset.select(find_projective_idx(tmp_train_dataset)) #to remove nonprojective trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bcb2cbf-eebb-4099-bba8-a05925919abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dictionary = orig.create_dict(train_dataset)\n",
    "deprels = create_deprel_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51d176de-aa6a-4258-ab75-e46c772beb81",
   "metadata": {
    "id": "51d176de-aa6a-4258-ab75-e46c772beb81"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels, get_gold_path=True))\n",
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52DDEpoy2T6F",
   "metadata": {
    "id": "52DDEpoy2T6F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: length of path:  36 length of moves:  36\n",
      "DEBUG: length of path:  20 length of moves:  20\n",
      "DEBUG: length of path:  46 length of moves:  46\n",
      "DEBUG: length of path:  28 length of moves:  28\n",
      "DEBUG: length of path:  28 length of moves:  28\n",
      "DEBUG: length of path:  70 length of moves:  70\n",
      "DEBUG: length of path:  48 length of moves:  48\n",
      "DEBUG: length of path:  98 length of moves:  98\n",
      "DEBUG: length of path:  22 length of moves:  22\n",
      "DEBUG: length of path:  4 length of moves:  4\n",
      "DEBUG: length of path:  16 length of moves:  16\n",
      "DEBUG: length of path:  10 length of moves:  10\n",
      "DEBUG: length of path:  20 length of moves:  20\n",
      "DEBUG: length of path:  76 length of moves:  76\n",
      "DEBUG: length of path:  34 length of moves:  34\n",
      "DEBUG: length of path:  36 length of moves:  36\n",
      "DEBUG: length of path:  12 length of moves:  12\n",
      "DEBUG: length of path:  42 length of moves:  42\n",
      "DEBUG: length of path:  30 length of moves:  30\n",
      "DEBUG: length of path:  62 length of moves:  62\n",
      "DEBUG: length of path:  18 length of moves:  18\n",
      "DEBUG: length of path:  38 length of moves:  38\n",
      "DEBUG: length of path:  24 length of moves:  24\n",
      "DEBUG: length of path:  26 length of moves:  26\n",
      "DEBUG: length of path:  92 length of moves:  92\n",
      "DEBUG: length of path:  106 length of moves:  106\n",
      "DEBUG: length of path:  36 length of moves:  36\n",
      "DEBUG: length of path:  26 length of moves:  26\n",
      "DEBUG: length of path:  42 length of moves:  42\n",
      "DEBUG: length of path:  16 length of moves:  16\n",
      "DEBUG: length of path:  82 length of moves:  82\n",
      "DEBUG: length of path:  16 length of moves:  16\n"
     ]
    }
   ],
   "source": [
    "sentences, paths, moves, trees, labels = next(iter(train_dataloader)) #<--- arresto anomalo per saturazione RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b",
   "metadata": {
    "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b"
   },
   "source": [
    "## Ideas for the future\n",
    "* Use mean square error to predict pairs (MOVE, LABEL) in the training set\n",
    "* We need to rescale the data in an acceptable range. Probably should make the MOVE have greater variation, e.g LeftArc=100 RightArc=0 Shift=-100\n",
    "* BERT layer must process each sentence separately to produce word embeddings, but it should also be finetuned alongside the fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xNoPh6s17yyx",
   "metadata": {
    "id": "xNoPh6s17yyx"
   },
   "source": [
    "# Neural Oracle\n",
    "\n",
    "Neural oracle implemented using BERT fine-tunned with a simple classifiers.\n",
    "The references are: [Towards Data Science](https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f) and [Text Classification | Sentiment Analysis with BERT using huggingface, PyTorch and Python Tutorial](https://www.youtube.com/watch?v=8N-nM3QW7O0).\n",
    "\n",
    "The hyperparameters and the training tweaks are taken from the original BERT paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c1ATofEBdwL",
   "metadata": {
    "id": "0c1ATofEBdwL"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "bert_model = 'dbmdz/bert-base-italian-xxl-cased'\n",
    "dropout = 0.3\n",
    "n_classes = 2\n",
    "n_classes_test = 1\n",
    "learning_rate = 2e-5\n",
    "epochs = 1\n",
    "save_path = \"path_were_to_save_model\"\n",
    "tokenizer_max_len = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ZfqzDHLLA08V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9da1244774f146a99fe8f9b00846039f",
      "d1c4641eb8674b0197157a5b664c9b6c",
      "7dc9839c24414c618e534158e201ab47",
      "6679afdeaa1e4b8582ca6fd522ef6a56",
      "84439a5f1c904136871bb1f153858efb",
      "51d5741dec2d4b3bbe4db1788efc3201",
      "ce6fac0028bf4769a47a89b33cc930ba",
      "0c6e4b6d36714c44bdd60ff22abd12d3",
      "b76373c0eed547ab840d9434307a88f1",
      "9782bcbb41f74daebf422d7c138c87d6",
      "803dad51cb5c47ba848913b69f491388",
      "dd26a44ee0f646e7ad020cf23561f1ec",
      "700d14c11d8f48ff8f88473beb352541",
      "80d16eea34df4aa58107470fae680241",
      "94c585290af74eef8db607560cd3476d",
      "0f2613de2594472987dcf87471cff45f",
      "d4b23a931d584438a9873b4d79250546",
      "170db99594d94d70891ca6c82339b84b",
      "7ab17378f8a5496bb3ad85afa9839030",
      "d111d077ca3c47e6abcfb1d95c82ddd7",
      "908fe35172f346bd8b15728d31bb066b",
      "9c179c15da554fc39248f078ed968eda"
     ]
    },
    "id": "ZfqzDHLLA08V",
    "outputId": "60dc1af9-b078-4a4f-c667-e1cd68f2f542"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da1244774f146a99fe8f9b00846039f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/230k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd26a44ee0f646e7ad020cf23561f1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the BERT tokenizer with pretrained weights for the Italian language\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "QtZZfEGK9IG5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtZZfEGK9IG5",
    "outputId": "0e8d3d8e-87ed-4152-9786-3720e091dd91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  102,   401,   162,  1909,   532, 27948,  2369,   139,  5101,  1783,\n",
      "           223,  1731,   146, 16711,   103]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "[CLS] Con il termine interfluvio in geologia si indica la porzione [SEP]\n"
     ]
    }
   ],
   "source": [
    "example_text = '''Con il termine interfluvio in geologia si indica la porzione di superﬁcie più elevata\n",
    "                  che separa due valli ﬂuviali adiacenti, che può essere una cresta oppure un' area ampia,\n",
    "                  comunque non coinvolta dal movimento delle acque'''\n",
    "\n",
    "\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length = 15, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(bert_input['input_ids'])      # words to integer\n",
    "print(bert_input['token_type_ids']) # binary mask that identifies whether a token is a real word or just padding\n",
    "print(bert_input['attention_mask']) # identifies whether a token is a real word or just padding\n",
    "\n",
    "decoded_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iEAbjVkDOwbB",
   "metadata": {
    "id": "iEAbjVkDOwbB"
   },
   "source": [
    "## Prepare data to be fed into the BERT Oracle using the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mxtuOhzE6rTi",
   "metadata": {
    "id": "mxtuOhzE6rTi"
   },
   "source": [
    "  ## Oracle model using BERT\n",
    "  The oracle, as we intended, is just a classifier that, for each possibile configuration provided, outputs the right pair of (MOVE, LABEL) as if they were simple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "KkXDGmBW-vFo",
   "metadata": {
    "id": "KkXDGmBW-vFo"
   },
   "outputs": [],
   "source": [
    "class BertOracle(nn.Module):\n",
    "  def __init__(self, dropout_rate, n_classes, bert_model):\n",
    "        super(BertOracle, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(bert_model, return_dict=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "  def forward(self, input_tokens, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "        input_ids = input_tokens,\n",
    "        attention_mask = attention_mask\n",
    "    )\n",
    "    output = self.dropout(pooled_output)\n",
    "    output = self.out(output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oUpbfnjJBTvv",
   "metadata": {
    "id": "oUpbfnjJBTvv"
   },
   "outputs": [],
   "source": [
    "model = BertOracle(dropout, n_classes, bert_model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QRk1Qh53F5EG",
   "metadata": {
    "id": "QRk1Qh53F5EG"
   },
   "source": [
    "## Training and evaluation functions\n",
    "Linear scheduler: used to decay the learning rates to improve training performacnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "AaJXSRebF7EE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaJXSRebF7EE",
    "outputId": "67ba7670-6e60-4a4e-ea74-43987f64a496"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = learning_rate, correct_bias = False)\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler  = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss().to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4h-Y7lj8INBz",
   "metadata": {
    "id": "4h-Y7lj8INBz"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "\n",
    "  for batch in data_loader:\n",
    "    optimizer.zero_grad()                                     # initialize gradient to zeros\n",
    "    sentences, paths, moves, trees, labels = batch            # unpack the batch (created above w/ prepare_batch)\n",
    "    moves = torch.FloatTensor(moves)\n",
    "\n",
    "    preprocessed_text = tokenizer(str(sentences), padding='max_length', max_length = tokenizer_max_len, \n",
    "                       truncation=True, return_tensors=\"pt\")  # tokenize input using BERT tokenizer\n",
    "    input_tokens = preprocessed_text[\"input_ids\"]\n",
    "    attention_mask = preprocessed_text[\"attention_mask\"]\n",
    "\n",
    "    outputs = model(\n",
    "        input_tokens = input_tokens,\n",
    "        attention_mask = attention_mask\n",
    "    )\n",
    "\n",
    "    loss = loss_fn(outputs, moves)\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "\n",
    "    #backpropagation routine\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm(model.parameters(), max_norm = 1.0) # gradient clipping to avoid exploding gradients if they become too large\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "  mean_loss = np.mean(losses)\n",
    "\n",
    "  return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "idw5no5rK0Ea",
   "metadata": {
    "id": "idw5no5rK0Ea"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, optimzier, device, scheduler, n_examples):\n",
    "  model = model.eval()                                         # dropout and batch_norm are not enabled\n",
    "\n",
    "  losses = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:    \n",
    "      optimizer.zero_grad()                                     # initialize gradient to zeros\n",
    "      sentences, paths, moves, trees, labels = batch            # unpack the batch (created above w/ prepare_batch)\n",
    "      moves = torch.FloatTensor(moves)\n",
    "\n",
    "      preprocessed_text = tokenizer(str(sentences), padding='max_length', max_length = tokenizer_max_len, \n",
    "                        truncation=True, return_tensors=\"pt\")  # tokenize input using BERT tokenizer\n",
    "      input_tokens = preprocessed_text[\"input_ids\"]\n",
    "      attention_mask = preprocessed_text[\"attention_mask\"]\n",
    "\n",
    "      outputs = model(\n",
    "          input_tokens = input_tokens,\n",
    "          attention_mask = attention_mask\n",
    "      )\n",
    "\n",
    "      loss = loss_fn(outputs, moves)\n",
    "\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  mean_loss = np.mean(losses)\n",
    "\n",
    "  return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4qhZPXfxLo67",
   "metadata": {
    "id": "4qhZPXfxLo67"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ngRlytTZLqnK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "ngRlytTZLqnK",
    "outputId": "d9b3ef76-570f-49cb-f704-200d8eff22a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.48 µs\n",
      "Epoch 1 / 1\n",
      "----------\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 2])\n",
      "tensor([], size=(32, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([32, 0])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-77438b429a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m#Training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train loss {train_loss} Train accuracy {train_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-20d963ba5d5e>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3259\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (0) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "%time                      \n",
    "\n",
    "history = defaultdict(list) # store training and validation losses and accuracy in a dictionary \n",
    "best_accuracy = 0           # save model with best accuracy only (can be used for early stopping)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(f'Epoch {epoch + 1} / {epochs}')\n",
    "  print('-'*10)\n",
    "\n",
    "  #Training step\n",
    "  train_acc, train_loss = train_epoch(model, dev_dataloader, loss_fn, optimizer, device, scheduler, n_classes)\n",
    "\n",
    "  print(f\"Train loss {train_loss} Train accuracy {train_acc}\")\n",
    "\n",
    "  #Evaluation step\n",
    "  val_acc, val_loss = eval_model(model, dev_dataloader, loss_fn, optimizer, device, scheduler, n_classes)\n",
    "\n",
    "  print(f\"Val loss {val_loss} Val accuracy {val_acc}\")\n",
    "\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model, save_path)\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Om8sss6qfK-L",
   "metadata": {
    "id": "Om8sss6qfK-L"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cTUAeO4EfMZU",
   "metadata": {
    "id": "cTUAeO4EfMZU"
   },
   "outputs": [],
   "source": [
    "def get_label_action_pairs(model, data_loader):\n",
    "  model = model.eval()\n",
    "\n",
    "  label_action_pairs = []\n",
    "  predictions = []\n",
    "\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:    \n",
    "      optimizer.zero_grad()                                     # initialize gradient to zeros\n",
    "      sentences, paths, moves, trees, labels = batch            # unpack the batch (created above w/ prepare_batch)\n",
    "      moves = torch.FloatTensor(moves)\n",
    "\n",
    "      preprocessed_text = tokenizer(str(sentences), padding='max_length', max_length = tokenizer_max_len, \n",
    "                        truncation=True, return_tensors=\"pt\")  # tokenize input using BERT tokenizer\n",
    "      input_tokens = preprocessed_text[\"input_ids\"]\n",
    "      attention_mask = preprocessed_text[\"attention_mask\"]\n",
    "\n",
    "      outputs = model(\n",
    "          input_tokens = input_tokens,\n",
    "          attention_mask = attention_mask\n",
    "      )\n",
    "\n",
    "      label_action_pairs.extends(moves)\n",
    "      predictions.extend(outputs)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  return label_action_pairs, predictions, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cRkOxD2Dh6n2",
   "metadata": {
    "id": "cRkOxD2Dh6n2"
   },
   "outputs": [],
   "source": [
    "test_acc, test_loss = eval_model(model, test_dataloader, loss_fn, device, n_classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kSzEvwpehpAu",
   "metadata": {
    "id": "kSzEvwpehpAu"
   },
   "outputs": [],
   "source": [
    "y_real_moves_pairs, y_pred_moves_pairs = get_label_action_pairs(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
    "747b671a-fd4b-4cbd-a602-a9a25da5e4b2",
    "5a1b7b56-5928-4ca4-9427-0a5edd150ecd"
   ],
   "name": "our_dep_parser.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "011f24bd730644c98fcd2874810912de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2808465ed9a4b33beb16b87b51ff0a3",
       "IPY_MODEL_790dbcfa114e418b8b0c5531dc08919e",
       "IPY_MODEL_f8896a0ad23f4827880c4618a4c3d48b"
      ],
      "layout": "IPY_MODEL_8f5364f179584d1aa53afc0567738d20"
     }
    },
    "0c6e4b6d36714c44bdd60ff22abd12d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f2613de2594472987dcf87471cff45f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "170db99594d94d70891ca6c82339b84b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48b10389415c42f2babb2a4cc887ac28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "51d5741dec2d4b3bbe4db1788efc3201": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6679afdeaa1e4b8582ca6fd522ef6a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9782bcbb41f74daebf422d7c138c87d6",
      "placeholder": "​",
      "style": "IPY_MODEL_803dad51cb5c47ba848913b69f491388",
      "value": " 230k/230k [00:00&lt;00:00, 924kB/s]"
     }
    },
    "700d14c11d8f48ff8f88473beb352541": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4b23a931d584438a9873b4d79250546",
      "placeholder": "​",
      "style": "IPY_MODEL_170db99594d94d70891ca6c82339b84b",
      "value": "Downloading: 100%"
     }
    },
    "72344d1e08924bbd9ec67d22d9f0175f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "790dbcfa114e418b8b0c5531dc08919e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed6f4348a55146dcaa66fd2fe666ba25",
      "max": 14,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48b10389415c42f2babb2a4cc887ac28",
      "value": 14
     }
    },
    "7ab17378f8a5496bb3ad85afa9839030": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dc9839c24414c618e534158e201ab47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c6e4b6d36714c44bdd60ff22abd12d3",
      "max": 235127,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b76373c0eed547ab840d9434307a88f1",
      "value": 235127
     }
    },
    "800087fe826b4a899ddc232a5ab19e1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "803dad51cb5c47ba848913b69f491388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80d16eea34df4aa58107470fae680241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ab17378f8a5496bb3ad85afa9839030",
      "max": 59,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d111d077ca3c47e6abcfb1d95c82ddd7",
      "value": 59
     }
    },
    "84439a5f1c904136871bb1f153858efb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f5364f179584d1aa53afc0567738d20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "908fe35172f346bd8b15728d31bb066b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94c585290af74eef8db607560cd3476d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_908fe35172f346bd8b15728d31bb066b",
      "placeholder": "​",
      "style": "IPY_MODEL_9c179c15da554fc39248f078ed968eda",
      "value": " 59.0/59.0 [00:00&lt;00:00, 1.56kB/s]"
     }
    },
    "9782bcbb41f74daebf422d7c138c87d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c179c15da554fc39248f078ed968eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9da1244774f146a99fe8f9b00846039f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1c4641eb8674b0197157a5b664c9b6c",
       "IPY_MODEL_7dc9839c24414c618e534158e201ab47",
       "IPY_MODEL_6679afdeaa1e4b8582ca6fd522ef6a56"
      ],
      "layout": "IPY_MODEL_84439a5f1c904136871bb1f153858efb"
     }
    },
    "b76373c0eed547ab840d9434307a88f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c2808465ed9a4b33beb16b87b51ff0a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf36f6cfcd78495382a0ac29c57c1234",
      "placeholder": "​",
      "style": "IPY_MODEL_800087fe826b4a899ddc232a5ab19e1d",
      "value": "100%"
     }
    },
    "ce6fac0028bf4769a47a89b33cc930ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf36f6cfcd78495382a0ac29c57c1234": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d111d077ca3c47e6abcfb1d95c82ddd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d1c4641eb8674b0197157a5b664c9b6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51d5741dec2d4b3bbe4db1788efc3201",
      "placeholder": "​",
      "style": "IPY_MODEL_ce6fac0028bf4769a47a89b33cc930ba",
      "value": "Downloading: 100%"
     }
    },
    "d4b23a931d584438a9873b4d79250546": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd26a44ee0f646e7ad020cf23561f1ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_700d14c11d8f48ff8f88473beb352541",
       "IPY_MODEL_80d16eea34df4aa58107470fae680241",
       "IPY_MODEL_94c585290af74eef8db607560cd3476d"
      ],
      "layout": "IPY_MODEL_0f2613de2594472987dcf87471cff45f"
     }
    },
    "e75b59f896ae47e5bd0a0cbc6dd705a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed6f4348a55146dcaa66fd2fe666ba25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8896a0ad23f4827880c4618a4c3d48b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72344d1e08924bbd9ec67d22d9f0175f",
      "placeholder": "​",
      "style": "IPY_MODEL_e75b59f896ae47e5bd0a0cbc6dd705a1",
      "value": " 14/14 [00:04&lt;00:00,  3.16ba/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
