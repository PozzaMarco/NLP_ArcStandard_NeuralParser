{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c041f954-42d3-44e6-b2c2-281d579e61e6",
      "metadata": {
        "id": "c041f954-42d3-44e6-b2c2-281d579e61e6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f",
      "metadata": {
        "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
      "metadata": {
        "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5"
      },
      "source": [
        "## Arc-standard\n",
        "\n",
        "Recall that a **configuration** of the arc-standard parser is a triple of the form $( \\sigma, \\beta, A)$\n",
        "where:\n",
        "\n",
        "* $\\sigma$ is the stack;\n",
        "* $\\beta$ is the input buffer;\n",
        "* $A$ is a set of arcs constructed so far.\n",
        "\n",
        "We write $\\sigma_i$, $i \\geq 1$, for the $i$-th token in the stack; we also write $\\beta_i$, $i \\geq 1$, for the $i$-th token in the buffer. \n",
        "\n",
        "The parser can perform three types of **actions** (transitions):\n",
        "\n",
        "* **shift**, which removes $\\beta_1$ from the buffer and pushes it into the stack;\n",
        "* **left-arc**, which creates the arc $(\\sigma_1 \\rightarrow \\sigma_2)$, and removes $\\sigma_2$ from the stack;\n",
        "* **right-arc**, which creates the arc $(\\sigma_2 \\rightarrow \\sigma_1)$, and removes $\\sigma_1$ from the stack.\n",
        "\n",
        "Let $w = w_0 w_1 \\cdots w_{n}$ be the input sentence, with $w_0$ the special symbol `<ROOT>`.\n",
        "Stack and buffer are implemented as lists of integers, where `j` represents word $w_j$.  Top-most stack token is at the right-end of the list; first buffer token is at the left-end of the list. \n",
        "Set $A$ is implemented as an array `arcs` of size $n+1$ such that if arc $(w_i \\rightarrow w_j)$ is in $A$ then `arcs[j]=i`, and if $w_j$ is still missing its head node in the tree under construction, then `arcs[j]=-1`. We always have `arcs[0]=-1`.  We use this representation also for complete dependency trees.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf",
      "metadata": {
        "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf"
      },
      "outputs": [],
      "source": [
        "import orig #file orig.py in the same foldr contains original class and function definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7",
      "metadata": {
        "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7"
      },
      "outputs": [],
      "source": [
        "class ArcStandard (orig.ArcStandard):\n",
        "    def __init__(self, sentence, label_set):\n",
        "        self.sentence = sentence\n",
        "        self.buffer = [i for i in range(len(self.sentence))]\n",
        "        self.stack = []\n",
        "        self.arcs = [(-1, -1) for _ in range(len(self.sentence))]# head - relation converted to int\n",
        "\n",
        "        self.label_set = {y:x for x,y in label_set.items()} #for future reference (printing)\n",
        "        # three shift moves to initialize the stack\n",
        "        self.shift()\n",
        "        self.shift()\n",
        "        if len(self.sentence) > 2:\n",
        "            self.shift()\n",
        "\n",
        "    def left_arc(self, deprel):\n",
        "        o1 = self.stack.pop()\n",
        "        o2 = self.stack.pop()\n",
        "        self.arcs[o2] = (o1, deprel) #added deprel\n",
        "        self.stack.append(o1)\n",
        "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
        "            self.shift()\n",
        "\n",
        "    def right_arc(self, deprel):\n",
        "        o1 = self.stack.pop()\n",
        "        o2 = self.stack.pop()\n",
        "        self.arcs[o1] = (o2, deprel) #added deprel\n",
        "        self.stack.append(o2)\n",
        "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
        "            self.shift()\n",
        "\n",
        "    def print_configuration(self):\n",
        "        s = [self.sentence[i] for i in self.stack]\n",
        "        b = [self.sentence[i] for i in self.buffer]\n",
        "        print(\"STACK: \", s, \"BUFFER: \", b) #added indication of stack and buffer\n",
        "        print([(x[0], self.label_set[x[1]]) for x in self.arcs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d836502-bba0-4f49-9c39-39a916ed270c",
      "metadata": {
        "id": "1d836502-bba0-4f49-9c39-39a916ed270c"
      },
      "outputs": [],
      "source": [
        "class Oracle (orig.Oracle):\n",
        "    def __init__(self, parser, gold_tree, gold_labels):\n",
        "        self.parser = parser\n",
        "        self.gold = gold_tree\n",
        "        self.labels = gold_labels #must be integers; see below\n",
        "\n",
        "    def get_gold_label(self):\n",
        "        if(self.is_left_arc_gold()):\n",
        "            o2 = self.parser.stack[len(self.parser.stack)-2]\n",
        "            return self.labels[o2]\n",
        "        elif(self.is_right_arc_gold()):\n",
        "            o1 = self.parser.stack[len(self.parser.stack)-1]\n",
        "            return self.labels[o1]\n",
        "        else:\n",
        "            raise Exception(\"Action SHIFT does not produce a labeled dependency\")\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2",
      "metadata": {
        "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2"
      },
      "source": [
        "## Functions to simplify the processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374",
      "metadata": {
        "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "dataset should be a Dataset object from HuggingFace\n",
        "Return a dictionary where arc labels are associate to integer values.\n",
        "Label '_' is removed (used for composite tokens)\n",
        "Labels are sorted in alphabetical order because MSE in the neural network will penalize less classes that are \"close\".\n",
        "<ROOT> label is given value -1 (label of the <ROOT> node).\n",
        "\"\"\"\n",
        "def create_deprel_dict(dataset):\n",
        "    labels = set()\n",
        "    for x in dataset['deprel']:\n",
        "        for elem in x:\n",
        "            if(elem != '_'):\n",
        "                labels.add(elem)\n",
        "    labels = sorted(list(labels))\n",
        "    ret = {labels[i]:i for i in range(len(labels))}\n",
        "    ret.update({\"None\":-1})\n",
        "    return ret\n",
        "\n",
        "\"\"\"\n",
        "Return (sanitized_tokens, gold tree, gold labels) for a sentence in the dataset, assuming gold tree is in a column labeled 'head' and labels in a column labeled 'deprel'.\n",
        "Both token indices and labels are converted to integer (in the latter case, according to deprel_dict).\n",
        "Sanitized tokens is a tokenlist with removal of composite tokens.\n",
        "\"\"\"\n",
        "def create_gold(sentence, deprel_dict):\n",
        "    sanitized = ['<ROOT>']\n",
        "    gold_tree = [-1]\n",
        "    gold_labels = [-1]\n",
        "    for i in range(len(sentence['tokens'])):\n",
        "        if(sentence['head'][i] != 'None'):\n",
        "            sanitized.append(sentence['tokens'][i])\n",
        "            gold_tree.append(int(sentence['head'][i]))\n",
        "            gold_labels.append(deprel_dict[sentence['deprel'][i]])\n",
        "    \n",
        "    return sanitized, gold_tree, gold_labels "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd",
      "metadata": {
        "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd"
      },
      "source": [
        "## Testing parser and oracle..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21bcbd5e-b121-4cef-992f-f22df16e4315",
      "metadata": {
        "id": "21bcbd5e-b121-4cef-992f-f22df16e4315"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9269d170-abea-4671-b795-a9026fc3e46a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9269d170-abea-4671-b795-a9026fc3e46a",
        "outputId": "3fb46291-7570-4bae-d7aa-2dee3e8e5877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<ROOT>', 'Inconsueto', 'allarme', 'a', 'la', 'Tate', 'Gallery', ':']\n",
            "[-1, 2, 0, 5, 5, 2, 5, 2]\n",
            "[-1, 4, 41, 8, 17, 31, 28, 40]\n"
          ]
        }
      ],
      "source": [
        "deprels = create_deprel_dict(train_dataset)\n",
        "sentence = train_dataset[3]\n",
        "\n",
        "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
        "\n",
        "print(tokens)\n",
        "print(gold_tree)\n",
        "print(gold_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
        "outputId": "2b64b18e-0d5f-4a6d-b8fb-6b237c50c918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STACK:  ['<ROOT>', 'Inconsueto', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
            "[(-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n"
          ]
        }
      ],
      "source": [
        "parser = ArcStandard(tokens, deprels)\n",
        "oracle = Oracle(parser, gold_tree, gold_labels)\n",
        "\n",
        "parser.print_configuration()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
        "outputId": "b28adc77-dc18-4a92-cbe2-de180876cf45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STACK:  ['<ROOT>', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'a'] BUFFER:  ['la', 'Tate', 'Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'a', 'la'] BUFFER:  ['Tate', 'Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'a', 'la', 'Tate'] BUFFER:  ['Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'a', 'Tate'] BUFFER:  ['Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  ['Gallery', ':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'Tate', 'Gallery'] BUFFER:  [':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  [':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (5, 'flat:name'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme'] BUFFER:  [':']\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme', ':'] BUFFER:  []\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
            "STACK:  ['<ROOT>', 'allarme'] BUFFER:  []\n",
            "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n",
            "STACK:  ['<ROOT>'] BUFFER:  []\n",
            "[(-1, 'None'), (2, 'amod'), (0, 'root'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n"
          ]
        }
      ],
      "source": [
        "while not parser.is_tree_final():  # transition precedence implemented here\n",
        "    if oracle.is_shift_gold():  \n",
        "        parser.shift()\n",
        "    elif oracle.is_left_arc_gold():\n",
        "        parser.left_arc(oracle.get_gold_label())\n",
        "    elif oracle.is_right_arc_gold():\n",
        "        parser.right_arc(oracle.get_gold_label())\n",
        "    \n",
        "    parser.print_configuration()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05840970-630c-4152-bdc6-2c25e81fefff",
      "metadata": {
        "id": "05840970-630c-4152-bdc6-2c25e81fefff"
      },
      "source": [
        "## Testing the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68",
      "metadata": {
        "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5ddb1d-1458-4cea-c074-269429fd5e88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# remember to call orig.is_projective() to check for projectivity!!\n",
        "sentence = train_dataset[10]\n",
        "deprels = create_deprel_dict(train_dataset)\n",
        "\n",
        "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
        "orig.is_projective(gold_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6464ec95-43b7-457a-b764-8ce310c34207",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6464ec95-43b7-457a-b764-8ce310c34207",
        "outputId": "d7c66e92-5550-4bbd-aa72-4904578be079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "non projective:  167\n",
            "correct:  282533\n",
            "wrong:  0\n"
          ]
        }
      ],
      "source": [
        "### NOTE: THIS CELL WAS COPIED WITH FEW MODIFICATIONS FROM THE ORIGINAL FILE\n",
        "\n",
        "# oracle test: run the parser guided by the oracle on the entire training set \n",
        "\n",
        "non_projective = 0\n",
        "correct = 0\n",
        "wrong = 0\n",
        "\n",
        "deprels = create_deprel_dict(train_dataset)\n",
        "\n",
        "for sample in train_dataset:\n",
        "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
        "\n",
        "    if not orig.is_projective(gold_tree):\n",
        "        non_projective += 1\n",
        "        continue\n",
        "\n",
        "    parser = ArcStandard(tokens, deprels)\n",
        "    oracle = Oracle(parser, gold_tree, gold_labels)\n",
        "\n",
        "    while not parser.is_tree_final():\n",
        "        if oracle.is_left_arc_gold(): \n",
        "            parser.left_arc(oracle.get_gold_label())\n",
        "        elif oracle.is_right_arc_gold():\n",
        "            parser.right_arc(oracle.get_gold_label())\n",
        "        elif oracle.is_shift_gold(): \n",
        "            parser.shift()\n",
        "\n",
        "    for j in range(len(gold_tree)):  # comparing heads from parser and gold for actual sample\n",
        "        if gold_tree[j] == parser.arcs[j][0] and gold_labels[j] == parser.arcs[j][1]: \n",
        "            correct += 1\n",
        "        else:\n",
        "            wrong += 1\n",
        "\n",
        "print(\"non projective: \", non_projective)\n",
        "print(\"correct: \", correct)\n",
        "print(\"wrong: \", wrong)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
      "metadata": {
        "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
        "outputId": "f87fd0da-15df-4d67-829e-21be6b0ee436"
      },
      "source": [
        "## Creating samples for the neural oracle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "453c9ca5-9c30-4813-bf82-2555efaeac12",
      "metadata": {
        "id": "453c9ca5-9c30-4813-bf82-2555efaeac12"
      },
      "outputs": [],
      "source": [
        "# Modified from the original\n",
        "\"\"\"\n",
        "This function processes a single sample, which is one sentence provided as an element of a Dataset object and returns \n",
        "    enc_sentence : a list of integers encoding the phrase #???? is this even correct for BERT???\n",
        "    gold_path : a list of configurations\n",
        "    gold_moves : a list of (move, label)\n",
        "\"\"\"\n",
        "def process_sample(sample, emb_dictionary, deprels, get_gold_path = False): #emb_dictionary and deprels are dictionaries of words and of dependency relations\n",
        "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
        "    #print(\"DEBUG:\", tokens)\n",
        "    enc_sentence = [emb_dictionary[word] if word in emb_dictionary else emb_dictionary[\"<unk>\"] for word in tokens]\n",
        "    #print(\"DEBUG:\", enc_sentence)\n",
        "    \n",
        "    # gold_path and gold_moves are parallel arrays whose elements refer to parsing steps\n",
        "    gold_path = []   # record two topmost stack token and first buffer token for current step\n",
        "    gold_moves = []  # oracle (canonical) move for current step: 100 is left, 0 right, -100 shift #motivations provided above TODO\n",
        "\n",
        "    if get_gold_path:  # only for training\n",
        "        parser = ArcStandard(enc_sentence, deprels)\n",
        "        oracle = Oracle(parser, gold_tree, gold_labels)\n",
        "\n",
        "        while not parser.is_tree_final():\n",
        "            configuration = [parser.stack[len(parser.stack)-2], parser.stack[len(parser.stack)-1]]\n",
        "            if len(parser.buffer) == 0:\n",
        "                configuration.append(-1)\n",
        "            else:\n",
        "                configuration.append(parser.buffer[0])\n",
        "\n",
        "            gold_path.append(configuration)\n",
        "            \n",
        "            if oracle.is_left_arc_gold():\n",
        "                label_code = oracle.get_gold_label() #deprels[oracle.get_gold_label()]\n",
        "                parser.left_arc(label_code)\n",
        "                gold_moves.append((100, label_code)) #note: I switched the instructions here for symmetry. There was no comment or good reason not to.\n",
        "            elif oracle.is_right_arc_gold():\n",
        "                label_code = oracle.get_gold_label() #deprels[oracle.get_gold_label()]\n",
        "                parser.right_arc(label_code)\n",
        "                gold_moves.append((0, label_code))\n",
        "            elif oracle.is_shift_gold():\n",
        "                parser.shift()\n",
        "                gold_moves.append((-100, -100))\n",
        "            else:\n",
        "                print(\"**** AN ERROR OCCURRED ****\")\n",
        "                #print(tokens)\n",
        "                #print(enc_sentence)\n",
        "                #print(gold_tree)\n",
        "                parser.print_configuration()\n",
        "                raise Exception(\"No action identified as gold!! Please make sure your dataset doesn't contain nonprojective trees.\")\n",
        "                \n",
        "            #print(\"DEBUG: \", parser.stack)\n",
        "    \n",
        "    #print(\"DEBUG: length of path: \", len(gold_path), \"length of moves: \", len(gold_moves))\n",
        "    return enc_sentence, gold_path, gold_moves, gold_tree, gold_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d214f7df-0622-40df-9ce6-ace620105cc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d214f7df-0622-40df-9ce6-ace620105cc2",
        "outputId": "00698f7d-efe3-4725-e0b7-4092f98c52fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntest_sentence = train_dataset[88]\\nemb_dictionary = orig.create_dict(train_dataset)\\ndeprels = create_deprel_dict(train_dataset)\\n\\nprocess_sample(test_sentence, emb_dictionary, deprels, get_gold_path = True)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "### Code to test process_sample\n",
        "\"\"\"\n",
        "test_sentence = train_dataset[88]\n",
        "emb_dictionary = orig.create_dict(train_dataset)\n",
        "deprels = create_deprel_dict(train_dataset)\n",
        "\n",
        "process_sample(test_sentence, emb_dictionary, deprels, get_gold_path = True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1",
      "metadata": {
        "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Function that prepares the data for the model.\n",
        "@return sentences : list of sentences in the dataset encoded according to emb_dictionary\n",
        "@return paths : list of lists of configurations visited during the oracle-guided parsing (on training data) | empty list if get_gold_path is False\n",
        "@return moves : list of lists of (MOVE, LABEL) performed during the oracle-guided parsing (on training data) | empty if get_gold_path is False\n",
        "@return trees : ground truth tree\n",
        "@return labels : ground truth lables\n",
        "\n",
        "Note: the last two returned values may eventually be zipped together for faster loss calculation.\n",
        "\"\"\"\n",
        "#modified form orig\n",
        "def prepare_batch(batch_data, emb_dictionary, deprels, get_gold_path=False):\n",
        "    data = [process_sample(s, emb_dictionary, deprels, get_gold_path=get_gold_path) for s in batch_data]\n",
        "    # sentences, paths, moves, trees are parallel arrays, each element refers to a sentence\n",
        "    sentences = [s[0] for s in data]\n",
        "    paths = [s[1] for s in data]\n",
        "    moves = [s[2] for s in data]\n",
        "    trees = [s[3] for s in data]\n",
        "    labels = [s[4] for s in data]\n",
        "    return sentences, paths, moves, trees, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3002b0-00f7-4f95-82f7-215b97ada014",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f3002b0-00f7-4f95-82f7-215b97ada014",
        "outputId": "b5e7670a-8f0e-4340-998a-a56fd36a8750"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nemb_dictionary = orig.create_dict(train_dataset)\\ndeprels = create_deprel_dict(train_dataset)\\n\\n_ = prepare_batch(iter(train_dataset), emb_dictionary, deprels, True)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "### code to test prepare_batch\n",
        "\"\"\"\n",
        "emb_dictionary = orig.create_dict(train_dataset)\n",
        "deprels = create_deprel_dict(train_dataset)\n",
        "\n",
        "_ = prepare_batch(iter(train_dataset), emb_dictionary, deprels, True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dc8dfb6-91e4-425d-8406-bd427b31d053",
      "metadata": {
        "id": "0dc8dfb6-91e4-425d-8406-bd427b31d053"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Return indices of projective sentences in the dataset. Must be used with select() to filter out nonprojective trees.\n",
        "\"\"\"\n",
        "def find_projective_idx(dataset):\n",
        "    ret = []\n",
        "    for i in range(len(dataset)):\n",
        "        x = dataset[i]\n",
        "        if orig.is_projective([-1] + [int(head) for head in x[\"head\"] if head!='None']):\n",
        "            ret.append(i)\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
        "outputId": "985a4ace-65ad-4f99-8b0e-436423e5e4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset universal_dependencies (/root/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
            "Reusing dataset universal_dependencies (/root/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
            "Reusing dataset universal_dependencies (/root/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n"
          ]
        }
      ],
      "source": [
        "tmp_train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")\n",
        "dev_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"validation\")\n",
        "test_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"test\")\n",
        "\n",
        "train_dataset = tmp_train_dataset.select(find_projective_idx(tmp_train_dataset)) #to remove nonprojective trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bcb2cbf-eebb-4099-bba8-a05925919abf",
      "metadata": {
        "id": "8bcb2cbf-eebb-4099-bba8-a05925919abf"
      },
      "outputs": [],
      "source": [
        "emb_dictionary = orig.create_dict(train_dataset)\n",
        "deprels = create_deprel_dict(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d176de-aa6a-4258-ab75-e46c772beb81",
      "metadata": {
        "id": "51d176de-aa6a-4258-ab75-e46c772beb81"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels, get_gold_path=True))\n",
        "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels, get_gold_path=True))\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch, emb_dictionary = emb_dictionary, deprels = deprels, get_gold_path=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b",
      "metadata": {
        "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b"
      },
      "source": [
        "## Ideas for the future\n",
        "* Use mean square error to predict pairs (MOVE, LABEL) in the training set\n",
        "* We need to rescale the data in an acceptable range. Probably should make the MOVE have greater variation, e.g LeftArc=100 RightArc=0 Shift=-100\n",
        "* BERT layer must process each sentence separately to produce word embeddings, but it should also be finetuned alongside the fully connected layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xNoPh6s17yyx",
      "metadata": {
        "id": "xNoPh6s17yyx"
      },
      "source": [
        "# Neural Oracle\n",
        "\n",
        "Neural oracle implemented using BERT fine-tunned with a simple classifiers.\n",
        "The references are: [Towards Data Science](https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f) and [Text Classification | Sentiment Analysis with BERT using huggingface, PyTorch and Python Tutorial](https://www.youtube.com/watch?v=8N-nM3QW7O0).\n",
        "\n",
        "The hyperparameters and the training tweaks are taken from the original BERT paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c1ATofEBdwL",
      "metadata": {
        "id": "0c1ATofEBdwL"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "bert_model = 'dbmdz/bert-base-italian-xxl-cased'\n",
        "dropout = 0.3\n",
        "input_size = 3*768\n",
        "learning_rate = 2e-5\n",
        "epochs = 1\n",
        "save_path = \"path_were_to_save_model\"\n",
        "tokenizer_max_len = 150\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZfqzDHLLA08V",
      "metadata": {
        "id": "ZfqzDHLLA08V"
      },
      "outputs": [],
      "source": [
        "# load the BERT tokenizer with pretrained weights for the Italian language\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we have loaded the BERT tokenizer and try it to see how a sentence is processed and which kind of objects the tokenizer returns to be used in BERT."
      ],
      "metadata": {
        "id": "845TJICw2Q9x"
      },
      "id": "845TJICw2Q9x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QtZZfEGK9IG5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtZZfEGK9IG5",
        "outputId": "a4335617-db66-46cd-a58d-4d8b1d2d72b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  102,   401,   162,  1909,   532, 27948,  2369,   139,  5101,  1783,\n",
            "           223,  1731,   146, 16711,   103]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
            "[CLS] Con il termine interfluvio in geologia si indica la porzione [SEP]\n"
          ]
        }
      ],
      "source": [
        "example_text = '''Con il termine interfluvio in geologia si indica la porzione di superﬁcie più elevata\n",
        "                  che separa due valli ﬂuviali adiacenti, che può essere una cresta oppure un' area ampia,\n",
        "                  comunque non coinvolta dal movimento delle acque'''\n",
        "\n",
        "\n",
        "bert_input = tokenizer(example_text, padding='max_length', max_length = 15, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "print(bert_input['input_ids'])      # words to integer\n",
        "print(bert_input['token_type_ids']) # binary mask that identifies whether a token is in the first sentence (before [SEP]) or the second (after [SEP])\n",
        "print(bert_input['attention_mask']) # binary mask that identifies whether a token is a real word or just padding\n",
        "\n",
        "decoded_text = tokenizer.decode(bert_input.input_ids[0])\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mxtuOhzE6rTi",
      "metadata": {
        "id": "mxtuOhzE6rTi"
      },
      "source": [
        "  ## Oracle model using BERT\n",
        "For the oracle we decided to use and fine-tune bert in a regression task.\n",
        "The main idea is:\n",
        "\n",
        "*   given a sentence get the **'Bert input tokens**' and the **'attention mask**' from the BERT tokenizer above;\n",
        "*   pass the 'input tokens' and the 'attention mask' to the BERTOracle that returns a tensor that contains a list of configurations, one for each sentence.\n",
        "\n",
        "In this setting a configuration is a pair of numbers. For this reason we use MSE loss to create a **multi-ouptut regressor** task.\n",
        "\n",
        "One configuration is in the form (**ACTION, LABELS**) where for ACTION we have:\n",
        "\n",
        "* 100 for **LeftArc** action;\n",
        "* 0 for **RightArc** action;\n",
        "* -100 for **Shift** action.\n",
        "\n",
        "For the LABELS we have decided to order them in alphabetical order and convert them into consecutive numbers.\n",
        "The main idea is: \n",
        "\n",
        "the labels represent the relation between words.<br>\n",
        "In the used treebank there are many such relation that are very similar like *obj* and *iobj* so by ordering them and giving consecutive numbers we have that *obj* will be encoded, for instance, as 12 and *iobj* with 13. This means that, even if the oracle infere 13 instead of 12 we have that the prediction is not as wrong as if it will have predicte 50.<br>\n",
        "The main assumption is that closer numbers represent more similar relation.\n",
        "\n",
        "To perfrom the actual multi-output regression we used a simple linear layer that outputs this two values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KkXDGmBW-vFo",
      "metadata": {
        "id": "KkXDGmBW-vFo"
      },
      "outputs": [],
      "source": [
        "class BERTOracle(nn.Module):\n",
        "    def __init__(self, dropout_rate, input_size, bert_model):\n",
        "      super(BERTOracle, self).__init__()\n",
        "      self.bert = BertModel.from_pretrained(bert_model)\n",
        "      self.dropout = nn.Dropout(dropout_rate)\n",
        "      self.out = nn.Linear(input_size, 2)\n",
        "    \n",
        "    def substitute_embeddings(self, word_embeddings, paths):\n",
        "      embedded_path = []\n",
        "      for configuration in paths:\n",
        "        embedded_config = []\n",
        "        for move in configuration:\n",
        "          embedded_move = word_embeddings[move];\n",
        "          embedded_config.append(embedded_move)\n",
        "          \n",
        "        embedded_path.append(torch.stack(embedded_config))\n",
        "\n",
        "      return torch.stack(embedded_path)\n",
        "\n",
        "    def forward(self, input_tokens, attention_mask, paths, num_sentences):\n",
        "      out = self.bert(input_tokens, attention_mask)    \n",
        "      word_embeddings = out.last_hidden_state\n",
        "\n",
        "      final_out = []\n",
        "      #I have to compute the configurations for each sentence individually\n",
        "      for sentence_idx in range(0, num_sentences):\n",
        "        #Substitute each word in a configuration with the corrisponding embeddings\n",
        "        configurations = self.substitute_embeddings(word_embeddings[sentence_idx], paths[sentence_idx])\n",
        "        #Change the shape of the configurations to match (batch_size x input_dim)\n",
        "        configuration_tensor = configurations.view(configurations.shape[0], 768*3)\n",
        "        \n",
        "        #Pass through FFN\n",
        "        output = self.dropout(configuration_tensor)\n",
        "        output = self.out(output)\n",
        "\n",
        "        #list that, for each sentence, contains the predicted configuration\n",
        "        final_out.append(output)\n",
        "\n",
        "      #return the list of configurations in for of tensor\n",
        "      return final_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oUpbfnjJBTvv",
      "metadata": {
        "id": "oUpbfnjJBTvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0448344-f98c-4d5c-8e25-e5f03671df47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTOracle(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32102, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=2304, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#Initialize the BERTOracle model\n",
        "model = BERTOracle(dropout, input_size, bert_model)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QRk1Qh53F5EG",
      "metadata": {
        "id": "QRk1Qh53F5EG"
      },
      "source": [
        "## Training and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AaJXSRebF7EE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaJXSRebF7EE",
        "outputId": "75abc51c-ddac-4ea3-c98f-5acdeaa2a144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# AdamW optimizer that uses a different weight decay procedure than Adam\n",
        "optimizer = AdamW(model.parameters(), lr = learning_rate, correct_bias = False)\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Linear scheduler: used to decay the learning rates to improve training performacnes.\n",
        "scheduler  = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = total_steps\n",
        ")\n",
        "#Define the loss as MSE\n",
        "loss_fn = nn.MSELoss().to(device) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluation function for BERTOracle model"
      ],
      "metadata": {
        "id": "p3ePzCq4gJWx"
      },
      "id": "p3ePzCq4gJWx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4h-Y7lj8INBz",
      "metadata": {
        "id": "4h-Y7lj8INBz"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, scheduler):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "\n",
        "  for batch in data_loader:\n",
        "    sentences, paths, moves, trees, labels = batch\n",
        "    optimizer.zero_grad()                                             # initialize gradient to zeros\n",
        "    list_sentences = [str(x) for x in sentences]                      # list of sentences in string format\n",
        "\n",
        "    preprocessed_text = tokenizer(list_sentences, padding='max_length', max_length = tokenizer_max_len, \n",
        "                       truncation=True, return_tensors=\"pt\")          # tokenize input using BERT tokenizer\n",
        "\n",
        "    input_tokens = preprocessed_text[\"input_ids\"]\n",
        "    attention_mask = preprocessed_text[\"attention_mask\"]\n",
        "\n",
        "    outputs = model(input_tokens, attention_mask, paths, BATCH_SIZE)\n",
        "\n",
        "    # Compute the loss for each configurations for each sentence\n",
        "    for idx in range(0, len(sentences)):\n",
        "\n",
        "      tensor_moves = torch.FloatTensor(moves[idx])\n",
        "      loss = loss_fn(outputs[idx], tensor_moves)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      #backpropagation routine\n",
        "      loss.backward(retain_graph=True)\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0) # gradient clipping to avoid exploding gradients if they become too large\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "  mean_loss = np.mean(losses)\n",
        "\n",
        "  return mean_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "idw5no5rK0Ea",
      "metadata": {
        "id": "idw5no5rK0Ea"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, optimzier, scheduler):\n",
        "  model = model.eval()                                                # dropout and batch_norm are not enabled\n",
        "\n",
        "  losses = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "      sentences, paths, moves, trees, labels = batch\n",
        "      optimizer.zero_grad()                                             # initialize gradient to zeros\n",
        "      list_sentences = [str(x) for x in sentences]                      # list of sentences in string format\n",
        "\n",
        "      preprocessed_text = tokenizer(list_sentences, padding='max_length', max_length = tokenizer_max_len, \n",
        "                        truncation=True, return_tensors=\"pt\")           # tokenize input using BERT tokenizer\n",
        "\n",
        "      input_tokens = preprocessed_text[\"input_ids\"]\n",
        "      attention_mask = preprocessed_text[\"attention_mask\"]\n",
        "\n",
        "      outputs = model(input_tokens, attention_mask, BATCH_SIZE)\n",
        "\n",
        "      for idx in range(0, len(sentences)):\n",
        "        tensor_moves = torch.FloatTensor(moves[idx])\n",
        "        loss = loss_fn(outputs[idx], tensor_moves)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "  mean_loss = np.mean(losses)\n",
        "\n",
        "  return mean_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4qhZPXfxLo67",
      "metadata": {
        "id": "4qhZPXfxLo67"
      },
      "source": [
        "## Training loop\n",
        "Training loop that for the given number of epoch preform the training step and the evaluation step for each sentence in the train_dataloader and val_dataloader.\n",
        "All the results are krept inside a dictionary of history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ngRlytTZLqnK",
      "metadata": {
        "id": "ngRlytTZLqnK"
      },
      "outputs": [],
      "source": [
        "history = defaultdict(list) # store training and validation losses in a dictionary \n",
        "epoch_to_save = 5           # save model every 5 epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f'Epoch {epoch + 1} / {epochs}')\n",
        "\n",
        "  #Training step\n",
        "  train_loss = train_epoch(model, train_dataloader, loss_fn, optimizer, scheduler)\n",
        "\n",
        "  print(f\"Train loss {train_loss}\")\n",
        "\n",
        "  #Evaluation step\n",
        "  val_loss = eval_model(model, dev_dataloader, loss_fn, optimizer, scheduler)\n",
        "\n",
        "  print(f\"Val loss {val_loss}\")\n",
        "  print('-'*10)\n",
        "\n",
        "  history['train_loss'].append(train_loss)\n",
        "\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if epoch % epoch_to_save == 0:\n",
        "    torch.save(model, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Om8sss6qfK-L",
      "metadata": {
        "id": "Om8sss6qfK-L"
      },
      "source": [
        "## Evaluation\n",
        "Here we have two evaluation function:\n",
        "* accuracy_unlabeled: given all the configurations for the sentences it check if the predicted move is equal to the golden move. It is the **UAS** (Unlabeled Attachement Score);\n",
        "* accuracy_labeled: given all the configurations for the sentences it check if the predicted configuration (pair of MOVE-LABEL) is equal to the golden one. It is the **LAS** (Labeled Attachement Score);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_unlabeled(golds, preds): \n",
        "  total = 0\n",
        "  correct = 0\n",
        "  n_sentences = len(golds)\n",
        "\n",
        "  for i in range(0, n_sentences):\n",
        "    for j in range(0, len(golds[i])):\n",
        "      total += 1\n",
        "      if(golds[i][j][0] == preds[i][j][0]):\n",
        "        correct += 1\n",
        "\n",
        "  return f'{correct}/{total}'\n",
        "\n",
        "def accuracy_labeled(golds, preds): \n",
        "  total = 0\n",
        "  correct = 0\n",
        "  n_sentences = len(golds)\n",
        "\n",
        "  for i in range(0, n_sentences):\n",
        "    for j in range(0, len(golds[i])):\n",
        "      total += 1\n",
        "      if(golds[i][j]== preds[i][j]):\n",
        "        correct += 1\n",
        "\n",
        "  return f'{correct}/{total}'"
      ],
      "metadata": {
        "id": "lWuyL05l8zUZ"
      },
      "id": "lWuyL05l8zUZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple inference function that uses the above functions to compute LAS and UAS and store them inside a dictionary.<br>\n",
        "Every epoch will have the associated LAS and UAS scores"
      ],
      "metadata": {
        "id": "c3iHhdv_sBjA"
      },
      "id": "c3iHhdv_sBjA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cTUAeO4EfMZU",
      "metadata": {
        "id": "cTUAeO4EfMZU"
      },
      "outputs": [],
      "source": [
        "def evaluation_with_scores(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  unlabeled_history = {}\n",
        "  labeled_history = {}\n",
        "  losses_history = {}\n",
        "  batch_num = 0\n",
        "  losses = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(data_loader):\n",
        "      batch_num += 1\n",
        "      sentences, paths, moves, trees, labels = batch\n",
        "      optimizer.zero_grad()                                             # initialize gradient to zeros\n",
        "      list_sentences = [str(x) for x in sentences]                      # list of sentences in string format\n",
        "\n",
        "      preprocessed_text = tokenizer(list_sentences, padding='max_length', max_length = tokenizer_max_len, \n",
        "                        truncation=True, return_tensors=\"pt\")           # tokenize input using BERT tokenizer\n",
        "\n",
        "      input_tokens = preprocessed_text[\"input_ids\"]\n",
        "      attention_mask = preprocessed_text[\"attention_mask\"]\n",
        "\n",
        "      outputs = model(input_tokens, attention_mask, paths, BATCH_SIZE)\n",
        "\n",
        "      for idx in range(0, len(sentences)):\n",
        "        tensor_moves = torch.FloatTensor(moves[idx])\n",
        "        loss = loss_fn(outputs[idx], tensor_moves)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "      unlabeled_history[batch_num] = accuracy_unlabeled(outputs, moves)\n",
        "      labeled_history[batch_num] = accuracy_labeled(outputs, moves)\n",
        "      losses_history[batch_num] = np.mean(losses)\n",
        "      \n",
        "  return losses_history, unlabeled_history, labeled_history"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the test set I get the the loss and the two dictionaries of UAS and LAS ready to be shown."
      ],
      "metadata": {
        "id": "aqoAqZOQsU5G"
      },
      "id": "aqoAqZOQsU5G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kSzEvwpehpAu",
      "metadata": {
        "id": "kSzEvwpehpAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a833b1-3e9f-4d65-d70b-fe53551e4e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/405 [00:13<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "losses_history, unlabeled_history, labeled_history = evaluation_with_scores(model, train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the results coming from the above evaluation procedure"
      ],
      "metadata": {
        "id": "NY4p93W21Qd-"
      },
      "id": "NY4p93W21Qd-"
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results(losses, uas, las):\n",
        "  for index in range(1, len(losses) + 1):\n",
        "    print(f'EPOCH NUMBER {index}:')\n",
        "    print(f'LOSS: {round(losses.get(index), 2)}')\n",
        "    print(f'UAS: {uas.get(index)}')\n",
        "    print(f'LAS: {las.get(index)}')\n",
        "    print('-'*10)"
      ],
      "metadata": {
        "id": "D18qyEOAyx3d"
      },
      "id": "D18qyEOAyx3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results(losses_history, unlabeled_history, labeled_history)"
      ],
      "metadata": {
        "id": "mtFLodNN0Gor"
      },
      "id": "mtFLodNN0Gor",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
        "747b671a-fd4b-4cbd-a602-a9a25da5e4b2",
        "5a1b7b56-5928-4ca4-9427-0a5edd150ecd",
        "05840970-630c-4152-bdc6-2c25e81fefff",
        "44355fbe-cb0c-4ae5-8967-016ec09033fc"
      ],
      "name": "our_dep_parser.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}