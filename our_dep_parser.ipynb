{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041f954-42d3-44e6-b2c2-281d579e61e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace40b65-a58f-47b6-9905-f41ad6a8d12f",
   "metadata": {
    "id": "fXpE3XkFMagl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac7b5d-012a-40dc-9d04-6ab4cfcca9a5",
   "metadata": {
    "id": "Jthj-_IoKkST"
   },
   "source": [
    "## Arc-standard\n",
    "\n",
    "Recall that a **configuration** of the arc-standard parser is a triple of the form $( \\sigma, \\beta, A)$\n",
    "where:\n",
    "\n",
    "* $\\sigma$ is the stack;\n",
    "* $\\beta$ is the input buffer;\n",
    "* $A$ is a set of arcs constructed so far.\n",
    "\n",
    "We write $\\sigma_i$, $i \\geq 1$, for the $i$-th token in the stack; we also write $\\beta_i$, $i \\geq 1$, for the $i$-th token in the buffer. \n",
    "\n",
    "The parser can perform three types of **actions** (transitions):\n",
    "\n",
    "* **shift**, which removes $\\beta_1$ from the buffer and pushes it into the stack;\n",
    "* **left-arc**, which creates the arc $(\\sigma_1 \\rightarrow \\sigma_2)$, and removes $\\sigma_2$ from the stack;\n",
    "* **right-arc**, which creates the arc $(\\sigma_2 \\rightarrow \\sigma_1)$, and removes $\\sigma_1$ from the stack.\n",
    "\n",
    "Let $w = w_0 w_1 \\cdots w_{n}$ be the input sentence, with $w_0$ the special symbol `<ROOT>`.\n",
    "Stack and buffer are implemented as lists of integers, where `j` represents word $w_j$.  Top-most stack token is at the right-end of the list; first buffer token is at the left-end of the list. \n",
    "Set $A$ is implemented as an array `arcs` of size $n+1$ such that if arc $(w_i \\rightarrow w_j)$ is in $A$ then `arcs[j]=i`, and if $w_j$ is still missing its head node in the tree under construction, then `arcs[j]=-1`. We always have `arcs[0]=-1`.  We use this representation also for complete dependency trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f68788f-e071-424f-9af7-2a35a4c0c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orig #file orig.py in the same foldr contains original class and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4e22b9-5e49-4b3e-8ab6-de62b923bae7",
   "metadata": {
    "id": "sOQpqLVmQZzJ"
   },
   "outputs": [],
   "source": [
    "class ArcStandard (orig.ArcStandard):\n",
    "    def __init__(self, sentence, label_set):\n",
    "        self.sentence = sentence\n",
    "        self.buffer = [i for i in range(len(self.sentence))]\n",
    "        self.stack = []\n",
    "        self.arcs = [(-1, -1) for _ in range(len(self.sentence))]\n",
    "\n",
    "        self.label_set = {y:x for x,y in label_set.items()} #for future reference (printing)\n",
    "        # three shift moves to initialize the stack\n",
    "        self.shift()\n",
    "        self.shift()\n",
    "        if len(self.sentence) > 2:\n",
    "            self.shift()\n",
    "\n",
    "    def left_arc(self, deprel):\n",
    "        o1 = self.stack.pop()\n",
    "        o2 = self.stack.pop()\n",
    "        self.arcs[o2] = (o1, deprel) #added deprel\n",
    "        self.stack.append(o1)\n",
    "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
    "            self.shift()\n",
    "\n",
    "    def right_arc(self, deprel):\n",
    "        o1 = self.stack.pop()\n",
    "        o2 = self.stack.pop()\n",
    "        self.arcs[o1] = (o2, deprel) #added deprel\n",
    "        self.stack.append(o2)\n",
    "        if len(self.stack) < 2 and len(self.buffer) > 0:\n",
    "            self.shift()\n",
    "\n",
    "    def print_configuration(self):\n",
    "        s = [self.sentence[i] for i in self.stack]\n",
    "        b = [self.sentence[i] for i in self.buffer]\n",
    "        print(\"STACK: \", s, \"BUFFER: \", b) #added indication of stack and buffer\n",
    "        print([(x[0], self.label_set[x[1]]) for x in self.arcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d836502-bba0-4f49-9c39-39a916ed270c",
   "metadata": {
    "id": "ImTye0fORmcQ"
   },
   "outputs": [],
   "source": [
    "class Oracle (orig.Oracle):\n",
    "    def __init__(self, parser, gold_tree, gold_labels):\n",
    "        self.parser = parser\n",
    "        self.gold = gold_tree\n",
    "        self.labels = gold_labels #must be integers; see below\n",
    "\n",
    "    def get_gold_label(self):\n",
    "        if(self.is_left_arc_gold()):\n",
    "            o2 = self.parser.stack[len(self.parser.stack)-2]\n",
    "            return self.labels[o2]\n",
    "        elif(self.is_right_arc_gold()):\n",
    "            o1 = self.parser.stack[len(self.parser.stack)-1]\n",
    "            return self.labels[o1]\n",
    "        else:\n",
    "            raise Exception(\"Action SHIFT does not produce a labeled dependency\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b671a-fd4b-4cbd-a602-a9a25da5e4b2",
   "metadata": {},
   "source": [
    "## Functions to simplify the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd7e0ac-d41b-4bd2-ba9a-4ec7d98f1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a dictionary where arc labels are associate to integer values.\n",
    "Label '_' is removed (used for composite tokens)\n",
    "Labels are sorted in alphabetical order because MSE in the neural network will penalize less classes that are \"close\".\n",
    "<ROOT> label is given value -1 (label of the <ROOT> node).\n",
    "\"\"\"\n",
    "def create_deprel_dict(dataset):\n",
    "    import pandas as pd\n",
    "    df = dataset.to_pandas()\n",
    "    labels = set()\n",
    "    for x in df['deprel']:\n",
    "        for elem in x:\n",
    "            if(elem != '_'):\n",
    "                labels.add(elem)\n",
    "    labels = sorted(list(labels))\n",
    "    ret = {labels[i]:i for i in range(len(labels))}\n",
    "    ret.update({\"None\":-1})\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "Return (sanitized_tokens, gold tree, gold labels) for a sentence in the dataset, assuming gold tree is in a column labeled 'head' and labels in a column labeled 'deprel'.\n",
    "Both token indices and labels are converted to integer (in the latter case, according to deprel_dict).\n",
    "Sanitized tokens is a tokenlist with removal of composite tokens.\n",
    "\"\"\"\n",
    "def create_gold(sentence, deprel_dict):\n",
    "    sanitized = ['<ROOT>']\n",
    "    gold_tree = [-1]\n",
    "    gold_labels = [-1]\n",
    "    for i in range(len(sentence['tokens'])):\n",
    "        if(sentence['head'][i] != 'None'):\n",
    "            sanitized.append(sentence['tokens'][i])\n",
    "            gold_tree.append(int(sentence['head'][i]))\n",
    "            gold_labels.append(deprel_dict[sentence['deprel'][i]])\n",
    "    \n",
    "    return sanitized, gold_tree, gold_labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b7b56-5928-4ca4-9427-0a5edd150ecd",
   "metadata": {},
   "source": [
    "## Testing parser and oracle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bcbd5e-b121-4cef-992f-f22df16e4315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9269d170-abea-4671-b795-a9026fc3e46a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6rY9t1Rd6oY",
    "outputId": "3465d0f6-19ad-47e6-d314-d4f8196c957f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 2, 0, 5, 5, 2, 5, 2]\n",
      "[-1, 4, 41, 8, 17, 31, 28, 40]\n"
     ]
    }
   ],
   "source": [
    "deprels = create_deprel_dict(train_dataset)\n",
    "sentence = train_dataset[3]\n",
    "\n",
    "tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
    "\n",
    "print(gold_tree)\n",
    "print(gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2e822a0-9ca2-405d-acdb-4b16f4021a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK:  ['<ROOT>', 'Inconsueto', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n"
     ]
    }
   ],
   "source": [
    "parser = ArcStandard(tokens, deprels)\n",
    "oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "parser.print_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3670b9c6-fa88-4258-8b38-7069bb4cb2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  ['a', 'la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a'] BUFFER:  ['la', 'Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'la'] BUFFER:  ['Tate', 'Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'la', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'a', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (-1, 'None'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  ['Gallery', ':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate', 'Gallery'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (-1, 'None'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', 'Tate'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (-1, 'None'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  [':']\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme', ':'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (-1, 'None')]\n",
      "STACK:  ['<ROOT>', 'allarme'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (-1, 'None'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n",
      "STACK:  ['<ROOT>'] BUFFER:  []\n",
      "[(-1, 'None'), (2, 'amod'), (0, 'root'), (5, 'case'), (5, 'det'), (2, 'nmod'), (5, 'flat:name'), (2, 'punct')]\n"
     ]
    }
   ],
   "source": [
    "while not parser.is_tree_final():  # transition precedence implemented here\n",
    "    if oracle.is_shift_gold():  \n",
    "        parser.shift()\n",
    "    elif oracle.is_left_arc_gold():\n",
    "        parser.left_arc(oracle.get_gold_label())\n",
    "    elif oracle.is_right_arc_gold():\n",
    "        parser.right_arc(oracle.get_gold_label())\n",
    "    \n",
    "    parser.print_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05840970-630c-4152-bdc6-2c25e81fefff",
   "metadata": {},
   "source": [
    "## Testing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9e3f8e-bada-4197-b52f-c14a2755df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to call orig.is_projective() to check for projectivity!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6464ec95-43b7-457a-b764-8ce310c34207",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssVleck0MB0p",
    "outputId": "c3de80a5-04af-4f68-bea7-788a98f156e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non projective:  0\n",
      "correct:  104968\n",
      "wrong:  0\n"
     ]
    }
   ],
   "source": [
    "### NOTE: THIS CELL WAS COPIED WITH FEW MODIFICATIONS FROM THE ORIGINAL FILE\n",
    "\n",
    "# oracle test: run the parser guided by the oracle on the entire training set \n",
    "\n",
    "non_projective = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "deprels = create_deprel_dict(train_dataset)\n",
    "\n",
    "for sample in train_dataset:\n",
    "    tokens, gold_tree, gold_labels = create_gold(sentence, deprels)\n",
    "\n",
    "    if not orig.is_projective(gold_tree):\n",
    "        non_projective += 1\n",
    "        continue\n",
    "\n",
    "    parser = ArcStandard(tokens, deprels)\n",
    "    oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "    while not parser.is_tree_final():\n",
    "        if oracle.is_left_arc_gold(): \n",
    "            parser.left_arc(oracle.get_gold_label())\n",
    "        elif oracle.is_right_arc_gold():\n",
    "            parser.right_arc(oracle.get_gold_label())\n",
    "        elif oracle.is_shift_gold(): \n",
    "            parser.shift()\n",
    "\n",
    "    for j in range(len(gold_tree)):  # comparing heads from parser and gold for actual sample\n",
    "        if gold_tree[j] == parser.arcs[j][0] and gold_labels[j] == parser.arcs[j][1]: \n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "print(\"non projective: \", non_projective)\n",
    "print(\"correct: \", correct)\n",
    "print(\"wrong: \", wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44355fbe-cb0c-4ae5-8967-016ec09033fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAafVsFofOyl",
    "outputId": "f87fd0da-15df-4d67-829e-21be6b0ee436"
   },
   "source": [
    "## Creating samples for the neural oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "453c9ca5-9c30-4813-bf82-2555efaeac12",
   "metadata": {
    "id": "b1ogbuYz-4IX"
   },
   "outputs": [],
   "source": [
    "# Modified from the original\n",
    "\n",
    "#TODO work in progress\n",
    "\"\"\"\n",
    "This function processes a single sample, which is one sentence provided as an element of a Dataset object and returns \n",
    "    enc_sentence : a list of integers encoding the phrase #???? is this even correct for BERT???\n",
    "    gold_path : a list of configurations\n",
    "    gold_moves : a list of (move, label)\n",
    "\"\"\"\n",
    "def process_sample(sample, emb_dictionary, deprels, get_gold_path = False): #emb_dictionary and deprels are dictionaries of words and of dependency relations\n",
    "    tokens, gold_tree, gold_labels = create_gold(sample, deprels)\n",
    "    enc_sentence = [emb_dictionary[word] if word in emb_dictionary else emb_dictionary[\"<unk>\"] for word in sentence]\n",
    "\n",
    "    # gold_path and gold_moves are parallel arrays whose elements refer to parsing steps\n",
    "    gold_path = []   # record two topmost stack token and first buffer token for current step\n",
    "    gold_moves = []  # oracle (canonical) move for current step: 100 is left, 0 right, -100 shift #motivations provided above TODO\n",
    "\n",
    "    if get_gold_path:  # only for training\n",
    "        parser = ArcStandard(sentence, deprel)\n",
    "        oracle = Oracle(parser, gold_tree, gold_labels)\n",
    "\n",
    "        while not parser.is_tree_final():\n",
    "            configuration = [parser.stack[len(parser.stack)-2], parser.stack[len(parser.stack)-1]]\n",
    "            if len(parser.buffer) == 0:\n",
    "                configuration.append(-1)\n",
    "            else:\n",
    "                configuration.append(parser.buffer[0])  \n",
    "\n",
    "            gold_path.append(configuration)\n",
    "\n",
    "            if oracle.is_left_arc_gold():  \n",
    "                label_code = deprels[oracle.get_gold_label()]\n",
    "                parser.left_arc(label_code)\n",
    "                gold_moves.append((100, label_code)) #note: I switched the instructions here for symmetry. There was no comment or good reason not to.\n",
    "            elif oracle.is_right_arc_gold():\n",
    "                label_code = deprels[oracle.get_gold_label()]\n",
    "                parser.right_arc(label_code)\n",
    "                gold_moves.append((0, label_code))\n",
    "            elif oracle.is_shift_gold():\n",
    "                parser.shift()\n",
    "                gold_moves.append((-100, -100))\n",
    "\n",
    "    return enc_sentence, gold_path, gold_moves, gold_tree, gold_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abf6e832-86cf-4033-8524-1a1070e7e5a1",
   "metadata": {
    "id": "5uhOyPuj-t1c"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that prepares the data for the model.\n",
    "@return sentences : list of sentences in the dataset encoded according to emb_dictionary\n",
    "@return paths : list of lists of configurations visited during the oracle-guided parsing (on training data) | empty list if get_gold_path is False\n",
    "@return moves : list of lists of (MOVE, LABEL) performed during the oracle-guided parsing (on training data) | empty if get_gold_path is False\n",
    "@return trees : ground truth tree\n",
    "@return labels : ground truth lables\n",
    "\n",
    "Note: the last two returned values may eventually be zipped together for faster loss calculation.\n",
    "\"\"\"\n",
    "#modified form orig\n",
    "def prepare_batch(batch_data, emb_dictionary, deprels, get_gold_path=False):\n",
    "    data = [process_sample(s, emb_dictionary, deprels, get_gold_path=get_gold_path) for s in batch_data]\n",
    "    # sentences, paths, moves, trees are parallel arrays, each element refers to a sentence\n",
    "    sentences = [s[0] for s in data]\n",
    "    paths = [s[1] for s in data]\n",
    "    moves = [s[2] for s in data]\n",
    "    trees = [s[3] for s in data]\n",
    "    labels = [s[4] for s in data]\n",
    "    return sentences, paths, moves, trees, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1491189-7f64-445d-a7ab-b556101fbc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0bc2e5d04f49f6a5c6e6f09bf92e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n",
      "Reusing dataset universal_dependencies (/home/filippo/.cache/huggingface/datasets/universal_dependencies/it_isdt/2.7.0/065e728dfe9a8371434a6e87132c2386a6eacab1a076d3a12aa417b994e6ef7d)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"train\")\n",
    "train_dataset.filter(lambda x : orig.is_projective([-1] + [int(head) for head in x[\"head\"] if head!='None'])) #to remove nonprojective trees\n",
    "dev_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"validation\")\n",
    "test_dataset = load_dataset('universal_dependencies', 'it_isdt', split=\"test\")\n",
    "\n",
    "emb_dictionary = orig.create_dict(train_dataset)\n",
    "deprels = create_deprel_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51d176de-aa6a-4258-ab75-e46c772beb81",
   "metadata": {
    "id": "r6tZREWR4JJm"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(prepare_batch, get_gold_path=True))\n",
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5fbde0-8a1c-4930-9a63-97b5ad18108b",
   "metadata": {},
   "source": [
    "## Ideas for the future\n",
    "* Use mean square error to predict pairs (MOVE, LABEL) in the training set\n",
    "* We need to rescale the data in an acceptable range. Probably should make the MOVE have greater variation, e.g LeftArc=100 RightArc=0 Shift=-100\n",
    "* BERT layer must process each sentence separately to produce word embeddings, but it should also be finetuned alongside the fully connected layer\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49161622-875c-46c2-a6f0-66b77b3462ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
